{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlexMatch PyTorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 패키지 중 이미 다운 받아진 패키지 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1647328279368,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "p4HGUQjvTyb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\dmqa\\AppData\\Local\\Programs\\Python\\Python38\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys, os, copy, random, argparse, math\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageEnhance\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from colorama import Fore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variable 정의하기\n",
    "#### PARAMETER_MAX, cifar10의 mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647328279369,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "6QzixtWaT0CS"
   },
   "outputs": [],
   "source": [
    "########### 이 값을 두는 이유는 뭘까? ###########\n",
    "PARAMETER_MAX = 10\n",
    "\n",
    "# 이미지 정규화를 위한 평균 및 표준편차\n",
    "mean_cifar10 = (0.4914, 0.4822, 0.4465)\n",
    "std_cifar10 = (0.2471, 0.2345, 0.2616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647328279884,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "slW12bm8UL2U"
   },
   "outputs": [],
   "source": [
    "def _float_parameter(v, max_v):\n",
    "    return float(v) * max_v / PARAMETER_MAX\n",
    "\n",
    "\n",
    "def _int_parameter(v, max_v):\n",
    "    return int(v * max_v / PARAMETER_MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIL 패키지 내 각종 Data Augmentation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279884,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "gBHAD6IoT0yK"
   },
   "outputs": [],
   "source": [
    "# Augmentation 함수들을 정의\n",
    "\n",
    "def AutoContrast(img, **kwargs):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Brightness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Contrast(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v, **kwargs):\n",
    "    w, h = img.size\n",
    "    x0, y0 = np.random.uniform(0, w), np.random.uniform(0, h)\n",
    "    x0, y0 = int(max(0, x0 - v / 2.)), int(max(0, y0 - v / 2.))\n",
    "\n",
    "    x1, y1 = int(min(w, x0 + v)), int(min(h, y0 + v))\n",
    "\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    # gray\n",
    "    color = (127, 127, 127)\n",
    "    img = img.copy()\n",
    "    \n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def Cutout(img, v, max_v, bias=0):\n",
    "    if v == 0:\n",
    "        return img\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    v = int(v * min(img.size))\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def Equalize(img, **kwargs):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Identity(img, **kwargs):\n",
    "    return img\n",
    "\n",
    "\n",
    "def Invert(img, **kwargs):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Posterize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Rotate(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def ShearX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def Solarize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.solarize(img, 256 - v)\n",
    "\n",
    "\n",
    "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    img_np = np.array(img).astype(np.int)\n",
    "    img_np = img_np + v\n",
    "    img_np = np.clip(img_np, 0, 255)\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    img = Image.fromarray(img_np)\n",
    "    return PIL.ImageOps.solarize(img, threshold)\n",
    "\n",
    "\n",
    "def TranslateX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[0])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[1])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647328279885,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "pdfdIvkWUQXY"
   },
   "outputs": [],
   "source": [
    "# RandAugment를 사용하기 위한 전체 Augmentation List를 정의\n",
    "\n",
    "def flexmatch_augment_pool():\n",
    "    \n",
    "    '''\n",
    "    augs: 활용할 Augmentation의 전체집합\n",
    "    '''\n",
    "    \n",
    "    augs = [(AutoContrast, None, None),\n",
    "            (Brightness, 0.9, 0.05),\n",
    "            (Color, 0.9, 0.05),\n",
    "            (Contrast, 0.9, 0.05),\n",
    "            (Equalize, None, None),\n",
    "            (Identity, None, None),\n",
    "            (Posterize, 4, 4),\n",
    "            (Rotate, 30, 0),\n",
    "            (Sharpness, 0.9, 0.05),\n",
    "            (ShearX, 0.3, 0),\n",
    "            (ShearY, 0.3, 0),\n",
    "            (Solarize, 256, 0),\n",
    "            (TranslateX, 0.3, 0),\n",
    "            (TranslateY, 0.3, 0)]\n",
    "    return augs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandAugment를 위한 class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 구현된 Augmentpool에서 랜덤으로 선정하여 실제 Augmentation을 구현\n",
    "\n",
    "class RandAugmentMC(object):\n",
    "    \n",
    "    def __init__(self, n, m):\n",
    "        \n",
    "        '''\n",
    "        초기값 지정\n",
    "        n: 1~\n",
    "        m: 1~10\n",
    "        augment_pool: augmentation 함수들이 모여있는 집합\n",
    "        '''\n",
    "        \n",
    "        assert n >= 1\n",
    "        assert 1 <= m <= 10\n",
    "        \n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.augment_pool = flexmatch_augment_pool()\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "        '''\n",
    "        1. 함수가 불리면 augment_pool에서 n개만큼 선택\n",
    "        2. m범위에서 랜덤하게 operation 강도를 선정\n",
    "        3. 50$의 확률로 위 2가지 과정을 진행할지 결정\n",
    "        4. 마지막에는 Cutout Augmentation 진행\n",
    "        '''\n",
    "        \n",
    "        ops = random.choices(self.augment_pool, k=self.n)\n",
    "        \n",
    "        for op, max_v, bias in ops:\n",
    "            v = np.random.randint(1, self.m)\n",
    "            if random.random() < 0.5:\n",
    "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
    "\n",
    "        img = CutoutAbs(img, int(32*0.5))\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279885,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "UQlTwYXAUQpv"
   },
   "outputs": [],
   "source": [
    "# train_data를 생성하는 함수\n",
    "\n",
    "class CIFAR10_SSL(datasets.CIFAR10):\n",
    "    \n",
    "    def __init__(self, root, indexs, train=True,\n",
    "                transform=None, target_transform=None,\n",
    "                download=False):\n",
    "        \n",
    "        '''\n",
    "        초기값 지정: Indexs가 None이 아니면, 해당 Index만큼 Train으로 설정할 것임\n",
    "        self.data: train_x\n",
    "        self.targets: train_y\n",
    "        '''\n",
    "        \n",
    "        super(CIFAR10_SSL, self).__init__(\n",
    "            root, train=train, transform=transform,\n",
    "            target_transform=target_transform, download=download\n",
    "        )\n",
    "\n",
    "        if indexs is not None:\n",
    "            self.data = self.data[indexs]\n",
    "            self.targets = np.array(self.targets)[indexs]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        '''\n",
    "        getitem: index에 접근할 때 작동하는 함수\n",
    "        1. self.data 및 self.targets (즉, train_x, train_y)에서 각각 index에 해당하는 값을 불러온다.\n",
    "        2. transform이 지정되었다면, img를 Transform(Augmentation) 진행\n",
    "        '''\n",
    "        \n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279885,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "N0xtM10qUQsR"
   },
   "outputs": [],
   "source": [
    "# weak_augmentation과 strong_augmentation된 객체를 반환\n",
    "\n",
    "class TransformFlexMatch(object):\n",
    "    \n",
    "    def __init__(self, mean=mean_cifar10, std=std_cifar10):\n",
    "        \n",
    "        '''\n",
    "        Augmentation하는 함수 초깃값 지정\n",
    "        self.weak_transform: 약한 왜곡의 Augmentation으로 구성\n",
    "        self.strong_transform: 큰 왜곡의 Augmentation으로 구성 --> Weak Augmentation에 추가적인 왜곡을 지정\n",
    "        self.normalize: 정규화하는 함수 정의 ((N, H, W, C)-> (N, C, H, W))\n",
    "        '''\n",
    "        \n",
    "        self.weak_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=32,\n",
    "                                padding=int(32*0.125),\n",
    "                                padding_mode='reflect')\n",
    "        ])\n",
    "\n",
    "        self.strong_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=32,\n",
    "                                padding=int(32*0.125),\n",
    "                                padding_mode='reflect'),\n",
    "            RandAugmentMC(n=2, m=10)\n",
    "        ])\n",
    "\n",
    "        self.normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ]) \n",
    "    \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        '''\n",
    "        함수가 불리면 Weak Aug객체와 Strong Aug객체를 각각 생성 후 정규화한 값들을 반환\n",
    "        '''\n",
    "        \n",
    "        weak = self.weak_transform(x)\n",
    "        strong = self.strong_transform(x)\n",
    "\n",
    "        return self.normalize(weak), self.normalize(strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647328279886,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "OZGgVTRhUQu9"
   },
   "outputs": [],
   "source": [
    "# Labeled data와 Unlabeled data를 분리\n",
    "\n",
    "def split_labeled_unlabeled(args, labels):\n",
    "    \n",
    "    '''\n",
    "    1. 클래스 당 Labeled data의 개수를 정의\n",
    "    2. Labeled data, Unlabeled data, Validation data의 Index를 담을 수 있는 List 초기화\n",
    "    3. 각 Label별로 1에서 정의한 개수만큼 Labeled data를 지정하고, Validation data는 500개, 그 외 데이터는 모두 Unlabeled data로 지정\n",
    "    4. 각 Index를 Shuffle\n",
    "    5. Return Labeled data의 Index, Unlabeled data의 Index, Validation data의 Index\n",
    "    '''\n",
    "    \n",
    "    label_per_class = args.n_labeled // args.n_classes\n",
    "    labels = np.array(labels, dtype=int)\n",
    "    indice_labeled, indice_unlabeled, indice_val = [], [], []\n",
    "\n",
    "    for i in range(10):\n",
    "        indice_tmp = np.where(labels==i)[0]\n",
    "\n",
    "        indice_labeled.extend(indice_tmp[: label_per_class])\n",
    "        indice_unlabeled.extend(indice_tmp[label_per_class: -500])\n",
    "        indice_val.extend(indice_tmp[-500: ])\n",
    "    \n",
    "    for i in [indice_labeled, indice_unlabeled, indice_val]:\n",
    "        np.random.shuffle(i)\n",
    "    \n",
    "    return np.array(indice_labeled), np.array(indice_unlabeled), np.array(indice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279886,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "BW-EzldfUQxR"
   },
   "outputs": [],
   "source": [
    "def get_cifar10(args, data_dir):\n",
    "    \n",
    "    '''\n",
    "    1. labeled data의 tranform정의 \n",
    "    2. validation data의 tranform 정의: 정규화만 진행\n",
    "    3. Cifar10 데이터셋을 불러온 후 Index에 따라 Labeled, Unlabeled, Validation data를 분류\n",
    "    '''\n",
    "    \n",
    "    transform_labeled = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(size=32, padding=int(32*0.125), padding_mode='reflect'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_cifar10, std=std_cifar10)\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_cifar10, std=std_cifar10)\n",
    "    ])\n",
    "\n",
    "    base_dataset = datasets.CIFAR10(data_dir, train=True, download=True)\n",
    "\n",
    "    indice_labeled, indice_unlabeled, indice_val = split_labeled_unlabeled(args, base_dataset.targets)\n",
    "\n",
    "    '''\n",
    "    4. labeled dataset에 대해서는 transform_labeled augmentation 만 적용\n",
    "    5. Unlabeled dataset에 대해서는 transform_labeled augmentation 및 strong augmentation 동시 적용 \n",
    "    6. validation, test dataset에 대해서는 ToTensor & Normalization transformation 만 적용\n",
    "    '''\n",
    "    \n",
    "    labeled_dataset = CIFAR10_SSL(\n",
    "        data_dir, indice_labeled, train=True,\n",
    "        transform=transform_labeled\n",
    "    )\n",
    "\n",
    "    unlabeled_dataset = CIFAR10_SSL(\n",
    "        data_dir, indice_unlabeled, train=True,\n",
    "        transform=TransformFlexMatch(mean=mean_cifar10, std=std_cifar10)\n",
    "    )\n",
    "\n",
    "    val_dataset = CIFAR10_SSL(\n",
    "        data_dir, indice_val, train=True, transform=transform_val, download=False\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        data_dir, train=False, transform=transform_val, download=False\n",
    "    )\n",
    "    \n",
    "    return labeled_dataset, unlabeled_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet (MixMatch 와 동일)\n",
    " - WideResNet Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1647328280379,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "Cu8-zR_HUQz1"
   },
   "outputs": [],
   "source": [
    "# BasicBlock을 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual == True:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "    \n",
    "# Network Block을 정의\n",
    "class NetworkBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual)\n",
    "        \n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate, activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "# WideResNet 모델 정의\n",
    "class WideResNet(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    위에서 정의한 Basic Block 및 Network Block을 기반으로 Wide ResNet 모델 정의\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_classes, depth=28, widen_factor=2, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, activate_before_residual=True)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647328280379,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "J8MGfe4KUQ3t"
   },
   "outputs": [],
   "source": [
    "# WeightEMA로 Parameter를 Update하는 함수를 정의 (EMA=Exponential Moving Average)\n",
    "\n",
    "class WeightEMA(object): \n",
    "    \n",
    "    '''\n",
    "    MixMatch와 hyperparameter 이름만 변경\n",
    "    WeightEMA를 하는 이유는 학습시간이 길어지거나, Trivial Solution을 방지, 과적합 방지 등. \n",
    "    --> 가중치를 업데이트 시 a(최근가중치)+(1-a)(이전가중치)\n",
    "    --> summary: ema_params_new = self.decay*ema_params_old + (1-self.decay)*params\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model, decay):\n",
    "        \n",
    "        self.ema = copy.deepcopy(model)\n",
    "        self.ema.eval()\n",
    "\n",
    "        self.decay = decay\n",
    "\n",
    "        self.ema_has_module = hasattr(self.ema, 'module')\n",
    "\n",
    "        self.param_keys = [k for k, _ in self.ema.named_parameters()]\n",
    "        self.buffer_keys = [k for k, _ in self.ema.named_buffers()]\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def step(self, model):\n",
    "        needs_module = hasattr(model, 'module') and not self.ema_has_module\n",
    "        with torch.no_grad():\n",
    "            msd = model.state_dict()\n",
    "            esd = self.ema.state_dict()\n",
    "            for k in self.param_keys:\n",
    "                if needs_module:\n",
    "                    j = 'module.' + k\n",
    "                else:\n",
    "                    j = k\n",
    "                model_v = msd[j].detach()\n",
    "                ema_v = esd[k]\n",
    "                esd[k].copy_(ema_v * self.decay + (1. - self.decay) * model_v)\n",
    "\n",
    "            for k in self.buffer_keys:\n",
    "                if needs_module:\n",
    "                    j = 'module.' + k\n",
    "                else:\n",
    "                    j = k\n",
    "                esd[k].copy_(msd[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647328280379,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "x7_m766lVDNu"
   },
   "outputs": [],
   "source": [
    "# TopK Accuracy를 구하는 함수를 정의\n",
    "def accuracy(output, target, topk=(1, )):\n",
    "    \n",
    "    '''  \n",
    "    Pred값이 TopK개내에 있다면, 맞춘 것으로 정의\n",
    "    '''\n",
    "    \n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        if k == 1:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        if k > 1:\n",
    "            correct_k = correct[:k].float().sum(0).sum(0)\n",
    "        acc = correct_k.mul_(100.0 / batch_size)\n",
    "        acc = acc.detach().cpu().numpy()\n",
    "        res.append(acc)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328280380,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "Di-FhnXPVDQw"
   },
   "outputs": [],
   "source": [
    "# tqdm config 함수 정의\n",
    "def get_tqdm_config(total, leave=True, color='white'):\n",
    "    fore_colors = {\n",
    "        'red': Fore.LIGHTRED_EX,\n",
    "        'green': Fore.LIGHTGREEN_EX,\n",
    "        'yellow': Fore.LIGHTYELLOW_EX,\n",
    "        'blue': Fore.LIGHTBLUE_EX,\n",
    "        'magenta': Fore.LIGHTMAGENTA_EX,\n",
    "        'cyan': Fore.LIGHTCYAN_EX,\n",
    "        'white': Fore.LIGHTWHITE_EX,\n",
    "    }\n",
    "    return {\n",
    "        'file': sys.stdout,\n",
    "        'total': total,\n",
    "        'desc': \" \",\n",
    "        'dynamic_ncols': True,\n",
    "        'bar_format':\n",
    "            \"{l_bar}%s{bar}%s| [{elapsed}<{remaining}, {rate_fmt}{postfix}]\" % (fore_colors[color], Fore.RESET),\n",
    "        'leave': leave\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328280380,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "UwHulI5UVDT8"
   },
   "outputs": [],
   "source": [
    "# Warmup을 적용한 Learning rate Scheduler 적용\n",
    "def get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps, num_training_steps,\n",
    "    num_cycles=7.0/16.0, last_epoch=-1\n",
    "    ):\n",
    "    \n",
    "    def _lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step)/float(max(1, num_warmup_steps))\n",
    "        \n",
    "        no_progress = float(current_step-num_warmup_steps)/\\\n",
    "            (float(max(1, num_training_steps-num_warmup_steps)))\n",
    "        return max(0.0, math.cos(math.pi*num_cycles*no_progress))\n",
    "    \n",
    "    return LambdaLR(optimizer, _lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1647328280640,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "0GJwI58MVDWu"
   },
   "outputs": [],
   "source": [
    "# trainer를 정의\n",
    "class FlexMatchTrainer():\n",
    "    \n",
    "    '''\n",
    "    DataLoader 내 num_workers 옵션에 대한 사설\n",
    "    Window10는 다중 CPU 코어 사용 시 순차적으로 작동 시작\n",
    "    Linux(Ubuntu, CentOS) 계열은 동시에 CPU 코어 작동을 시작 가능\n",
    "    (Windows10+PyTorch)를 사용해 Deep Learning 모델 학습 시 num_workers=0을 사용하는 것을 권유\n",
    "    (Linux계열 운영체제+PyTorch)를 사용해 Deep Learning 모델 학습 시 CPU&GPU 사용량이 최대가 될 수 있도록 num_workers 조정 권유\n",
    "    '''\n",
    "    \n",
    "    # 초깃값 지정\n",
    "    def __init__(self, args):\n",
    "        \n",
    "        '''\n",
    "        초깃값 지정\n",
    "        1. argument\n",
    "        2. directory\n",
    "        3. Dataset\n",
    "        4. DataLoader\n",
    "        5. Model(EMA Model), Optimzer, Model_parameter, LR Scheduler, Loss Function\n",
    "        6. Tensorboard 객체\n",
    "        '''\n",
    "        \n",
    "        # argment를 받아오기\n",
    "        self.args = args\n",
    "        \n",
    "        # 각종 Directory를 지정\n",
    "        root_dir = '/content/FlexMatch' ### Project Directory\n",
    "        data_dir = os.path.join(root_dir, 'data') ### Data Directory\n",
    "        \n",
    "        self.experiment_dir = os.path.join(root_dir, 'results') ### 학습된 모델을 저장할 큰 폴더\n",
    "        os.makedirs(self.experiment_dir, exist_ok=True)\n",
    "\n",
    "        name_exp = \"_\".join([str(self.args.n_labeled), str(self.args.T)]) ### 학습된 모델을 저장할 세부 폴더 (하이퍼파라미터로 지정)\n",
    "        self.experiment_dir = os.path.join(self.experiment_dir, name_exp)\n",
    "        os.makedirs(self.experiment_dir, exist_ok=True)\n",
    "        \n",
    "        # Load Dataset (Labeled, Unlabeled, Valid, Test dataset)\n",
    "        print(\"==> Preparing CIFAR10 dataset\")\n",
    "        labeled_set, unlabeled_set, val_set, test_set = get_cifar10(self.args, data_dir=data_dir)\n",
    "        \n",
    "        # DataLoader를 각각 정의 (Labeled, Unlabeled, Valid, Test dataset)                 \n",
    "        self.labeled_loader = DataLoader(\n",
    "            labeled_set,\n",
    "            sampler=RandomSampler(labeled_set), ### RandomSampler: DataLoader(shuffle=True) 와 동일한 역할\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        self.unlabeled_loader = DataLoader(\n",
    "            unlabeled_set,\n",
    "            sampler=RandomSampler(unlabeled_set),\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        self.val_loader = DataLoader(\n",
    "            val_set,\n",
    "            sampler=SequentialSampler(val_set), ### SequentialSampler: DataLoader(shuffle=False) 와 동일한 역할\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        self.test_loader = DataLoader(\n",
    "            test_set,\n",
    "            sampler=SequentialSampler(test_set),\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # WideResNet모델 정의\n",
    "        print(\"==> Preparing WideResNet\")\n",
    "        self.model = WideResNet(self.args.n_classes).to(self.args.cuda)\n",
    "        \n",
    "        # 모델의 Gradient 초기화 및 Loss Function을 정의\n",
    "        self.model.zero_grad()\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.cuda)\n",
    "\n",
    "        # Optimzer를 정의: params의 이름 내 bias, bn이 들어가지 않는 경우에만 weight_decay 적용\n",
    "        no_decay = ['bias', 'bn']\n",
    "        grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(\n",
    "                nd in n for nd in no_decay)], 'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(\n",
    "                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "        self.optimizer = torch.optim.SGD(grouped_parameters, lr=self.args.lr,\n",
    "                            momentum=0.9, nesterov=self.args.nesterov)\n",
    "        \n",
    "        # Learning rate Scheduler를 적용\n",
    "        \n",
    "        '''\n",
    "        Learning scheduler의 경우 사용이 까다로움\n",
    "         - 특정 scheduler는 각각 iteration 마다 step을 진행\n",
    "         - 또 다른 scheduler그룹은 한 epoch 종료 후 step 진행\n",
    "         - 아래 Documentation 에서 사용할 lr_scheduler에 대한 설명을 정확히 읽고 사용\n",
    "           - https://pytorch.org/docs/stable/optim.html\n",
    "        '''\n",
    "        \n",
    "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer,\n",
    "                                                    self.args.warmup,\n",
    "                                                    self.args.total_steps)\n",
    "        \n",
    "        # EMA Model을 쓸건지 안 쓸건지 명시\n",
    "        if self.args.use_ema:  \n",
    "            self.ema_model = WeightEMA(self.model, self.args.ema_decay)\n",
    "        \n",
    "        # Tensorboard에 기록할 객체 정의\n",
    "        self.writer = SummaryWriter(self.experiment_dir)\n",
    "\n",
    "        \n",
    "    # train을 위한 함수\n",
    "    def train(self, epoch):\n",
    "        \n",
    "        # total, labeled, unlabeled loss 초기화 및 Mask probs(Threshold를 넘었는지 여부를 표시한 것) 초기화\n",
    "        losses_t, losses_x, losses_u, mask_probs = 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        # 훈련모드 전환\n",
    "        self.model.train()\n",
    "        \n",
    "        # iter함수로 Labeled data 및 Unlabeled data 불러오기\n",
    "        iter_labeled = iter(self.labeled_loader)\n",
    "        iter_unlabeled = iter(self.unlabeled_loader)\n",
    "\n",
    "        with tqdm(**get_tqdm_config(total=self.args.eval_step,\n",
    "                leave=True, color='blue')) as pbar:\n",
    "            \n",
    "            for batch_idx in range(self.args.eval_step): ### eval_step: 1024 // batch_size: 64\n",
    "                \n",
    "                '''\n",
    "                왜 try-except 문을 사용하나?\n",
    "                 - 코드 작성 후 iter&next가 정확히 작용하지 않는 경우가 있음을 확인\n",
    "                 - 다시 iter_labeled, iter_unlabeled를 정의해 학습에 문제가 없도록 다시 선언\n",
    "                '''\n",
    "                \n",
    "                ### Labeled Data(각각 데이터와 Target)\n",
    "                try:\n",
    "                    inputs_x, targets_x = next(iter_labeled)\n",
    "                except:\n",
    "                    iter_labeled = iter(self.labeled_loader)\n",
    "                    inputs_x, targets_x = next(iter_labeled)\n",
    "                real_B = inputs_x.size(0)\n",
    "                \n",
    "                ### Unlabeled Data (각각 Weak Aug, Strong Aug)\n",
    "                try:\n",
    "                    (inputs_u_w, inputs_u_s), _ = next(iter_unlabeled)\n",
    "                except:\n",
    "                    iter_unlabeled = iter(self.unlabeled_loader)\n",
    "                    (inputs_u_w, inputs_u_s), _ = next(iter_unlabeled)\n",
    "                \n",
    "                ### Labeled data, Weak_aug Unlabeled data, Strong_aug Unlabeled data Concat하여 Input으로 활용\n",
    "                inputs = torch.cat((inputs_x, inputs_u_w, inputs_u_s), dim=0).to(self.args.cuda)\n",
    "                targets_x = targets_x.type(torch.LongTensor)\n",
    "                targets_x = targets_x.to(self.args.cuda)\n",
    "                \n",
    "                logits = self.model(inputs) ##### 예측값이 들어있음\n",
    "                \n",
    "                ### Labeled data와 Unlabeled data를 구분\n",
    "                \n",
    "                '''\n",
    "                real_B까지가 Labeled data Index, 그 외가 Unlabeled임\n",
    "                --> chunk함수로 weak_aug 및 strong_aug 구분 (Unlabeled data에 이미 weak, strong aug 각각 적용한 객체가 남아있는 형태)\n",
    "                '''\n",
    "                \n",
    "                logits_x = logits[:real_B]\n",
    "                logits_u_w, logits_u_s = logits[real_B:].chunk(2)\n",
    "                del(logits)\n",
    "\n",
    "                # Labeled data에 대한 loss계산\n",
    "                loss_x = F.cross_entropy(logits_x, targets_x, reduction='mean')\n",
    "\n",
    "                # Unlabeled data에 대한 loss계산\n",
    "                \n",
    "                '''\n",
    "                Unlabeled 데이터에 대한 로짓 산출 및 Temparature hyperparameter를 사용한 Sharpening\n",
    "                 --> Pseudo label 생성\n",
    "                1) Unlabeled data에 대한 예측값(logits_u_w)에 Softmax를 통과시킨 후 Sharpen 적용\n",
    "                2) 가장 높은 확률을 Label로 지정 (targets_u)\n",
    "                3) threshold값과 비교하여 mask 객체 생성\n",
    "                 - 이는 각 샘플에 대하여 확률이 도출되고, 배치 내 있는 데이터 만큼 Threshold를 넘었는지 여부를 T/F로 도출 [T, T, F, T..]\n",
    "                 - 근데, 지금 1개씩 가져와서 실험하다보니 결국 1개 sample에 대해서만 진행\n",
    "                '''\n",
    "                \n",
    "                pseudo_labels = torch.softmax(logits_u_w.detach()/self.args.T, dim=-1) \n",
    "                max_prob, targets_u = torch.max(pseudo_labels, dim=-1)\n",
    "                mask = max_prob.ge(self.args.threshold).float() ##### mask: Threshold보다 크면 True, 작으면 False를 반환\n",
    "\n",
    "                ### strong augmentation된 이미지에서 산출된 logit과 Pseudo label 사이 cross_entropy 계산\n",
    "                '''\n",
    "                여기서 mask를 곱해줌으로써 True면 1, False면 0을 곱해주게 된다.\n",
    "                --> 이를 통해 False일 경우 Loss연산에 이를 반영하지 않음\n",
    "                '''\n",
    "                loss_u = (F.cross_entropy(logits_u_s, targets_u, reduction='none')*mask).mean()\n",
    "\n",
    "                ### Total loss: Labeled data loss와 Unlabeled data loss의 가중합\n",
    "                loss = loss_x + self.args.lambda_u * loss_u\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                if self.args.use_ema:\n",
    "                    self.ema_model.step(self.model)\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                \n",
    "                ### Tensorboard를 위해 loss값들을 기록\n",
    "                losses_x += loss_x.item()\n",
    "                losses_u += loss_u.item()\n",
    "                losses_t += loss.item()\n",
    "                mask_probs += max_prob.mean().item()\n",
    "                \n",
    "                ### Print log\n",
    "                self.writer.add_scalars(\n",
    "                    'Training steps', {\n",
    "                        'Total_loss': losses_t/(batch_idx+1),\n",
    "                        'Labeled_loss':losses_x/(batch_idx+1),\n",
    "                        'Unlabeled_loss':losses_u/(batch_idx+1),\n",
    "                        'Mask probs': mask_probs/(batch_idx+1)\n",
    "                    }, global_step=epoch*self.args.batch_size+batch_idx\n",
    "                )\n",
    "\n",
    "                pbar.set_description(\n",
    "                    '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n",
    "                        (batch_idx+1), self.args.eval_step,\n",
    "                        losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.set_description(\n",
    "                '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n",
    "                    epoch, self.args.epochs,\n",
    "                    losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "                )\n",
    "            )\n",
    "        return losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "\n",
    "    \n",
    "    # Validation 함수 (MixMatch와 동일)\n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch, phase):\n",
    "        if phase == 'Train': ### Train Loss\n",
    "            data_loader = self.labeled_loader\n",
    "            c = 'blue'\n",
    "        elif phase == 'Valid': ### Valid Loss\n",
    "            data_loader = self.val_loader\n",
    "            c = 'green'\n",
    "        elif phase == 'Test ': ### Test Loss\n",
    "            data_loader = self.test_loader\n",
    "            c = 'red'\n",
    "        \n",
    "        ### 값 초기화\n",
    "        losses = 0.0\n",
    "        top1s, top5s = [], []\n",
    "        \n",
    "        ### 데이터를 넣은 후 Output 및 Loss값, 정확도 산출\n",
    "        with tqdm(**get_tqdm_config(total=len(data_loader),\n",
    "                leave=True, color=c)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "                \n",
    "                targets = targets.type(torch.LongTensor)\n",
    "                inputs, targets = inputs.to(self.args.cuda), targets.to(self.args.cuda)\n",
    "\n",
    "                outputs = self.ema_model.ema(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "                losses += loss.item()\n",
    "                top1s.append(prec1)\n",
    "                top5s.append(prec5)\n",
    "\n",
    "                self.writer.add_scalars(\n",
    "                    f'{phase} steps', {\n",
    "                        'Total_loss': losses/(batch_idx+1),\n",
    "                        'Top1 Acc': np.mean(top1s),\n",
    "                        'Top5 Acc': np.mean(top5s)\n",
    "                    }, global_step=epoch*self.args.batch_size+batch_idx\n",
    "                )\n",
    "\n",
    "                pbar.set_description(\n",
    "                    '[%s-Loss: %.3f|Top1 Acc: %.3f|Top5 Acc: %.3f]'%(\n",
    "                        phase,\n",
    "                        losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.set_description(\n",
    "                '[%s(%4d/ %4d)-Loss: %.3f|Top1 Acc: %.3f|Top5 Acc: %.3f]'%(\n",
    "                    phase,\n",
    "                    epoch, self.args.epochs,\n",
    "                    losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647328280640,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "k-qr4I-2XwBJ"
   },
   "outputs": [],
   "source": [
    "# Argument 정의\n",
    "def FlexMatch_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"FlexMatch PyTorch Implementation for LG Electornics education\")\n",
    "    \n",
    "    # method arguments\n",
    "    parser.add_argument('--n-labeled', type=int, default=4000) # labeled dat의 수\n",
    "    parser.add_argument('--n-classes', type=int, default=10) # Class의 수\n",
    "    parser.add_argument(\"--expand-labels\", action=\"store_true\", \n",
    "                        help=\"expand labels to fit eval steps\")\n",
    "\n",
    "    # training hyperparameters\n",
    "    parser.add_argument('--batch-size', type=int, default=64) # 배치 사이즈\n",
    "    parser.add_argument('--total-steps', default=2**20, type=int) # iteration마다 Scheduler가 적용되기에, Epoch가 아닌, Total-step을 정의\n",
    "    parser.add_argument('--eval-step', type=int, default=1024) # Evaluation Step의 수\n",
    "    parser.add_argument('--lr', type=float, default=0.03) # Learning rate\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4) # Weight Decay 정도\n",
    "    parser.add_argument('--nesterov', action='store_true', default=True) # Nesterov Momentum\n",
    "    parser.add_argument('--warmup', type=float, default=0.0) # Warmup 정도\n",
    "\n",
    "    parser.add_argument('--use-ema', action='store_true', default=True) # EMA 사용여부\n",
    "    parser.add_argument('--ema-decay', type=float, default=0.999) # EMA에서 Decay 정도\n",
    "\n",
    "    parser.add_argument('--mu', type=int, default=7) # Labeled data의 mu배를 Unlabeled 데이터의 개수로 정의하기 위한 함수 (근데 위 Trainer에서는 안 쓰임)\n",
    "    parser.add_argument('--T', type=float, default=1.0) # Sharpening 함수에 들어가는 하이퍼 파라미터\n",
    "\n",
    "    parser.add_argument('--threshold', type=float, default=0.95) # Pseudo-Labeling이 진행되는 Threshold 정의\n",
    "    parser.add_argument('--lambda-u', type=float, default=1.0) # Loss 가중치 정도\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647328280640,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "_z6O-zHBXwIa"
   },
   "outputs": [],
   "source": [
    "# main함수 정의\n",
    "\n",
    "def main():\n",
    "    \n",
    "    '''\n",
    "    1. 사용자의 Parser를 받아온 후, Cuda지정 및 epoch 산정\n",
    "    2. Trainer를 정의\n",
    "    3. Loss값 초기화 \n",
    "    4. 전체 Loss, Labeled data의 Loss, Unlabeled data의 Loss를 담을 리스트 초기화\n",
    "    5. Train, Valid, Test 각각에 대해 Loss, top1 acc, top5 acc를 저장하기 위한 리스트 초기화\n",
    "    6. 각 Epoch 단위로 학습할 때 마다 성능들을 기록 및 Checkpoint 저장\n",
    "    7. 학습 중 Best_loss보다 개선되면, Best Loss를 변환 및 Model Save\n",
    "    '''\n",
    "    \n",
    "    parser = FlexMatch_parser()\n",
    "    args = parser.parse_args([])\n",
    "    args.cuda = torch.device(\"cuda:0\")\n",
    "    args.epochs = math.ceil(args.total_steps/args.eval_step)\n",
    "\n",
    "    trainer = FlexMatchTrainer(args)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    losses, losses_x, losses_u = [], [], []\n",
    "    \n",
    "    train_losses, train _top1s, train_top5s = [], [], []\n",
    "    val_losses, val_top1s, val_top5s = [], [], []\n",
    "    test_losses, test_top1s, test_top5s = [], [], []\n",
    "    \n",
    "    # 각 Epoch단위로 학습할 때 마다 성능들을 기록\n",
    "    for epoch in range(1, args.epochs+1, 1):\n",
    "        loss, loss_x, loss_u = trainer.train(epoch)\n",
    "        losses.append(loss)\n",
    "        losses_x.append(loss_x)\n",
    "        losses_u.append(loss_u)\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Train')\n",
    "        train_losses.append(loss)\n",
    "        train_top1s.append(top1)\n",
    "        train_top5s.append(top5)\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Valid')\n",
    "        val_losses.append(loss)\n",
    "        val_top1s.append(top1)\n",
    "        val_top5s.append(top5)\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(trainer.model, os.path.join(trainer.experiment_dir, 'model.pth'))\n",
    "            torch.save(trainer.ema_model, os.path.join(trainer.experiment_dir, 'ema_model.pth'))\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Test ')\n",
    "        test_losses.append(loss)\n",
    "        test_top1s.append(top1)\n",
    "        test_top5s.append(top5)\n",
    "\n",
    "        torch.save(trainer.model, os.path.join(trainer.experiment_dir, 'checkpooint_model.pth'))\n",
    "        torch.save(trainer.ema_model, os.path.join(trainer.experiment_dir, 'checkpoint_ema_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gn8znG3LX16K",
    "outputId": "4feb12dc-428f-483c-ed43-756ae3ae127b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing CIFAR10 dataset\n",
      "Files already downloaded and verified\n",
      "==> Preparing WideResNet\n",
      "[Train(   1/ 1024)-Total: 1.262|Labeled: 1.216|Unlabeled: 0.046]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:35<00:00,  4.75it/s]\u001b[0m\n",
      "[Train(   1/ 1024)-Loss: 1.703|Top1 Acc: 39.919|Top5 Acc: 85.912]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:02<00:00, 23.07it/s]\u001b[0m\n",
      "[Valid(   1/ 1024)-Loss: 1.708|Top1 Acc: 39.323|Top5 Acc: 86.218]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.75it/s]\u001b[0m\n",
      "[Test (   1/ 1024)-Loss: 1.712|Top1 Acc: 39.023|Top5 Acc: 86.186]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.32it/s]\u001b[0m\n",
      "[Train(   2/ 1024)-Total: 0.838|Labeled: 0.689|Unlabeled: 0.148]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.83it/s]\u001b[0m\n",
      "[Train(   2/ 1024)-Loss: 0.877|Top1 Acc: 70.363|Top5 Acc: 97.833]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:02<00:00, 24.09it/s]\u001b[0m\n",
      "[Valid(   2/ 1024)-Loss: 0.970|Top1 Acc: 66.346|Top5 Acc: 96.615]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.72it/s]\u001b[0m\n",
      "[Test (   2/ 1024)-Loss: 0.999|Top1 Acc: 64.699|Top5 Acc: 96.507]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 36.47it/s]\u001b[0m\n",
      "[Train(   3/ 1024)-Total: 0.680|Labeled: 0.451|Unlabeled: 0.229]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:26<00:00,  4.95it/s]\u001b[0m\n",
      "[Train(   3/ 1024)-Loss: 0.396|Top1 Acc: 88.382|Top5 Acc: 99.622]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:02<00:00, 21.26it/s]\u001b[0m\n",
      "[Valid(   3/ 1024)-Loss: 0.684|Top1 Acc: 76.823|Top5 Acc: 98.397]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.47it/s]\u001b[0m\n",
      "[Test (   3/ 1024)-Loss: 0.720|Top1 Acc: 75.189|Top5 Acc: 98.447]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.92it/s]\u001b[0m\n",
      "[Train(   4/ 1024)-Total: 0.595|Labeled: 0.317|Unlabeled: 0.278]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:39<00:00,  4.66it/s]\u001b[0m\n",
      "[Train(   4/ 1024)-Loss: 0.181|Top1 Acc: 95.086|Top5 Acc: 99.924]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:02<00:00, 23.28it/s]\u001b[0m\n",
      "[Valid(   4/ 1024)-Loss: 0.608|Top1 Acc: 79.868|Top5 Acc: 98.858]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.87it/s]\u001b[0m\n",
      "[Test (   4/ 1024)-Loss: 0.650|Top1 Acc: 78.852|Top5 Acc: 98.925]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.19it/s]\u001b[0m\n",
      "[Train(   5/ 1024)-Total: 0.543|Labeled: 0.232|Unlabeled: 0.311]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.84it/s]\u001b[0m\n",
      "[Train(   5/ 1024)-Loss: 0.086|Top1 Acc: 98.311|Top5 Acc: 99.975]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:02<00:00, 23.36it/s]\u001b[0m\n",
      "[Valid(   5/ 1024)-Loss: 0.601|Top1 Acc: 81.390|Top5 Acc: 99.058]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.92it/s]\u001b[0m\n",
      "[Test (   5/ 1024)-Loss: 0.640|Top1 Acc: 80.653|Top5 Acc: 99.094]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.17it/s]\u001b[0m\n",
      "[Train(   6/ 1024)-Total: 0.512|Labeled: 0.189|Unlabeled: 0.323]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:41<00:00,  4.63it/s]\u001b[0m\n",
      "[Train(   6/ 1024)-Loss: 0.049|Top1 Acc: 99.168|Top5 Acc: 99.975]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:02<00:00, 22.36it/s]\u001b[0m\n",
      "[Valid(   6/ 1024)-Loss: 0.595|Top1 Acc: 83.073|Top5 Acc: 98.978]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.86it/s]\u001b[0m\n",
      "[Test (   6/ 1024)-Loss: 0.635|Top1 Acc: 82.046|Top5 Acc: 99.154]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.84it/s]\u001b[0m\n",
      "[Train(   7/ 1024)-Total: 0.483|Labeled: 0.150|Unlabeled: 0.333]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:42<00:00,  4.61it/s]\u001b[0m\n",
      "[Train(   7/ 1024)-Loss: 0.026|Top1 Acc: 99.723|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.00it/s]\u001b[0m\n",
      "[Valid(   7/ 1024)-Loss: 0.586|Top1 Acc: 83.433|Top5 Acc: 99.038]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 29.77it/s]\u001b[0m\n",
      "[Test (   7/ 1024)-Loss: 0.633|Top1 Acc: 82.932|Top5 Acc: 99.114]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.96it/s]\u001b[0m\n",
      "[Train(   8/ 1024)-Total: 0.468|Labeled: 0.134|Unlabeled: 0.334]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:43<00:00,  4.58it/s]\u001b[0m\n",
      "[Train(   8/ 1024)-Loss: 0.016|Top1 Acc: 99.849|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 21.52it/s]\u001b[0m\n",
      "[Valid(   8/ 1024)-Loss: 0.579|Top1 Acc: 83.914|Top5 Acc: 99.179]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.09it/s]\u001b[0m\n",
      "[Test (   8/ 1024)-Loss: 0.626|Top1 Acc: 83.519|Top5 Acc: 99.074]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.93it/s]\u001b[0m\n",
      "[Train(   9/ 1024)-Total: 0.461|Labeled: 0.124|Unlabeled: 0.337]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:42<00:00,  4.60it/s]\u001b[0m\n",
      "[Train(   9/ 1024)-Loss: 0.011|Top1 Acc: 99.950|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.27it/s]\u001b[0m\n",
      "[Valid(   9/ 1024)-Loss: 0.568|Top1 Acc: 84.736|Top5 Acc: 99.279]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.95it/s]\u001b[0m\n",
      "[Test (   9/ 1024)-Loss: 0.618|Top1 Acc: 83.977|Top5 Acc: 99.144]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.05it/s]\u001b[0m\n",
      "[Train(  10/ 1024)-Total: 0.449|Labeled: 0.112|Unlabeled: 0.337]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:42<00:00,  4.60it/s]\u001b[0m\n",
      "[Train(  10/ 1024)-Loss: 0.008|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.00it/s]\u001b[0m\n",
      "[Valid(  10/ 1024)-Loss: 0.558|Top1 Acc: 85.517|Top5 Acc: 99.399]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.64it/s]\u001b[0m\n",
      "[Test (  10/ 1024)-Loss: 0.608|Top1 Acc: 84.584|Top5 Acc: 99.184]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.73it/s]\u001b[0m\n",
      "[Train(  11/ 1024)-Total: 0.441|Labeled: 0.103|Unlabeled: 0.338]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:40<00:00,  4.64it/s]\u001b[0m\n",
      "[Train(  11/ 1024)-Loss: 0.008|Top1 Acc: 99.924|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 23.95it/s]\u001b[0m\n",
      "[Valid(  11/ 1024)-Loss: 0.556|Top1 Acc: 85.697|Top5 Acc: 99.339]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 36.67it/s]\u001b[0m\n",
      "[Test (  11/ 1024)-Loss: 0.608|Top1 Acc: 84.893|Top5 Acc: 99.303]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 36.87it/s]\u001b[0m\n",
      "[Train(  12/ 1024)-Total: 0.433|Labeled: 0.098|Unlabeled: 0.336]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:33<00:00,  4.79it/s]\u001b[0m\n",
      "[Train(  12/ 1024)-Loss: 0.005|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 23.33it/s]\u001b[0m\n",
      "[Valid(  12/ 1024)-Loss: 0.546|Top1 Acc: 86.118|Top5 Acc: 99.299]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.88it/s]\u001b[0m\n",
      "[Test (  12/ 1024)-Loss: 0.597|Top1 Acc: 85.161|Top5 Acc: 99.204]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.28it/s]\u001b[0m\n",
      "[Train(  13/ 1024)-Total: 0.423|Labeled: 0.091|Unlabeled: 0.332]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.77it/s]\u001b[0m\n",
      "[Train(  13/ 1024)-Loss: 0.004|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.41it/s]\u001b[0m\n",
      "[Valid(  13/ 1024)-Loss: 0.537|Top1 Acc: 86.478|Top5 Acc: 99.399]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.97it/s]\u001b[0m\n",
      "[Test (  13/ 1024)-Loss: 0.596|Top1 Acc: 85.330|Top5 Acc: 99.234]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 33.11it/s]\u001b[0m\n",
      "[Train(  14/ 1024)-Total: 0.424|Labeled: 0.087|Unlabeled: 0.337]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:33<00:00,  4.80it/s]\u001b[0m\n",
      "[Train(  14/ 1024)-Loss: 0.004|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid(  14/ 1024)-Loss: 0.535|Top1 Acc: 86.518|Top5 Acc: 99.319]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 35.78it/s]\u001b[0m\n",
      "[Test (  14/ 1024)-Loss: 0.595|Top1 Acc: 85.858|Top5 Acc: 99.224]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.72it/s]\u001b[0m\n",
      "[Train(  15/ 1024)-Total: 0.423|Labeled: 0.086|Unlabeled: 0.337]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.73it/s]\u001b[0m\n",
      "[Train(  15/ 1024)-Loss: 0.004|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.35it/s]\u001b[0m\n",
      "[Valid(  15/ 1024)-Loss: 0.531|Top1 Acc: 86.959|Top5 Acc: 99.359]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.11it/s]\u001b[0m\n",
      "[Test (  15/ 1024)-Loss: 0.582|Top1 Acc: 86.087|Top5 Acc: 99.313]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.13it/s]\u001b[0m\n",
      "[Train(  16/ 1024)-Total: 0.424|Labeled: 0.085|Unlabeled: 0.339]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:41<00:00,  4.63it/s]\u001b[0m\n",
      "[Train(  16/ 1024)-Loss: 0.003|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.61it/s]\u001b[0m\n",
      "[Valid(  16/ 1024)-Loss: 0.534|Top1 Acc: 86.859|Top5 Acc: 99.399]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.34it/s]\u001b[0m\n",
      "[Test (  16/ 1024)-Loss: 0.576|Top1 Acc: 86.097|Top5 Acc: 99.333]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.52it/s]\u001b[0m\n",
      "[Train(  17/ 1024)-Total: 0.409|Labeled: 0.077|Unlabeled: 0.332]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:42<00:00,  4.60it/s]\u001b[0m\n",
      "[Train(  17/ 1024)-Loss: 0.003|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.47it/s]\u001b[0m\n",
      "[Valid(  17/ 1024)-Loss: 0.527|Top1 Acc: 86.959|Top5 Acc: 99.499]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.36it/s]\u001b[0m\n",
      "[Test (  17/ 1024)-Loss: 0.568|Top1 Acc: 86.385|Top5 Acc: 99.353]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.96it/s]\u001b[0m\n",
      "[Train(  18/ 1024)-Total: 0.407|Labeled: 0.075|Unlabeled: 0.332]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:41<00:00,  4.62it/s]\u001b[0m\n",
      "[Train(  18/ 1024)-Loss: 0.003|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.49it/s]\u001b[0m\n",
      "[Valid(  18/ 1024)-Loss: 0.528|Top1 Acc: 87.039|Top5 Acc: 99.399]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.46it/s]\u001b[0m\n",
      "[Test (  18/ 1024)-Loss: 0.557|Top1 Acc: 86.535|Top5 Acc: 99.393]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.58it/s]\u001b[0m\n",
      "[Train(  19/ 1024)-Total: 0.406|Labeled: 0.075|Unlabeled: 0.332]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:42<00:00,  4.60it/s]\u001b[0m\n",
      "[Train(  19/ 1024)-Loss: 0.002|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.66it/s]\u001b[0m\n",
      "[Valid(  19/ 1024)-Loss: 0.523|Top1 Acc: 87.119|Top5 Acc: 99.519]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.41it/s]\u001b[0m\n",
      "[Test (  19/ 1024)-Loss: 0.546|Top1 Acc: 86.893|Top5 Acc: 99.383]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.40it/s]\u001b[0m\n",
      "[Train(  20/ 1024)-Total: 0.401|Labeled: 0.075|Unlabeled: 0.326]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:41<00:00,  4.62it/s]\u001b[0m\n",
      "[Train(  20/ 1024)-Loss: 0.002|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.29it/s]\u001b[0m\n",
      "[Valid(  20/ 1024)-Loss: 0.517|Top1 Acc: 87.380|Top5 Acc: 99.479]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.10it/s]\u001b[0m\n",
      "[Test (  20/ 1024)-Loss: 0.541|Top1 Acc: 87.012|Top5 Acc: 99.353]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.37it/s]\u001b[0m\n",
      "[Train(  21/ 1024)-Total: 0.402|Labeled: 0.072|Unlabeled: 0.330]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:41<00:00,  4.62it/s]\u001b[0m\n",
      "[Train(  21/ 1024)-Loss: 0.002|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.42it/s]\u001b[0m\n",
      "[Valid(  21/ 1024)-Loss: 0.504|Top1 Acc: 87.901|Top5 Acc: 99.499]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 32.46it/s]\u001b[0m\n",
      "[Test (  21/ 1024)-Loss: 0.534|Top1 Acc: 87.311|Top5 Acc: 99.333]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:05<00:00, 29.87it/s]\u001b[0m\n",
      "[Train(  22/ 1024)-Total: 0.405|Labeled: 0.068|Unlabeled: 0.336]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:43<00:00,  4.59it/s]\u001b[0m\n",
      "[Train(  22/ 1024)-Loss: 0.002|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.47it/s]\u001b[0m\n",
      "[Valid(  22/ 1024)-Loss: 0.507|Top1 Acc: 88.061|Top5 Acc: 99.539]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.65it/s]\u001b[0m\n",
      "[Test (  22/ 1024)-Loss: 0.531|Top1 Acc: 87.341|Top5 Acc: 99.393]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.80it/s]\u001b[0m\n",
      "[Train(  23/ 1024)-Total: 0.394|Labeled: 0.067|Unlabeled: 0.327]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:41<00:00,  4.62it/s]\u001b[0m\n",
      "[Train(  23/ 1024)-Loss: 0.002|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.61it/s]\u001b[0m\n",
      "[Valid(  23/ 1024)-Loss: 0.510|Top1 Acc: 88.161|Top5 Acc: 99.479]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.30it/s]\u001b[0m\n",
      "[Test (  23/ 1024)-Loss: 0.525|Top1 Acc: 87.460|Top5 Acc: 99.413]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.99it/s]\u001b[0m\n",
      "[Train(  24/ 1024)-Total: 0.395|Labeled: 0.067|Unlabeled: 0.328]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:44<00:00,  4.56it/s]\u001b[0m\n",
      "[Train(  24/ 1024)-Loss: 0.002|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.36it/s]\u001b[0m\n",
      "[Valid(  24/ 1024)-Loss: 0.511|Top1 Acc: 88.081|Top5 Acc: 99.539]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.39it/s]\u001b[0m\n",
      "[Test (  24/ 1024)-Loss: 0.527|Top1 Acc: 87.520|Top5 Acc: 99.353]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:05<00:00, 31.11it/s]\u001b[0m\n",
      "[Train(  25/ 1024)-Total: 0.392|Labeled: 0.067|Unlabeled: 0.326]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:45<00:00,  4.54it/s]\u001b[0m\n",
      "[Train(  25/ 1024)-Loss: 0.002|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 22.35it/s]\u001b[0m\n",
      "[Valid(  25/ 1024)-Loss: 0.499|Top1 Acc: 88.221|Top5 Acc: 99.559]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.72it/s]\u001b[0m\n",
      "[Test (  25/ 1024)-Loss: 0.517|Top1 Acc: 87.759|Top5 Acc: 99.443]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.68it/s]\u001b[0m\n",
      "[Train(  26/ 1024)-Total: 0.387|Labeled: 0.065|Unlabeled: 0.322]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:43<00:00,  4.58it/s]\u001b[0m\n",
      "[Train(  26/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.61it/s]\u001b[0m\n",
      "[Valid(  26/ 1024)-Loss: 0.501|Top1 Acc: 88.542|Top5 Acc: 99.519]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 33.27it/s]\u001b[0m\n",
      "[Test (  26/ 1024)-Loss: 0.512|Top1 Acc: 87.749|Top5 Acc: 99.453]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.54it/s]\u001b[0m\n",
      "[Train(  27/ 1024)-Total: 0.394|Labeled: 0.065|Unlabeled: 0.329]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:46<00:00,  4.52it/s]\u001b[0m\n",
      "[Train(  27/ 1024)-Loss: 0.002|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.24it/s]\u001b[0m\n",
      "[Valid(  27/ 1024)-Loss: 0.498|Top1 Acc: 88.341|Top5 Acc: 99.559]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.57it/s]\u001b[0m\n",
      "[Test (  27/ 1024)-Loss: 0.511|Top1 Acc: 88.008|Top5 Acc: 99.502]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.66it/s]\u001b[0m\n",
      "[Train(  28/ 1024)-Total: 0.390|Labeled: 0.062|Unlabeled: 0.327]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:45<00:00,  4.54it/s]\u001b[0m\n",
      "[Train(  28/ 1024)-Loss: 0.002|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.28it/s]\u001b[0m\n",
      "[Valid(  28/ 1024)-Loss: 0.489|Top1 Acc: 88.462|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.94it/s]\u001b[0m\n",
      "[Test (  28/ 1024)-Loss: 0.511|Top1 Acc: 87.918|Top5 Acc: 99.512]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.00it/s]\u001b[0m\n",
      "[Train(  29/ 1024)-Total: 0.382|Labeled: 0.062|Unlabeled: 0.321]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:43<00:00,  4.58it/s]\u001b[0m\n",
      "[Train(  29/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.44it/s]\u001b[0m\n",
      "[Valid(  29/ 1024)-Loss: 0.488|Top1 Acc: 88.682|Top5 Acc: 99.539]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.76it/s]\u001b[0m\n",
      "[Test (  29/ 1024)-Loss: 0.504|Top1 Acc: 88.008|Top5 Acc: 99.482]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 31.44it/s]\u001b[0m\n",
      "[Train(  30/ 1024)-Total: 0.377|Labeled: 0.060|Unlabeled: 0.317]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:42<00:00,  4.60it/s]\u001b[0m\n",
      "[Train(  30/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.44it/s]\u001b[0m\n",
      "[Valid(  30/ 1024)-Loss: 0.472|Top1 Acc: 88.562|Top5 Acc: 99.599]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 31.84it/s]\u001b[0m\n",
      "[Test (  30/ 1024)-Loss: 0.498|Top1 Acc: 88.157|Top5 Acc: 99.433]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 32.06it/s]\u001b[0m\n",
      "[Train(  31/ 1024)-Total: 0.377|Labeled: 0.058|Unlabeled: 0.319]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.76it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train(  31/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.43it/s]\u001b[0m\n",
      "[Valid(  31/ 1024)-Loss: 0.474|Top1 Acc: 88.822|Top5 Acc: 99.559]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 35.38it/s]\u001b[0m\n",
      "[Test (  31/ 1024)-Loss: 0.501|Top1 Acc: 87.998|Top5 Acc: 99.482]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.61it/s]\u001b[0m\n",
      "[Train(  32/ 1024)-Total: 0.381|Labeled: 0.062|Unlabeled: 0.319]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:32<00:00,  4.83it/s]\u001b[0m\n",
      "[Train(  32/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.52it/s]\u001b[0m\n",
      "[Valid(  32/ 1024)-Loss: 0.473|Top1 Acc: 89.183|Top5 Acc: 99.559]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 35.26it/s]\u001b[0m\n",
      "[Test (  32/ 1024)-Loss: 0.494|Top1 Acc: 88.376|Top5 Acc: 99.473]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.56it/s]\u001b[0m\n",
      "[Train(  33/ 1024)-Total: 0.377|Labeled: 0.057|Unlabeled: 0.320]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.85it/s]\u001b[0m\n",
      "[Train(  33/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.26it/s]\u001b[0m\n",
      "[Valid(  33/ 1024)-Loss: 0.477|Top1 Acc: 88.602|Top5 Acc: 99.479]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.35it/s]\u001b[0m\n",
      "[Test (  33/ 1024)-Loss: 0.492|Top1 Acc: 88.465|Top5 Acc: 99.482]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.47it/s]\u001b[0m\n",
      "[Train(  34/ 1024)-Total: 0.381|Labeled: 0.059|Unlabeled: 0.322]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.84it/s]\u001b[0m\n",
      "[Train(  34/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.03it/s]\u001b[0m\n",
      "[Valid(  34/ 1024)-Loss: 0.478|Top1 Acc: 88.762|Top5 Acc: 99.559]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.82it/s]\u001b[0m\n",
      "[Test (  34/ 1024)-Loss: 0.494|Top1 Acc: 88.356|Top5 Acc: 99.423]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.11it/s]\u001b[0m\n",
      "[Train(  35/ 1024)-Total: 0.377|Labeled: 0.058|Unlabeled: 0.319]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:33<00:00,  4.80it/s]\u001b[0m\n",
      "[Train(  35/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.49it/s]\u001b[0m\n",
      "[Valid(  35/ 1024)-Loss: 0.475|Top1 Acc: 88.882|Top5 Acc: 99.519]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.94it/s]\u001b[0m\n",
      "[Test (  35/ 1024)-Loss: 0.493|Top1 Acc: 88.416|Top5 Acc: 99.433]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.11it/s]\u001b[0m\n",
      "[Train(  36/ 1024)-Total: 0.374|Labeled: 0.055|Unlabeled: 0.318]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.83it/s]\u001b[0m\n",
      "[Train(  36/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid(  36/ 1024)-Loss: 0.471|Top1 Acc: 88.822|Top5 Acc: 99.599]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.12it/s]\u001b[0m\n",
      "[Test (  36/ 1024)-Loss: 0.486|Top1 Acc: 88.535|Top5 Acc: 99.512]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train(  37/ 1024)-Total: 0.378|Labeled: 0.056|Unlabeled: 0.322]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  37/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.74it/s]\u001b[0m\n",
      "[Valid(  37/ 1024)-Loss: 0.465|Top1 Acc: 88.762|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.18it/s]\u001b[0m\n",
      "[Test (  37/ 1024)-Loss: 0.480|Top1 Acc: 88.505|Top5 Acc: 99.542]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.88it/s]\u001b[0m\n",
      "[Train(  38/ 1024)-Total: 0.373|Labeled: 0.057|Unlabeled: 0.316]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  38/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.70it/s]\u001b[0m\n",
      "[Valid(  38/ 1024)-Loss: 0.466|Top1 Acc: 88.722|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test (  38/ 1024)-Loss: 0.476|Top1 Acc: 88.734|Top5 Acc: 99.512]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.31it/s]\u001b[0m\n",
      "[Train(  39/ 1024)-Total: 0.370|Labeled: 0.052|Unlabeled: 0.318]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  39/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.26it/s]\u001b[0m\n",
      "[Valid(  39/ 1024)-Loss: 0.461|Top1 Acc: 89.283|Top5 Acc: 99.579]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test (  39/ 1024)-Loss: 0.481|Top1 Acc: 88.694|Top5 Acc: 99.482]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train(  40/ 1024)-Total: 0.373|Labeled: 0.056|Unlabeled: 0.318]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  40/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.75it/s]\u001b[0m\n",
      "[Valid(  40/ 1024)-Loss: 0.456|Top1 Acc: 89.163|Top5 Acc: 99.519]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test (  40/ 1024)-Loss: 0.476|Top1 Acc: 88.645|Top5 Acc: 99.502]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train(  41/ 1024)-Total: 0.372|Labeled: 0.058|Unlabeled: 0.314]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  41/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid(  41/ 1024)-Loss: 0.449|Top1 Acc: 89.363|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test (  41/ 1024)-Loss: 0.471|Top1 Acc: 88.794|Top5 Acc: 99.552]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train(  42/ 1024)-Total: 0.372|Labeled: 0.053|Unlabeled: 0.318]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  42/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid(  42/ 1024)-Loss: 0.455|Top1 Acc: 89.243|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.06it/s]\u001b[0m\n",
      "[Test (  42/ 1024)-Loss: 0.472|Top1 Acc: 88.993|Top5 Acc: 99.552]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.08it/s]\u001b[0m\n",
      "[Train(  43/ 1024)-Total: 0.366|Labeled: 0.052|Unlabeled: 0.314]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.01it/s]\u001b[0m\n",
      "[Train(  43/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid(  43/ 1024)-Loss: 0.454|Top1 Acc: 89.042|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test (  43/ 1024)-Loss: 0.475|Top1 Acc: 89.271|Top5 Acc: 99.522]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train(  44/ 1024)-Total: 0.370|Labeled: 0.056|Unlabeled: 0.315]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  44/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.97it/s]\u001b[0m\n",
      "[Valid(  44/ 1024)-Loss: 0.448|Top1 Acc: 89.303|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test (  44/ 1024)-Loss: 0.471|Top1 Acc: 88.923|Top5 Acc: 99.532]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train(  45/ 1024)-Total: 0.368|Labeled: 0.052|Unlabeled: 0.316]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train(  45/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid(  45/ 1024)-Loss: 0.452|Top1 Acc: 89.323|Top5 Acc: 99.559]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test (  45/ 1024)-Loss: 0.473|Top1 Acc: 89.192|Top5 Acc: 99.502]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train(  46/ 1024)-Total: 0.369|Labeled: 0.051|Unlabeled: 0.319]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.02it/s]\u001b[0m\n",
      "[Train(  46/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid(  46/ 1024)-Loss: 0.448|Top1 Acc: 89.383|Top5 Acc: 99.579]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test (  46/ 1024)-Loss: 0.474|Top1 Acc: 89.172|Top5 Acc: 99.512]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.36it/s]\u001b[0m\n",
      "[Train(  47/ 1024)-Total: 0.367|Labeled: 0.054|Unlabeled: 0.314]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train(  47/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.82it/s]\u001b[0m\n",
      "[Valid(  47/ 1024)-Loss: 0.435|Top1 Acc: 89.583|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.13it/s]\u001b[0m\n",
      "[Test (  47/ 1024)-Loss: 0.464|Top1 Acc: 89.311|Top5 Acc: 99.562]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.38it/s]\u001b[0m\n",
      "[Train(  48/ 1024)-Total: 0.369|Labeled: 0.053|Unlabeled: 0.316]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  48/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.99it/s]\u001b[0m\n",
      "[Valid(  48/ 1024)-Loss: 0.434|Top1 Acc: 89.744|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test (  48/ 1024)-Loss: 0.462|Top1 Acc: 89.351|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.06it/s]\u001b[0m\n",
      "[Train(  49/ 1024)-Total: 0.362|Labeled: 0.049|Unlabeled: 0.313]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  49/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid(  49/ 1024)-Loss: 0.433|Top1 Acc: 89.704|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test (  49/ 1024)-Loss: 0.466|Top1 Acc: 89.172|Top5 Acc: 99.582]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train(  50/ 1024)-Total: 0.367|Labeled: 0.053|Unlabeled: 0.315]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  50/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.98it/s]\u001b[0m\n",
      "[Valid(  50/ 1024)-Loss: 0.425|Top1 Acc: 89.824|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test (  50/ 1024)-Loss: 0.464|Top1 Acc: 89.232|Top5 Acc: 99.542]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.80it/s]\u001b[0m\n",
      "[Train(  51/ 1024)-Total: 0.362|Labeled: 0.050|Unlabeled: 0.312]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  51/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.71it/s]\u001b[0m\n",
      "[Valid(  51/ 1024)-Loss: 0.424|Top1 Acc: 89.423|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test (  51/ 1024)-Loss: 0.461|Top1 Acc: 89.212|Top5 Acc: 99.582]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train(  52/ 1024)-Total: 0.363|Labeled: 0.049|Unlabeled: 0.314]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  52/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.68it/s]\u001b[0m\n",
      "[Valid(  52/ 1024)-Loss: 0.420|Top1 Acc: 89.603|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test (  52/ 1024)-Loss: 0.461|Top1 Acc: 89.242|Top5 Acc: 99.532]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train(  53/ 1024)-Total: 0.363|Labeled: 0.050|Unlabeled: 0.314]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  53/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid(  53/ 1024)-Loss: 0.426|Top1 Acc: 89.543|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.27it/s]\u001b[0m\n",
      "[Test (  53/ 1024)-Loss: 0.458|Top1 Acc: 89.271|Top5 Acc: 99.552]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.02it/s]\u001b[0m\n",
      "[Train(  54/ 1024)-Total: 0.360|Labeled: 0.052|Unlabeled: 0.308]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  54/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.84it/s]\u001b[0m\n",
      "[Valid(  54/ 1024)-Loss: 0.422|Top1 Acc: 89.683|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test (  54/ 1024)-Loss: 0.453|Top1 Acc: 89.461|Top5 Acc: 99.532]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train(  55/ 1024)-Total: 0.367|Labeled: 0.047|Unlabeled: 0.319]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  55/ 1024)-Loss: 0.001|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid(  55/ 1024)-Loss: 0.426|Top1 Acc: 89.964|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test (  55/ 1024)-Loss: 0.452|Top1 Acc: 89.480|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train(  56/ 1024)-Total: 0.369|Labeled: 0.052|Unlabeled: 0.318]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  56/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.76it/s]\u001b[0m\n",
      "[Valid(  56/ 1024)-Loss: 0.423|Top1 Acc: 89.764|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test (  56/ 1024)-Loss: 0.450|Top1 Acc: 89.520|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.10it/s]\u001b[0m\n",
      "[Train(  57/ 1024)-Total: 0.361|Labeled: 0.048|Unlabeled: 0.313]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  57/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.82it/s]\u001b[0m\n",
      "[Valid(  57/ 1024)-Loss: 0.423|Top1 Acc: 89.563|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test (  57/ 1024)-Loss: 0.450|Top1 Acc: 89.401|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train(  58/ 1024)-Total: 0.359|Labeled: 0.050|Unlabeled: 0.309]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  58/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid(  58/ 1024)-Loss: 0.420|Top1 Acc: 89.844|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test (  58/ 1024)-Loss: 0.443|Top1 Acc: 89.680|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train(  59/ 1024)-Total: 0.365|Labeled: 0.049|Unlabeled: 0.316]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  59/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid(  59/ 1024)-Loss: 0.420|Top1 Acc: 89.964|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.76it/s]\u001b[0m\n",
      "[Test (  59/ 1024)-Loss: 0.441|Top1 Acc: 89.600|Top5 Acc: 99.572]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train(  60/ 1024)-Total: 0.358|Labeled: 0.048|Unlabeled: 0.310]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train(  60/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.82it/s]\u001b[0m\n",
      "[Valid(  60/ 1024)-Loss: 0.418|Top1 Acc: 89.744|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.88it/s]\u001b[0m\n",
      "[Test (  60/ 1024)-Loss: 0.440|Top1 Acc: 89.660|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.07it/s]\u001b[0m\n",
      "[Train(  61/ 1024)-Total: 0.359|Labeled: 0.046|Unlabeled: 0.314]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  61/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.26it/s]\u001b[0m\n",
      "[Valid(  61/ 1024)-Loss: 0.420|Top1 Acc: 90.024|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.83it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test (  61/ 1024)-Loss: 0.444|Top1 Acc: 89.640|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.29it/s]\u001b[0m\n",
      "[Train(  62/ 1024)-Total: 0.365|Labeled: 0.048|Unlabeled: 0.317]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  62/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid(  62/ 1024)-Loss: 0.409|Top1 Acc: 90.325|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.12it/s]\u001b[0m\n",
      "[Test (  62/ 1024)-Loss: 0.438|Top1 Acc: 89.729|Top5 Acc: 99.572]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.26it/s]\u001b[0m\n",
      "[Train(  63/ 1024)-Total: 0.358|Labeled: 0.049|Unlabeled: 0.309]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  63/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid(  63/ 1024)-Loss: 0.411|Top1 Acc: 90.325|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test (  63/ 1024)-Loss: 0.438|Top1 Acc: 89.789|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train(  64/ 1024)-Total: 0.358|Labeled: 0.047|Unlabeled: 0.311]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  64/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid(  64/ 1024)-Loss: 0.416|Top1 Acc: 90.244|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.14it/s]\u001b[0m\n",
      "[Test (  64/ 1024)-Loss: 0.441|Top1 Acc: 89.739|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train(  65/ 1024)-Total: 0.357|Labeled: 0.050|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  65/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.78it/s]\u001b[0m\n",
      "[Valid(  65/ 1024)-Loss: 0.407|Top1 Acc: 90.445|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test (  65/ 1024)-Loss: 0.445|Top1 Acc: 89.560|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.30it/s]\u001b[0m\n",
      "[Train(  66/ 1024)-Total: 0.359|Labeled: 0.046|Unlabeled: 0.313]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train(  66/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid(  66/ 1024)-Loss: 0.404|Top1 Acc: 90.565|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.14it/s]\u001b[0m\n",
      "[Test (  66/ 1024)-Loss: 0.434|Top1 Acc: 89.829|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train(  67/ 1024)-Total: 0.354|Labeled: 0.047|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  67/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid(  67/ 1024)-Loss: 0.401|Top1 Acc: 90.224|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test (  67/ 1024)-Loss: 0.439|Top1 Acc: 89.630|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.90it/s]\u001b[0m\n",
      "[Train(  68/ 1024)-Total: 0.356|Labeled: 0.045|Unlabeled: 0.312]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  68/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid(  68/ 1024)-Loss: 0.407|Top1 Acc: 90.204|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test (  68/ 1024)-Loss: 0.441|Top1 Acc: 89.719|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train(  69/ 1024)-Total: 0.352|Labeled: 0.049|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  69/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid(  69/ 1024)-Loss: 0.408|Top1 Acc: 90.345|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.43it/s]\u001b[0m\n",
      "[Test (  69/ 1024)-Loss: 0.437|Top1 Acc: 89.759|Top5 Acc: 99.592]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train(  70/ 1024)-Total: 0.361|Labeled: 0.048|Unlabeled: 0.313]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  70/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid(  70/ 1024)-Loss: 0.410|Top1 Acc: 90.485|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test (  70/ 1024)-Loss: 0.446|Top1 Acc: 89.849|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train(  71/ 1024)-Total: 0.355|Labeled: 0.045|Unlabeled: 0.310]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  71/ 1024)-Loss: 0.001|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 24.60it/s]\u001b[0m\n",
      "[Valid(  71/ 1024)-Loss: 0.409|Top1 Acc: 90.104|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test (  71/ 1024)-Loss: 0.448|Top1 Acc: 89.699|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.08it/s]\u001b[0m\n",
      "[Train(  72/ 1024)-Total: 0.359|Labeled: 0.046|Unlabeled: 0.313]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  72/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid(  72/ 1024)-Loss: 0.401|Top1 Acc: 90.264|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test (  72/ 1024)-Loss: 0.431|Top1 Acc: 89.898|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train(  73/ 1024)-Total: 0.352|Labeled: 0.047|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  73/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid(  73/ 1024)-Loss: 0.400|Top1 Acc: 90.264|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test (  73/ 1024)-Loss: 0.425|Top1 Acc: 90.058|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train(  74/ 1024)-Total: 0.358|Labeled: 0.046|Unlabeled: 0.312]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  74/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid(  74/ 1024)-Loss: 0.403|Top1 Acc: 90.284|Top5 Acc: 99.619]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test (  74/ 1024)-Loss: 0.426|Top1 Acc: 90.127|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.88it/s]\u001b[0m\n",
      "[Train(  75/ 1024)-Total: 0.353|Labeled: 0.047|Unlabeled: 0.306]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  75/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid(  75/ 1024)-Loss: 0.400|Top1 Acc: 90.304|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test (  75/ 1024)-Loss: 0.433|Top1 Acc: 89.938|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train(  76/ 1024)-Total: 0.352|Labeled: 0.045|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  76/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid(  76/ 1024)-Loss: 0.400|Top1 Acc: 90.345|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.06it/s]\u001b[0m\n",
      "[Test (  76/ 1024)-Loss: 0.435|Top1 Acc: 90.038|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.11it/s]\u001b[0m\n",
      "[Train(  77/ 1024)-Total: 0.353|Labeled: 0.046|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  77/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.00it/s]\u001b[0m\n",
      "[Valid(  77/ 1024)-Loss: 0.403|Top1 Acc: 90.785|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test (  77/ 1024)-Loss: 0.439|Top1 Acc: 89.958|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.38it/s]\u001b[0m\n",
      "[Train(  78/ 1024)-Total: 0.353|Labeled: 0.043|Unlabeled: 0.310]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.07it/s]\u001b[0m\n",
      "[Train(  78/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.82it/s]\u001b[0m\n",
      "[Valid(  78/ 1024)-Loss: 0.401|Top1 Acc: 90.405|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.30it/s]\u001b[0m\n",
      "[Test (  78/ 1024)-Loss: 0.434|Top1 Acc: 89.938|Top5 Acc: 99.592]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.38it/s]\u001b[0m\n",
      "[Train(  79/ 1024)-Total: 0.347|Labeled: 0.044|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  79/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid(  79/ 1024)-Loss: 0.401|Top1 Acc: 90.345|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test (  79/ 1024)-Loss: 0.427|Top1 Acc: 89.978|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.29it/s]\u001b[0m\n",
      "[Train(  80/ 1024)-Total: 0.353|Labeled: 0.044|Unlabeled: 0.309]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  80/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid(  80/ 1024)-Loss: 0.394|Top1 Acc: 90.765|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test (  80/ 1024)-Loss: 0.418|Top1 Acc: 90.217|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train(  81/ 1024)-Total: 0.351|Labeled: 0.044|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  81/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.98it/s]\u001b[0m\n",
      "[Valid(  81/ 1024)-Loss: 0.393|Top1 Acc: 90.525|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.03it/s]\u001b[0m\n",
      "[Test (  81/ 1024)-Loss: 0.415|Top1 Acc: 90.416|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train(  82/ 1024)-Total: 0.353|Labeled: 0.045|Unlabeled: 0.308]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  82/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.92it/s]\u001b[0m\n",
      "[Valid(  82/ 1024)-Loss: 0.395|Top1 Acc: 90.445|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test (  82/ 1024)-Loss: 0.418|Top1 Acc: 90.217|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train(  83/ 1024)-Total: 0.355|Labeled: 0.045|Unlabeled: 0.310]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  83/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid(  83/ 1024)-Loss: 0.394|Top1 Acc: 90.345|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test (  83/ 1024)-Loss: 0.421|Top1 Acc: 90.117|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train(  84/ 1024)-Total: 0.348|Labeled: 0.045|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  84/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid(  84/ 1024)-Loss: 0.388|Top1 Acc: 90.625|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test (  84/ 1024)-Loss: 0.419|Top1 Acc: 90.297|Top5 Acc: 99.741]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train(  85/ 1024)-Total: 0.353|Labeled: 0.045|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  85/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid(  85/ 1024)-Loss: 0.386|Top1 Acc: 90.665|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test (  85/ 1024)-Loss: 0.412|Top1 Acc: 90.426|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train(  86/ 1024)-Total: 0.351|Labeled: 0.045|Unlabeled: 0.306]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  86/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid(  86/ 1024)-Loss: 0.382|Top1 Acc: 90.525|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test (  86/ 1024)-Loss: 0.409|Top1 Acc: 90.277|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.67it/s]\u001b[0m\n",
      "[Train(  87/ 1024)-Total: 0.349|Labeled: 0.045|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train(  87/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid(  87/ 1024)-Loss: 0.382|Top1 Acc: 90.605|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.90it/s]\u001b[0m\n",
      "[Test (  87/ 1024)-Loss: 0.417|Top1 Acc: 90.167|Top5 Acc: 99.731]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train(  88/ 1024)-Total: 0.349|Labeled: 0.042|Unlabeled: 0.308]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  88/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.84it/s]\u001b[0m\n",
      "[Valid(  88/ 1024)-Loss: 0.388|Top1 Acc: 90.545|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.32it/s]\u001b[0m\n",
      "[Test (  88/ 1024)-Loss: 0.414|Top1 Acc: 90.356|Top5 Acc: 99.711]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train(  89/ 1024)-Total: 0.355|Labeled: 0.047|Unlabeled: 0.309]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  89/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.66it/s]\u001b[0m\n",
      "[Valid(  89/ 1024)-Loss: 0.390|Top1 Acc: 90.445|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test (  89/ 1024)-Loss: 0.410|Top1 Acc: 90.316|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.10it/s]\u001b[0m\n",
      "[Train(  90/ 1024)-Total: 0.352|Labeled: 0.043|Unlabeled: 0.309]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  90/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.55it/s]\u001b[0m\n",
      "[Valid(  90/ 1024)-Loss: 0.379|Top1 Acc: 90.705|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test (  90/ 1024)-Loss: 0.413|Top1 Acc: 90.247|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.05it/s]\u001b[0m\n",
      "[Train(  91/ 1024)-Total: 0.350|Labeled: 0.044|Unlabeled: 0.306]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  91/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.74it/s]\u001b[0m\n",
      "[Valid(  91/ 1024)-Loss: 0.389|Top1 Acc: 90.525|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.84it/s]\u001b[0m\n",
      "[Test (  91/ 1024)-Loss: 0.417|Top1 Acc: 89.948|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.13it/s]\u001b[0m\n",
      "[Train(  92/ 1024)-Total: 0.353|Labeled: 0.045|Unlabeled: 0.308]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train(  92/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid(  92/ 1024)-Loss: 0.389|Top1 Acc: 90.705|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test (  92/ 1024)-Loss: 0.418|Top1 Acc: 90.197|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train(  93/ 1024)-Total: 0.350|Labeled: 0.043|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  93/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid(  93/ 1024)-Loss: 0.385|Top1 Acc: 90.805|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test (  93/ 1024)-Loss: 0.418|Top1 Acc: 90.098|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train(  94/ 1024)-Total: 0.349|Labeled: 0.042|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  94/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid(  94/ 1024)-Loss: 0.388|Top1 Acc: 90.885|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test (  94/ 1024)-Loss: 0.417|Top1 Acc: 90.147|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train(  95/ 1024)-Total: 0.348|Labeled: 0.044|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  95/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid(  95/ 1024)-Loss: 0.384|Top1 Acc: 91.026|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test (  95/ 1024)-Loss: 0.413|Top1 Acc: 90.098|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.58it/s]\u001b[0m\n",
      "[Train(  96/ 1024)-Total: 0.343|Labeled: 0.042|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  96/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.92it/s]\u001b[0m\n",
      "[Valid(  96/ 1024)-Loss: 0.386|Top1 Acc: 90.725|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.85it/s]\u001b[0m\n",
      "[Test (  96/ 1024)-Loss: 0.420|Top1 Acc: 90.157|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train(  97/ 1024)-Total: 0.347|Labeled: 0.044|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train(  97/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid(  97/ 1024)-Loss: 0.379|Top1 Acc: 90.805|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test (  97/ 1024)-Loss: 0.420|Top1 Acc: 90.117|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train(  98/ 1024)-Total: 0.351|Labeled: 0.042|Unlabeled: 0.308]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  98/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid(  98/ 1024)-Loss: 0.384|Top1 Acc: 90.705|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test (  98/ 1024)-Loss: 0.411|Top1 Acc: 90.307|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train(  99/ 1024)-Total: 0.351|Labeled: 0.045|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train(  99/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.52it/s]\u001b[0m\n",
      "[Valid(  99/ 1024)-Loss: 0.394|Top1 Acc: 90.445|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.49it/s]\u001b[0m\n",
      "[Test (  99/ 1024)-Loss: 0.416|Top1 Acc: 90.386|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.38it/s]\u001b[0m\n",
      "[Train( 100/ 1024)-Total: 0.353|Labeled: 0.045|Unlabeled: 0.308]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 100/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 100/ 1024)-Loss: 0.380|Top1 Acc: 90.705|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.03it/s]\u001b[0m\n",
      "[Test ( 100/ 1024)-Loss: 0.413|Top1 Acc: 90.406|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train( 101/ 1024)-Total: 0.347|Labeled: 0.042|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 101/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 101/ 1024)-Loss: 0.379|Top1 Acc: 90.505|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test ( 101/ 1024)-Loss: 0.413|Top1 Acc: 90.297|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.09it/s]\u001b[0m\n",
      "[Train( 102/ 1024)-Total: 0.345|Labeled: 0.042|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 102/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 102/ 1024)-Loss: 0.368|Top1 Acc: 90.925|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 102/ 1024)-Loss: 0.402|Top1 Acc: 90.326|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.12it/s]\u001b[0m\n",
      "[Train( 103/ 1024)-Total: 0.345|Labeled: 0.044|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 103/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.57it/s]\u001b[0m\n",
      "[Valid( 103/ 1024)-Loss: 0.374|Top1 Acc: 90.625|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 103/ 1024)-Loss: 0.404|Top1 Acc: 90.436|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 104/ 1024)-Total: 0.345|Labeled: 0.041|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 104/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 104/ 1024)-Loss: 0.386|Top1 Acc: 90.505|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 104/ 1024)-Loss: 0.410|Top1 Acc: 90.426|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 105/ 1024)-Total: 0.343|Labeled: 0.043|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 105/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid( 105/ 1024)-Loss: 0.388|Top1 Acc: 90.325|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 105/ 1024)-Loss: 0.409|Top1 Acc: 90.307|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.60it/s]\u001b[0m\n",
      "[Train( 106/ 1024)-Total: 0.343|Labeled: 0.044|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 106/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 106/ 1024)-Loss: 0.384|Top1 Acc: 90.485|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test ( 106/ 1024)-Loss: 0.409|Top1 Acc: 90.316|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 107/ 1024)-Total: 0.353|Labeled: 0.042|Unlabeled: 0.311]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 107/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.72it/s]\u001b[0m\n",
      "[Valid( 107/ 1024)-Loss: 0.382|Top1 Acc: 90.665|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.40it/s]\u001b[0m\n",
      "[Test ( 107/ 1024)-Loss: 0.408|Top1 Acc: 90.396|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 108/ 1024)-Total: 0.347|Labeled: 0.040|Unlabeled: 0.306]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 108/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 108/ 1024)-Loss: 0.390|Top1 Acc: 90.625|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.15it/s]\u001b[0m\n",
      "[Test ( 108/ 1024)-Loss: 0.410|Top1 Acc: 90.346|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 109/ 1024)-Total: 0.346|Labeled: 0.043|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 109/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.37it/s]\u001b[0m\n",
      "[Valid( 109/ 1024)-Loss: 0.378|Top1 Acc: 90.845|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 109/ 1024)-Loss: 0.403|Top1 Acc: 90.396|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train( 110/ 1024)-Total: 0.354|Labeled: 0.042|Unlabeled: 0.312]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 110/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.75it/s]\u001b[0m\n",
      "[Valid( 110/ 1024)-Loss: 0.383|Top1 Acc: 90.645|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.18it/s]\u001b[0m\n",
      "[Test ( 110/ 1024)-Loss: 0.410|Top1 Acc: 90.396|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 111/ 1024)-Total: 0.346|Labeled: 0.043|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 111/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid( 111/ 1024)-Loss: 0.380|Top1 Acc: 90.445|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 111/ 1024)-Loss: 0.405|Top1 Acc: 90.446|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train( 112/ 1024)-Total: 0.342|Labeled: 0.041|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 112/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 112/ 1024)-Loss: 0.372|Top1 Acc: 90.825|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.92it/s]\u001b[0m\n",
      "[Test ( 112/ 1024)-Loss: 0.400|Top1 Acc: 90.476|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 113/ 1024)-Total: 0.345|Labeled: 0.041|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 113/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 113/ 1024)-Loss: 0.375|Top1 Acc: 90.745|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 113/ 1024)-Loss: 0.399|Top1 Acc: 90.506|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.06it/s]\u001b[0m\n",
      "[Train( 114/ 1024)-Total: 0.346|Labeled: 0.043|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 114/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 114/ 1024)-Loss: 0.380|Top1 Acc: 90.565|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 114/ 1024)-Loss: 0.405|Top1 Acc: 90.267|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 115/ 1024)-Total: 0.345|Labeled: 0.042|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 115/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.97it/s]\u001b[0m\n",
      "[Valid( 115/ 1024)-Loss: 0.375|Top1 Acc: 90.705|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 115/ 1024)-Loss: 0.405|Top1 Acc: 90.376|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 116/ 1024)-Total: 0.344|Labeled: 0.042|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 116/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 116/ 1024)-Loss: 0.375|Top1 Acc: 91.026|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test ( 116/ 1024)-Loss: 0.409|Top1 Acc: 90.287|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.46it/s]\u001b[0m\n",
      "[Train( 117/ 1024)-Total: 0.341|Labeled: 0.040|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 117/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.84it/s]\u001b[0m\n",
      "[Valid( 117/ 1024)-Loss: 0.369|Top1 Acc: 90.885|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test ( 117/ 1024)-Loss: 0.405|Top1 Acc: 90.466|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 118/ 1024)-Total: 0.346|Labeled: 0.042|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 118/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid( 118/ 1024)-Loss: 0.366|Top1 Acc: 91.026|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 118/ 1024)-Loss: 0.405|Top1 Acc: 90.516|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 119/ 1024)-Total: 0.343|Labeled: 0.040|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 119/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.70it/s]\u001b[0m\n",
      "[Valid( 119/ 1024)-Loss: 0.369|Top1 Acc: 90.745|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 119/ 1024)-Loss: 0.403|Top1 Acc: 90.396|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 120/ 1024)-Total: 0.341|Labeled: 0.041|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 120/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.84it/s]\u001b[0m\n",
      "[Valid( 120/ 1024)-Loss: 0.370|Top1 Acc: 90.665|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.92it/s]\u001b[0m\n",
      "[Test ( 120/ 1024)-Loss: 0.397|Top1 Acc: 90.476|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 121/ 1024)-Total: 0.348|Labeled: 0.043|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 121/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 121/ 1024)-Loss: 0.384|Top1 Acc: 90.925|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 121/ 1024)-Loss: 0.396|Top1 Acc: 90.486|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.07it/s]\u001b[0m\n",
      "[Train( 122/ 1024)-Total: 0.341|Labeled: 0.040|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 122/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 122/ 1024)-Loss: 0.376|Top1 Acc: 90.946|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test ( 122/ 1024)-Loss: 0.392|Top1 Acc: 90.764|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 123/ 1024)-Total: 0.347|Labeled: 0.042|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 123/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 123/ 1024)-Loss: 0.374|Top1 Acc: 90.865|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.06it/s]\u001b[0m\n",
      "[Test ( 123/ 1024)-Loss: 0.399|Top1 Acc: 90.516|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 124/ 1024)-Total: 0.344|Labeled: 0.040|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 124/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 124/ 1024)-Loss: 0.371|Top1 Acc: 90.946|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.12it/s]\u001b[0m\n",
      "[Test ( 124/ 1024)-Loss: 0.399|Top1 Acc: 90.316|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.94it/s]\u001b[0m\n",
      "[Train( 125/ 1024)-Total: 0.343|Labeled: 0.041|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 125/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 125/ 1024)-Loss: 0.364|Top1 Acc: 90.805|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 125/ 1024)-Loss: 0.403|Top1 Acc: 90.267|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 126/ 1024)-Total: 0.347|Labeled: 0.042|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 126/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid( 126/ 1024)-Loss: 0.375|Top1 Acc: 90.825|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.54it/s]\u001b[0m\n",
      "[Test ( 126/ 1024)-Loss: 0.403|Top1 Acc: 90.247|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.09it/s]\u001b[0m\n",
      "[Train( 127/ 1024)-Total: 0.340|Labeled: 0.037|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 127/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 127/ 1024)-Loss: 0.369|Top1 Acc: 91.066|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.20it/s]\u001b[0m\n",
      "[Test ( 127/ 1024)-Loss: 0.400|Top1 Acc: 90.307|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.29it/s]\u001b[0m\n",
      "[Train( 128/ 1024)-Total: 0.346|Labeled: 0.039|Unlabeled: 0.307]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 128/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.42it/s]\u001b[0m\n",
      "[Valid( 128/ 1024)-Loss: 0.366|Top1 Acc: 91.186|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 128/ 1024)-Loss: 0.393|Top1 Acc: 90.516|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 129/ 1024)-Total: 0.343|Labeled: 0.042|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 129/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 129/ 1024)-Loss: 0.366|Top1 Acc: 91.006|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.91it/s]\u001b[0m\n",
      "[Test ( 129/ 1024)-Loss: 0.393|Top1 Acc: 90.496|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 130/ 1024)-Total: 0.342|Labeled: 0.040|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 130/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.73it/s]\u001b[0m\n",
      "[Valid( 130/ 1024)-Loss: 0.365|Top1 Acc: 90.785|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 130/ 1024)-Loss: 0.395|Top1 Acc: 90.426|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 131/ 1024)-Total: 0.344|Labeled: 0.040|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.02it/s]\u001b[0m\n",
      "[Train( 131/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 131/ 1024)-Loss: 0.365|Top1 Acc: 90.785|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 131/ 1024)-Loss: 0.395|Top1 Acc: 90.685|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 132/ 1024)-Total: 0.344|Labeled: 0.043|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 132/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 132/ 1024)-Loss: 0.358|Top1 Acc: 91.066|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 132/ 1024)-Loss: 0.389|Top1 Acc: 90.924|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 133/ 1024)-Total: 0.340|Labeled: 0.041|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 133/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 133/ 1024)-Loss: 0.360|Top1 Acc: 90.905|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 133/ 1024)-Loss: 0.394|Top1 Acc: 90.715|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.68it/s]\u001b[0m\n",
      "[Train( 134/ 1024)-Total: 0.345|Labeled: 0.041|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 134/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.97it/s]\u001b[0m\n",
      "[Valid( 134/ 1024)-Loss: 0.367|Top1 Acc: 90.925|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test ( 134/ 1024)-Loss: 0.400|Top1 Acc: 90.535|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 135/ 1024)-Total: 0.337|Labeled: 0.041|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 135/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid( 135/ 1024)-Loss: 0.368|Top1 Acc: 91.206|Top5 Acc: 99.639]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 135/ 1024)-Loss: 0.397|Top1 Acc: 90.486|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 136/ 1024)-Total: 0.339|Labeled: 0.041|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 136/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 136/ 1024)-Loss: 0.367|Top1 Acc: 91.246|Top5 Acc: 99.659]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 136/ 1024)-Loss: 0.402|Top1 Acc: 90.784|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 137/ 1024)-Total: 0.339|Labeled: 0.041|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 137/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid( 137/ 1024)-Loss: 0.357|Top1 Acc: 91.346|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 137/ 1024)-Loss: 0.399|Top1 Acc: 90.764|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 138/ 1024)-Total: 0.338|Labeled: 0.039|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 138/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 138/ 1024)-Loss: 0.354|Top1 Acc: 91.386|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 138/ 1024)-Loss: 0.403|Top1 Acc: 90.535|Top5 Acc: 99.592]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.33it/s]\u001b[0m\n",
      "[Train( 139/ 1024)-Total: 0.345|Labeled: 0.040|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 139/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 139/ 1024)-Loss: 0.356|Top1 Acc: 91.306|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test ( 139/ 1024)-Loss: 0.402|Top1 Acc: 90.565|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.26it/s]\u001b[0m\n",
      "[Train( 140/ 1024)-Total: 0.346|Labeled: 0.041|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 140/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.01it/s]\u001b[0m\n",
      "[Valid( 140/ 1024)-Loss: 0.361|Top1 Acc: 90.825|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 140/ 1024)-Loss: 0.395|Top1 Acc: 90.705|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.26it/s]\u001b[0m\n",
      "[Train( 141/ 1024)-Total: 0.341|Labeled: 0.039|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 141/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 141/ 1024)-Loss: 0.356|Top1 Acc: 90.946|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 141/ 1024)-Loss: 0.392|Top1 Acc: 90.804|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 142/ 1024)-Total: 0.343|Labeled: 0.038|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 142/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.97it/s]\u001b[0m\n",
      "[Valid( 142/ 1024)-Loss: 0.355|Top1 Acc: 90.925|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 142/ 1024)-Loss: 0.394|Top1 Acc: 90.804|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 143/ 1024)-Total: 0.342|Labeled: 0.040|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 143/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 143/ 1024)-Loss: 0.349|Top1 Acc: 91.346|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 143/ 1024)-Loss: 0.388|Top1 Acc: 90.804|Top5 Acc: 99.592]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.71it/s]\u001b[0m\n",
      "[Train( 144/ 1024)-Total: 0.337|Labeled: 0.039|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 144/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.66it/s]\u001b[0m\n",
      "[Valid( 144/ 1024)-Loss: 0.355|Top1 Acc: 91.286|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 144/ 1024)-Loss: 0.395|Top1 Acc: 90.854|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 145/ 1024)-Total: 0.338|Labeled: 0.039|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 145/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.69it/s]\u001b[0m\n",
      "[Valid( 145/ 1024)-Loss: 0.354|Top1 Acc: 91.246|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.51it/s]\u001b[0m\n",
      "[Test ( 145/ 1024)-Loss: 0.394|Top1 Acc: 90.625|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.11it/s]\u001b[0m\n",
      "[Train( 146/ 1024)-Total: 0.346|Labeled: 0.041|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 146/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid( 146/ 1024)-Loss: 0.361|Top1 Acc: 91.026|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 146/ 1024)-Loss: 0.392|Top1 Acc: 90.595|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 147/ 1024)-Total: 0.341|Labeled: 0.042|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 147/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.42it/s]\u001b[0m\n",
      "[Valid( 147/ 1024)-Loss: 0.363|Top1 Acc: 90.885|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 147/ 1024)-Loss: 0.388|Top1 Acc: 90.824|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 148/ 1024)-Total: 0.341|Labeled: 0.040|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 148/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 148/ 1024)-Loss: 0.362|Top1 Acc: 91.286|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.14it/s]\u001b[0m\n",
      "[Test ( 148/ 1024)-Loss: 0.390|Top1 Acc: 90.744|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.10it/s]\u001b[0m\n",
      "[Train( 149/ 1024)-Total: 0.339|Labeled: 0.039|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 149/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.92it/s]\u001b[0m\n",
      "[Valid( 149/ 1024)-Loss: 0.351|Top1 Acc: 91.466|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 149/ 1024)-Loss: 0.389|Top1 Acc: 90.844|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 150/ 1024)-Total: 0.340|Labeled: 0.038|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 150/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 150/ 1024)-Loss: 0.350|Top1 Acc: 91.366|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.88it/s]\u001b[0m\n",
      "[Test ( 150/ 1024)-Loss: 0.391|Top1 Acc: 90.734|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.07it/s]\u001b[0m\n",
      "[Train( 151/ 1024)-Total: 0.336|Labeled: 0.039|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 151/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 151/ 1024)-Loss: 0.351|Top1 Acc: 91.206|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.72it/s]\u001b[0m\n",
      "[Test ( 151/ 1024)-Loss: 0.392|Top1 Acc: 90.754|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 152/ 1024)-Total: 0.345|Labeled: 0.041|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.01it/s]\u001b[0m\n",
      "[Train( 152/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.69it/s]\u001b[0m\n",
      "[Valid( 152/ 1024)-Loss: 0.355|Top1 Acc: 91.206|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 152/ 1024)-Loss: 0.390|Top1 Acc: 90.774|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.07it/s]\u001b[0m\n",
      "[Train( 153/ 1024)-Total: 0.342|Labeled: 0.040|Unlabeled: 0.302]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 153/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 153/ 1024)-Loss: 0.352|Top1 Acc: 91.226|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.19it/s]\u001b[0m\n",
      "[Test ( 153/ 1024)-Loss: 0.386|Top1 Acc: 90.864|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train( 154/ 1024)-Total: 0.340|Labeled: 0.039|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 154/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.33it/s]\u001b[0m\n",
      "[Valid( 154/ 1024)-Loss: 0.350|Top1 Acc: 91.366|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.19it/s]\u001b[0m\n",
      "[Test ( 154/ 1024)-Loss: 0.388|Top1 Acc: 90.844|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train( 155/ 1024)-Total: 0.336|Labeled: 0.039|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 155/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 155/ 1024)-Loss: 0.355|Top1 Acc: 91.286|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test ( 155/ 1024)-Loss: 0.389|Top1 Acc: 90.784|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.31it/s]\u001b[0m\n",
      "[Train( 156/ 1024)-Total: 0.340|Labeled: 0.039|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 156/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.75it/s]\u001b[0m\n",
      "[Valid( 156/ 1024)-Loss: 0.354|Top1 Acc: 91.106|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.08it/s]\u001b[0m\n",
      "[Test ( 156/ 1024)-Loss: 0.386|Top1 Acc: 90.705|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train( 157/ 1024)-Total: 0.339|Labeled: 0.040|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 157/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.97it/s]\u001b[0m\n",
      "[Valid( 157/ 1024)-Loss: 0.352|Top1 Acc: 91.206|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 157/ 1024)-Loss: 0.384|Top1 Acc: 90.834|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 158/ 1024)-Total: 0.344|Labeled: 0.039|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 158/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 158/ 1024)-Loss: 0.353|Top1 Acc: 91.206|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 158/ 1024)-Loss: 0.391|Top1 Acc: 90.764|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 159/ 1024)-Total: 0.342|Labeled: 0.042|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 159/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 159/ 1024)-Loss: 0.348|Top1 Acc: 91.466|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 159/ 1024)-Loss: 0.384|Top1 Acc: 90.655|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train( 160/ 1024)-Total: 0.338|Labeled: 0.038|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 160/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 160/ 1024)-Loss: 0.355|Top1 Acc: 91.466|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.11it/s]\u001b[0m\n",
      "[Test ( 160/ 1024)-Loss: 0.389|Top1 Acc: 90.715|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.67it/s]\u001b[0m\n",
      "[Train( 161/ 1024)-Total: 0.339|Labeled: 0.040|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 161/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.78it/s]\u001b[0m\n",
      "[Valid( 161/ 1024)-Loss: 0.356|Top1 Acc: 91.386|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test ( 161/ 1024)-Loss: 0.388|Top1 Acc: 90.834|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 162/ 1024)-Total: 0.340|Labeled: 0.040|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 162/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid( 162/ 1024)-Loss: 0.358|Top1 Acc: 91.266|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 162/ 1024)-Loss: 0.390|Top1 Acc: 90.874|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.87it/s]\u001b[0m\n",
      "[Train( 163/ 1024)-Total: 0.341|Labeled: 0.038|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 163/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.02it/s]\u001b[0m\n",
      "[Valid( 163/ 1024)-Loss: 0.362|Top1 Acc: 91.286|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 163/ 1024)-Loss: 0.391|Top1 Acc: 90.744|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 164/ 1024)-Total: 0.344|Labeled: 0.040|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 164/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.41it/s]\u001b[0m\n",
      "[Valid( 164/ 1024)-Loss: 0.357|Top1 Acc: 91.266|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 164/ 1024)-Loss: 0.387|Top1 Acc: 90.894|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 165/ 1024)-Total: 0.338|Labeled: 0.039|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 165/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.73it/s]\u001b[0m\n",
      "[Valid( 165/ 1024)-Loss: 0.361|Top1 Acc: 91.106|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 165/ 1024)-Loss: 0.389|Top1 Acc: 90.655|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.11it/s]\u001b[0m\n",
      "[Train( 166/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 166/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.01it/s]\u001b[0m\n",
      "[Valid( 166/ 1024)-Loss: 0.359|Top1 Acc: 91.406|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 166/ 1024)-Loss: 0.384|Top1 Acc: 90.625|Top5 Acc: 99.741]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 167/ 1024)-Total: 0.332|Labeled: 0.038|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 167/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 167/ 1024)-Loss: 0.349|Top1 Acc: 91.486|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.87it/s]\u001b[0m\n",
      "[Test ( 167/ 1024)-Loss: 0.381|Top1 Acc: 90.834|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.12it/s]\u001b[0m\n",
      "[Train( 168/ 1024)-Total: 0.339|Labeled: 0.042|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 168/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.71it/s]\u001b[0m\n",
      "[Valid( 168/ 1024)-Loss: 0.352|Top1 Acc: 91.546|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 168/ 1024)-Loss: 0.385|Top1 Acc: 90.953|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.38it/s]\u001b[0m\n",
      "[Train( 169/ 1024)-Total: 0.339|Labeled: 0.039|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 169/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 169/ 1024)-Loss: 0.351|Top1 Acc: 91.587|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.03it/s]\u001b[0m\n",
      "[Test ( 169/ 1024)-Loss: 0.382|Top1 Acc: 90.953|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train( 170/ 1024)-Total: 0.334|Labeled: 0.038|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 170/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 170/ 1024)-Loss: 0.347|Top1 Acc: 91.587|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 170/ 1024)-Loss: 0.384|Top1 Acc: 90.675|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train( 171/ 1024)-Total: 0.333|Labeled: 0.038|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 171/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 171/ 1024)-Loss: 0.352|Top1 Acc: 91.426|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.67it/s]\u001b[0m\n",
      "[Test ( 171/ 1024)-Loss: 0.389|Top1 Acc: 90.744|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.83it/s]\u001b[0m\n",
      "[Train( 172/ 1024)-Total: 0.340|Labeled: 0.039|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 172/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.74it/s]\u001b[0m\n",
      "[Valid( 172/ 1024)-Loss: 0.356|Top1 Acc: 91.186|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.84it/s]\u001b[0m\n",
      "[Test ( 172/ 1024)-Loss: 0.386|Top1 Acc: 90.844|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.26it/s]\u001b[0m\n",
      "[Train( 173/ 1024)-Total: 0.340|Labeled: 0.037|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 173/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 173/ 1024)-Loss: 0.349|Top1 Acc: 91.526|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 173/ 1024)-Loss: 0.390|Top1 Acc: 90.565|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 174/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 174/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.92it/s]\u001b[0m\n",
      "[Valid( 174/ 1024)-Loss: 0.355|Top1 Acc: 91.346|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 174/ 1024)-Loss: 0.398|Top1 Acc: 90.695|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train( 175/ 1024)-Total: 0.340|Labeled: 0.040|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 175/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid( 175/ 1024)-Loss: 0.358|Top1 Acc: 91.306|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 175/ 1024)-Loss: 0.392|Top1 Acc: 90.744|Top5 Acc: 99.582]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train( 176/ 1024)-Total: 0.342|Labeled: 0.041|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 176/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 176/ 1024)-Loss: 0.361|Top1 Acc: 90.925|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.06it/s]\u001b[0m\n",
      "[Test ( 176/ 1024)-Loss: 0.394|Top1 Acc: 90.814|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.09it/s]\u001b[0m\n",
      "[Train( 177/ 1024)-Total: 0.338|Labeled: 0.040|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 177/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 177/ 1024)-Loss: 0.360|Top1 Acc: 91.186|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 177/ 1024)-Loss: 0.391|Top1 Acc: 90.804|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 178/ 1024)-Total: 0.334|Labeled: 0.038|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 178/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 178/ 1024)-Loss: 0.349|Top1 Acc: 91.426|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 178/ 1024)-Loss: 0.384|Top1 Acc: 90.894|Top5 Acc: 99.572]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 179/ 1024)-Total: 0.337|Labeled: 0.037|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 179/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 179/ 1024)-Loss: 0.346|Top1 Acc: 91.366|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.86it/s]\u001b[0m\n",
      "[Test ( 179/ 1024)-Loss: 0.390|Top1 Acc: 90.943|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.82it/s]\u001b[0m\n",
      "[Train( 180/ 1024)-Total: 0.342|Labeled: 0.039|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 180/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 180/ 1024)-Loss: 0.343|Top1 Acc: 91.306|Top5 Acc: 99.679]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 180/ 1024)-Loss: 0.389|Top1 Acc: 90.824|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 181/ 1024)-Total: 0.328|Labeled: 0.037|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 181/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 181/ 1024)-Loss: 0.345|Top1 Acc: 91.246|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.17it/s]\u001b[0m\n",
      "[Test ( 181/ 1024)-Loss: 0.380|Top1 Acc: 91.053|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 182/ 1024)-Total: 0.340|Labeled: 0.038|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 182/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 182/ 1024)-Loss: 0.345|Top1 Acc: 91.206|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 182/ 1024)-Loss: 0.380|Top1 Acc: 90.973|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 183/ 1024)-Total: 0.334|Labeled: 0.037|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 183/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid( 183/ 1024)-Loss: 0.348|Top1 Acc: 91.266|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test ( 183/ 1024)-Loss: 0.385|Top1 Acc: 91.083|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 184/ 1024)-Total: 0.340|Labeled: 0.037|Unlabeled: 0.303]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 184/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 184/ 1024)-Loss: 0.344|Top1 Acc: 91.246|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.14it/s]\u001b[0m\n",
      "[Test ( 184/ 1024)-Loss: 0.391|Top1 Acc: 91.003|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 185/ 1024)-Total: 0.344|Labeled: 0.039|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 185/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 185/ 1024)-Loss: 0.349|Top1 Acc: 91.186|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 185/ 1024)-Loss: 0.383|Top1 Acc: 91.192|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train( 186/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 186/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 186/ 1024)-Loss: 0.345|Top1 Acc: 91.386|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test ( 186/ 1024)-Loss: 0.385|Top1 Acc: 91.023|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 187/ 1024)-Total: 0.340|Labeled: 0.039|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 187/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 187/ 1024)-Loss: 0.344|Top1 Acc: 91.426|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 187/ 1024)-Loss: 0.393|Top1 Acc: 90.705|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 188/ 1024)-Total: 0.339|Labeled: 0.037|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 188/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 188/ 1024)-Loss: 0.351|Top1 Acc: 91.266|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.17it/s]\u001b[0m\n",
      "[Test ( 188/ 1024)-Loss: 0.385|Top1 Acc: 90.874|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.67it/s]\u001b[0m\n",
      "[Train( 189/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 189/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 189/ 1024)-Loss: 0.346|Top1 Acc: 91.587|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 189/ 1024)-Loss: 0.390|Top1 Acc: 90.645|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 190/ 1024)-Total: 0.337|Labeled: 0.040|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 190/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 190/ 1024)-Loss: 0.343|Top1 Acc: 91.727|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 190/ 1024)-Loss: 0.389|Top1 Acc: 90.844|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 191/ 1024)-Total: 0.337|Labeled: 0.037|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 191/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.98it/s]\u001b[0m\n",
      "[Valid( 191/ 1024)-Loss: 0.342|Top1 Acc: 91.687|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test ( 191/ 1024)-Loss: 0.392|Top1 Acc: 90.943|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 192/ 1024)-Total: 0.335|Labeled: 0.037|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 192/ 1024)-Loss: 0.001|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 24.43it/s]\u001b[0m\n",
      "[Valid( 192/ 1024)-Loss: 0.340|Top1 Acc: 91.546|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 192/ 1024)-Loss: 0.383|Top1 Acc: 90.914|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 193/ 1024)-Total: 0.340|Labeled: 0.039|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 193/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 193/ 1024)-Loss: 0.355|Top1 Acc: 91.366|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 193/ 1024)-Loss: 0.394|Top1 Acc: 90.983|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 194/ 1024)-Total: 0.342|Labeled: 0.037|Unlabeled: 0.305]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 194/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 194/ 1024)-Loss: 0.353|Top1 Acc: 91.226|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 194/ 1024)-Loss: 0.389|Top1 Acc: 90.804|Top5 Acc: 99.582]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 195/ 1024)-Total: 0.334|Labeled: 0.038|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 195/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.99it/s]\u001b[0m\n",
      "[Valid( 195/ 1024)-Loss: 0.345|Top1 Acc: 91.587|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 195/ 1024)-Loss: 0.389|Top1 Acc: 90.764|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 196/ 1024)-Total: 0.339|Labeled: 0.040|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 196/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 196/ 1024)-Loss: 0.343|Top1 Acc: 91.607|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 196/ 1024)-Loss: 0.389|Top1 Acc: 90.754|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 197/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 197/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 197/ 1024)-Loss: 0.342|Top1 Acc: 91.567|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 197/ 1024)-Loss: 0.386|Top1 Acc: 90.725|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.05it/s]\u001b[0m\n",
      "[Train( 198/ 1024)-Total: 0.335|Labeled: 0.038|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 198/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.00it/s]\u001b[0m\n",
      "[Valid( 198/ 1024)-Loss: 0.342|Top1 Acc: 91.366|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 198/ 1024)-Loss: 0.384|Top1 Acc: 90.675|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.69it/s]\u001b[0m\n",
      "[Train( 199/ 1024)-Total: 0.336|Labeled: 0.038|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 199/ 1024)-Loss: 0.001|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 199/ 1024)-Loss: 0.336|Top1 Acc: 91.707|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 199/ 1024)-Loss: 0.381|Top1 Acc: 90.744|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.31it/s]\u001b[0m\n",
      "[Train( 200/ 1024)-Total: 0.339|Labeled: 0.039|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 200/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.49it/s]\u001b[0m\n",
      "[Valid( 200/ 1024)-Loss: 0.342|Top1 Acc: 91.647|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 200/ 1024)-Loss: 0.379|Top1 Acc: 90.874|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.09it/s]\u001b[0m\n",
      "[Train( 201/ 1024)-Total: 0.336|Labeled: 0.035|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 201/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 201/ 1024)-Loss: 0.340|Top1 Acc: 91.386|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 201/ 1024)-Loss: 0.376|Top1 Acc: 91.152|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.26it/s]\u001b[0m\n",
      "[Train( 202/ 1024)-Total: 0.333|Labeled: 0.038|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 202/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.01it/s]\u001b[0m\n",
      "[Valid( 202/ 1024)-Loss: 0.352|Top1 Acc: 91.206|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test ( 202/ 1024)-Loss: 0.382|Top1 Acc: 90.904|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 203/ 1024)-Total: 0.339|Labeled: 0.038|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 203/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.82it/s]\u001b[0m\n",
      "[Valid( 203/ 1024)-Loss: 0.344|Top1 Acc: 91.406|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 203/ 1024)-Loss: 0.385|Top1 Acc: 91.053|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.19it/s]\u001b[0m\n",
      "[Train( 204/ 1024)-Total: 0.334|Labeled: 0.036|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 204/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 204/ 1024)-Loss: 0.350|Top1 Acc: 91.066|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 204/ 1024)-Loss: 0.381|Top1 Acc: 90.943|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 205/ 1024)-Total: 0.339|Labeled: 0.039|Unlabeled: 0.301]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:21<00:00,  5.08it/s]\u001b[0m\n",
      "[Train( 205/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.00it/s]\u001b[0m\n",
      "[Valid( 205/ 1024)-Loss: 0.350|Top1 Acc: 90.966|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 205/ 1024)-Loss: 0.376|Top1 Acc: 90.983|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 206/ 1024)-Total: 0.331|Labeled: 0.038|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 206/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 206/ 1024)-Loss: 0.345|Top1 Acc: 91.587|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 206/ 1024)-Loss: 0.377|Top1 Acc: 91.172|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.10it/s]\u001b[0m\n",
      "[Train( 207/ 1024)-Total: 0.335|Labeled: 0.036|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 207/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 207/ 1024)-Loss: 0.343|Top1 Acc: 91.787|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 207/ 1024)-Loss: 0.372|Top1 Acc: 91.113|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 208/ 1024)-Total: 0.334|Labeled: 0.038|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 208/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid( 208/ 1024)-Loss: 0.342|Top1 Acc: 91.787|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.91it/s]\u001b[0m\n",
      "[Test ( 208/ 1024)-Loss: 0.374|Top1 Acc: 90.963|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 209/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 209/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 209/ 1024)-Loss: 0.341|Top1 Acc: 91.847|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.10it/s]\u001b[0m\n",
      "[Test ( 209/ 1024)-Loss: 0.373|Top1 Acc: 90.993|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 210/ 1024)-Total: 0.334|Labeled: 0.037|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 210/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 210/ 1024)-Loss: 0.339|Top1 Acc: 91.767|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 210/ 1024)-Loss: 0.378|Top1 Acc: 91.083|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 211/ 1024)-Total: 0.331|Labeled: 0.035|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 211/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 211/ 1024)-Loss: 0.332|Top1 Acc: 92.007|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.84it/s]\u001b[0m\n",
      "[Test ( 211/ 1024)-Loss: 0.379|Top1 Acc: 91.222|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.09it/s]\u001b[0m\n",
      "[Train( 212/ 1024)-Total: 0.334|Labeled: 0.037|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 212/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 212/ 1024)-Loss: 0.337|Top1 Acc: 91.787|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.89it/s]\u001b[0m\n",
      "[Test ( 212/ 1024)-Loss: 0.377|Top1 Acc: 91.113|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.12it/s]\u001b[0m\n",
      "[Train( 213/ 1024)-Total: 0.334|Labeled: 0.038|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 213/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 213/ 1024)-Loss: 0.340|Top1 Acc: 91.526|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.86it/s]\u001b[0m\n",
      "[Test ( 213/ 1024)-Loss: 0.376|Top1 Acc: 91.252|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 214/ 1024)-Total: 0.335|Labeled: 0.037|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 214/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 214/ 1024)-Loss: 0.343|Top1 Acc: 91.767|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.06it/s]\u001b[0m\n",
      "[Test ( 214/ 1024)-Loss: 0.375|Top1 Acc: 91.212|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.30it/s]\u001b[0m\n",
      "[Train( 215/ 1024)-Total: 0.333|Labeled: 0.037|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 215/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.99it/s]\u001b[0m\n",
      "[Valid( 215/ 1024)-Loss: 0.337|Top1 Acc: 91.567|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.08it/s]\u001b[0m\n",
      "[Test ( 215/ 1024)-Loss: 0.373|Top1 Acc: 90.943|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.30it/s]\u001b[0m\n",
      "[Train( 216/ 1024)-Total: 0.330|Labeled: 0.038|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 216/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 216/ 1024)-Loss: 0.339|Top1 Acc: 91.627|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 216/ 1024)-Loss: 0.373|Top1 Acc: 91.222|Top5 Acc: 99.602]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 217/ 1024)-Total: 0.331|Labeled: 0.037|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 217/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 217/ 1024)-Loss: 0.350|Top1 Acc: 91.546|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 217/ 1024)-Loss: 0.379|Top1 Acc: 91.083|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.92it/s]\u001b[0m\n",
      "[Train( 218/ 1024)-Total: 0.328|Labeled: 0.036|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 218/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.74it/s]\u001b[0m\n",
      "[Valid( 218/ 1024)-Loss: 0.344|Top1 Acc: 91.707|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 218/ 1024)-Loss: 0.379|Top1 Acc: 91.063|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 219/ 1024)-Total: 0.332|Labeled: 0.036|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 219/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 219/ 1024)-Loss: 0.347|Top1 Acc: 91.627|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.31it/s]\u001b[0m\n",
      "[Test ( 219/ 1024)-Loss: 0.381|Top1 Acc: 90.953|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 220/ 1024)-Total: 0.326|Labeled: 0.035|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 220/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 220/ 1024)-Loss: 0.333|Top1 Acc: 91.787|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.01it/s]\u001b[0m\n",
      "[Test ( 220/ 1024)-Loss: 0.378|Top1 Acc: 91.113|Top5 Acc: 99.572]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 221/ 1024)-Total: 0.333|Labeled: 0.037|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 221/ 1024)-Loss: 0.001|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 24.29it/s]\u001b[0m\n",
      "[Valid( 221/ 1024)-Loss: 0.333|Top1 Acc: 91.587|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 221/ 1024)-Loss: 0.370|Top1 Acc: 91.202|Top5 Acc: 99.572]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 222/ 1024)-Total: 0.336|Labeled: 0.037|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 222/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 222/ 1024)-Loss: 0.336|Top1 Acc: 91.406|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test ( 222/ 1024)-Loss: 0.374|Top1 Acc: 91.182|Top5 Acc: 99.582]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 223/ 1024)-Total: 0.334|Labeled: 0.036|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 223/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid( 223/ 1024)-Loss: 0.342|Top1 Acc: 91.386|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 223/ 1024)-Loss: 0.374|Top1 Acc: 91.342|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 224/ 1024)-Total: 0.331|Labeled: 0.034|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 224/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 224/ 1024)-Loss: 0.339|Top1 Acc: 91.506|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n",
      "[Test ( 224/ 1024)-Loss: 0.368|Top1 Acc: 91.232|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 225/ 1024)-Total: 0.334|Labeled: 0.037|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 225/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.75it/s]\u001b[0m\n",
      "[Valid( 225/ 1024)-Loss: 0.346|Top1 Acc: 91.306|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 225/ 1024)-Loss: 0.371|Top1 Acc: 91.023|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.05it/s]\u001b[0m\n",
      "[Train( 226/ 1024)-Total: 0.335|Labeled: 0.036|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 226/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid( 226/ 1024)-Loss: 0.344|Top1 Acc: 91.446|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.00it/s]\u001b[0m\n",
      "[Test ( 226/ 1024)-Loss: 0.374|Top1 Acc: 91.003|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.57it/s]\u001b[0m\n",
      "[Train( 227/ 1024)-Total: 0.329|Labeled: 0.036|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 227/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.67it/s]\u001b[0m\n",
      "[Valid( 227/ 1024)-Loss: 0.340|Top1 Acc: 91.647|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.88it/s]\u001b[0m\n",
      "[Test ( 227/ 1024)-Loss: 0.376|Top1 Acc: 91.043|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 228/ 1024)-Total: 0.337|Labeled: 0.039|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 228/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 228/ 1024)-Loss: 0.346|Top1 Acc: 91.627|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.92it/s]\u001b[0m\n",
      "[Test ( 228/ 1024)-Loss: 0.369|Top1 Acc: 91.043|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.10it/s]\u001b[0m\n",
      "[Train( 229/ 1024)-Total: 0.331|Labeled: 0.036|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 229/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 229/ 1024)-Loss: 0.347|Top1 Acc: 91.687|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.16it/s]\u001b[0m\n",
      "[Test ( 229/ 1024)-Loss: 0.367|Top1 Acc: 91.162|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.30it/s]\u001b[0m\n",
      "[Train( 230/ 1024)-Total: 0.332|Labeled: 0.039|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 230/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.36it/s]\u001b[0m\n",
      "[Valid( 230/ 1024)-Loss: 0.340|Top1 Acc: 91.627|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.11it/s]\u001b[0m\n",
      "[Test ( 230/ 1024)-Loss: 0.363|Top1 Acc: 91.123|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train( 231/ 1024)-Total: 0.334|Labeled: 0.035|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 231/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 231/ 1024)-Loss: 0.343|Top1 Acc: 91.667|Top5 Acc: 99.700]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 231/ 1024)-Loss: 0.368|Top1 Acc: 91.152|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train( 232/ 1024)-Total: 0.332|Labeled: 0.035|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 232/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.00it/s]\u001b[0m\n",
      "[Valid( 232/ 1024)-Loss: 0.345|Top1 Acc: 91.506|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test ( 232/ 1024)-Loss: 0.370|Top1 Acc: 91.162|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 233/ 1024)-Total: 0.331|Labeled: 0.037|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 233/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 233/ 1024)-Loss: 0.339|Top1 Acc: 91.627|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.11it/s]\u001b[0m\n",
      "[Test ( 233/ 1024)-Loss: 0.367|Top1 Acc: 91.252|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.29it/s]\u001b[0m\n",
      "[Train( 234/ 1024)-Total: 0.337|Labeled: 0.038|Unlabeled: 0.299]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 234/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.72it/s]\u001b[0m\n",
      "[Valid( 234/ 1024)-Loss: 0.346|Top1 Acc: 91.807|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test ( 234/ 1024)-Loss: 0.366|Top1 Acc: 91.172|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.28it/s]\u001b[0m\n",
      "[Train( 235/ 1024)-Total: 0.334|Labeled: 0.037|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.00it/s]\u001b[0m\n",
      "[Train( 235/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.85it/s]\u001b[0m\n",
      "[Valid( 235/ 1024)-Loss: 0.351|Top1 Acc: 91.406|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.07it/s]\u001b[0m\n",
      "[Test ( 235/ 1024)-Loss: 0.371|Top1 Acc: 91.192|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.14it/s]\u001b[0m\n",
      "[Train( 236/ 1024)-Total: 0.330|Labeled: 0.035|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 236/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.77it/s]\u001b[0m\n",
      "[Valid( 236/ 1024)-Loss: 0.350|Top1 Acc: 91.186|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 236/ 1024)-Loss: 0.370|Top1 Acc: 91.113|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.73it/s]\u001b[0m\n",
      "[Train( 237/ 1024)-Total: 0.331|Labeled: 0.037|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 237/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 237/ 1024)-Loss: 0.349|Top1 Acc: 91.306|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 237/ 1024)-Loss: 0.369|Top1 Acc: 91.023|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.13it/s]\u001b[0m\n",
      "[Train( 238/ 1024)-Total: 0.331|Labeled: 0.035|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 238/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.43it/s]\u001b[0m\n",
      "[Valid( 238/ 1024)-Loss: 0.347|Top1 Acc: 91.687|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.00it/s]\u001b[0m\n",
      "[Test ( 238/ 1024)-Loss: 0.372|Top1 Acc: 91.093|Top5 Acc: 99.721]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 239/ 1024)-Total: 0.341|Labeled: 0.037|Unlabeled: 0.304]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 239/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 239/ 1024)-Loss: 0.341|Top1 Acc: 91.687|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.96it/s]\u001b[0m\n",
      "[Test ( 239/ 1024)-Loss: 0.374|Top1 Acc: 91.083|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.12it/s]\u001b[0m\n",
      "[Train( 240/ 1024)-Total: 0.329|Labeled: 0.036|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 240/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.88it/s]\u001b[0m\n",
      "[Valid( 240/ 1024)-Loss: 0.337|Top1 Acc: 91.466|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 240/ 1024)-Loss: 0.374|Top1 Acc: 91.033|Top5 Acc: 99.731]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 241/ 1024)-Total: 0.327|Labeled: 0.034|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 241/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.67it/s]\u001b[0m\n",
      "[Valid( 241/ 1024)-Loss: 0.335|Top1 Acc: 91.647|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.91it/s]\u001b[0m\n",
      "[Test ( 241/ 1024)-Loss: 0.371|Top1 Acc: 91.212|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 242/ 1024)-Total: 0.336|Labeled: 0.038|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 242/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 242/ 1024)-Loss: 0.333|Top1 Acc: 91.426|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test ( 242/ 1024)-Loss: 0.373|Top1 Acc: 91.063|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 243/ 1024)-Total: 0.328|Labeled: 0.035|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 243/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 243/ 1024)-Loss: 0.336|Top1 Acc: 91.526|Top5 Acc: 99.900]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.81it/s]\u001b[0m\n",
      "[Test ( 243/ 1024)-Loss: 0.375|Top1 Acc: 91.162|Top5 Acc: 99.592]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.99it/s]\u001b[0m\n",
      "[Train( 244/ 1024)-Total: 0.332|Labeled: 0.035|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 244/ 1024)-Loss: 0.001|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 244/ 1024)-Loss: 0.334|Top1 Acc: 91.607|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.02it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test ( 244/ 1024)-Loss: 0.371|Top1 Acc: 91.302|Top5 Acc: 99.592]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 245/ 1024)-Total: 0.333|Labeled: 0.038|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 245/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 245/ 1024)-Loss: 0.331|Top1 Acc: 91.647|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.08it/s]\u001b[0m\n",
      "[Test ( 245/ 1024)-Loss: 0.371|Top1 Acc: 91.182|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train( 246/ 1024)-Total: 0.332|Labeled: 0.035|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 246/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 246/ 1024)-Loss: 0.327|Top1 Acc: 91.847|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 246/ 1024)-Loss: 0.371|Top1 Acc: 91.152|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.32it/s]\u001b[0m\n",
      "[Train( 247/ 1024)-Total: 0.328|Labeled: 0.035|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 247/ 1024)-Loss: 0.001|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid( 247/ 1024)-Loss: 0.328|Top1 Acc: 91.967|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.39it/s]\u001b[0m\n",
      "[Test ( 247/ 1024)-Loss: 0.377|Top1 Acc: 91.073|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.21it/s]\u001b[0m\n",
      "[Train( 248/ 1024)-Total: 0.330|Labeled: 0.035|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 248/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.83it/s]\u001b[0m\n",
      "[Valid( 248/ 1024)-Loss: 0.339|Top1 Acc: 91.807|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 248/ 1024)-Loss: 0.376|Top1 Acc: 91.083|Top5 Acc: 99.612]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train( 249/ 1024)-Total: 0.330|Labeled: 0.035|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 249/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 249/ 1024)-Loss: 0.340|Top1 Acc: 91.827|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 249/ 1024)-Loss: 0.370|Top1 Acc: 91.282|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train( 250/ 1024)-Total: 0.326|Labeled: 0.034|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 250/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 250/ 1024)-Loss: 0.338|Top1 Acc: 91.727|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 250/ 1024)-Loss: 0.373|Top1 Acc: 91.133|Top5 Acc: 99.711]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.25it/s]\u001b[0m\n",
      "[Train( 251/ 1024)-Total: 0.333|Labeled: 0.036|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 251/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 251/ 1024)-Loss: 0.342|Top1 Acc: 91.486|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 251/ 1024)-Loss: 0.372|Top1 Acc: 91.133|Top5 Acc: 99.741]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 252/ 1024)-Total: 0.335|Labeled: 0.035|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 252/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.78it/s]\u001b[0m\n",
      "[Valid( 252/ 1024)-Loss: 0.349|Top1 Acc: 91.406|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.98it/s]\u001b[0m\n",
      "[Test ( 252/ 1024)-Loss: 0.378|Top1 Acc: 90.953|Top5 Acc: 99.741]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.22it/s]\u001b[0m\n",
      "[Train( 253/ 1024)-Total: 0.333|Labeled: 0.036|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.00it/s]\u001b[0m\n",
      "[Train( 253/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid( 253/ 1024)-Loss: 0.351|Top1 Acc: 91.426|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 253/ 1024)-Loss: 0.376|Top1 Acc: 91.003|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.80it/s]\u001b[0m\n",
      "[Train( 254/ 1024)-Total: 0.330|Labeled: 0.033|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 254/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 254/ 1024)-Loss: 0.351|Top1 Acc: 91.546|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 254/ 1024)-Loss: 0.375|Top1 Acc: 91.113|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 255/ 1024)-Total: 0.338|Labeled: 0.038|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 255/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 255/ 1024)-Loss: 0.354|Top1 Acc: 91.446|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 36.96it/s]\u001b[0m\n",
      "[Test ( 255/ 1024)-Loss: 0.370|Top1 Acc: 91.242|Top5 Acc: 99.721]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.86it/s]\u001b[0m\n",
      "[Train( 256/ 1024)-Total: 0.326|Labeled: 0.034|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 256/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.94it/s]\u001b[0m\n",
      "[Valid( 256/ 1024)-Loss: 0.349|Top1 Acc: 91.607|Top5 Acc: 99.760]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 256/ 1024)-Loss: 0.369|Top1 Acc: 91.242|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 257/ 1024)-Total: 0.331|Labeled: 0.036|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 257/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.23it/s]\u001b[0m\n",
      "[Valid( 257/ 1024)-Loss: 0.340|Top1 Acc: 91.727|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.90it/s]\u001b[0m\n",
      "[Test ( 257/ 1024)-Loss: 0.364|Top1 Acc: 91.242|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 258/ 1024)-Total: 0.324|Labeled: 0.033|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 258/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.84it/s]\u001b[0m\n",
      "[Valid( 258/ 1024)-Loss: 0.342|Top1 Acc: 91.727|Top5 Acc: 99.900]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.91it/s]\u001b[0m\n",
      "[Test ( 258/ 1024)-Loss: 0.368|Top1 Acc: 91.262|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.10it/s]\u001b[0m\n",
      "[Train( 259/ 1024)-Total: 0.331|Labeled: 0.036|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 259/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.80it/s]\u001b[0m\n",
      "[Valid( 259/ 1024)-Loss: 0.336|Top1 Acc: 91.887|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.97it/s]\u001b[0m\n",
      "[Test ( 259/ 1024)-Loss: 0.366|Top1 Acc: 91.272|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 260/ 1024)-Total: 0.332|Labeled: 0.037|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 260/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 260/ 1024)-Loss: 0.336|Top1 Acc: 91.807|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.09it/s]\u001b[0m\n",
      "[Test ( 260/ 1024)-Loss: 0.368|Top1 Acc: 91.381|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 261/ 1024)-Total: 0.330|Labeled: 0.037|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 261/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.79it/s]\u001b[0m\n",
      "[Valid( 261/ 1024)-Loss: 0.341|Top1 Acc: 91.446|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.16it/s]\u001b[0m\n",
      "[Test ( 261/ 1024)-Loss: 0.364|Top1 Acc: 91.322|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.30it/s]\u001b[0m\n",
      "[Train( 262/ 1024)-Total: 0.333|Labeled: 0.035|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 262/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.95it/s]\u001b[0m\n",
      "[Valid( 262/ 1024)-Loss: 0.341|Top1 Acc: 91.386|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.10it/s]\u001b[0m\n",
      "[Test ( 262/ 1024)-Loss: 0.366|Top1 Acc: 91.152|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train( 263/ 1024)-Total: 0.331|Labeled: 0.036|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.06it/s]\u001b[0m\n",
      "[Train( 263/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.04it/s]\u001b[0m\n",
      "[Valid( 263/ 1024)-Loss: 0.338|Top1 Acc: 91.647|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.99it/s]\u001b[0m\n",
      "[Test ( 263/ 1024)-Loss: 0.360|Top1 Acc: 91.391|Top5 Acc: 99.711]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 264/ 1024)-Total: 0.332|Labeled: 0.035|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 264/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 264/ 1024)-Loss: 0.334|Top1 Acc: 91.707|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.95it/s]\u001b[0m\n",
      "[Test ( 264/ 1024)-Loss: 0.364|Top1 Acc: 91.222|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.74it/s]\u001b[0m\n",
      "[Train( 265/ 1024)-Total: 0.331|Labeled: 0.034|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 265/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.92it/s]\u001b[0m\n",
      "[Valid( 265/ 1024)-Loss: 0.338|Top1 Acc: 91.526|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.11it/s]\u001b[0m\n",
      "[Test ( 265/ 1024)-Loss: 0.365|Top1 Acc: 91.063|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.16it/s]\u001b[0m\n",
      "[Train( 266/ 1024)-Total: 0.332|Labeled: 0.036|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 266/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.93it/s]\u001b[0m\n",
      "[Valid( 266/ 1024)-Loss: 0.341|Top1 Acc: 91.707|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 266/ 1024)-Loss: 0.371|Top1 Acc: 91.073|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 267/ 1024)-Total: 0.332|Labeled: 0.037|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 267/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.84it/s]\u001b[0m\n",
      "[Valid( 267/ 1024)-Loss: 0.337|Top1 Acc: 91.887|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 267/ 1024)-Loss: 0.365|Top1 Acc: 91.182|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.24it/s]\u001b[0m\n",
      "[Train( 268/ 1024)-Total: 0.329|Labeled: 0.034|Unlabeled: 0.296]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 268/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.46it/s]\u001b[0m\n",
      "[Valid( 268/ 1024)-Loss: 0.335|Top1 Acc: 91.887|Top5 Acc: 99.740]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.82it/s]\u001b[0m\n",
      "[Test ( 268/ 1024)-Loss: 0.369|Top1 Acc: 91.073|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.20it/s]\u001b[0m\n",
      "[Train( 269/ 1024)-Total: 0.327|Labeled: 0.033|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 269/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.81it/s]\u001b[0m\n",
      "[Valid( 269/ 1024)-Loss: 0.339|Top1 Acc: 91.647|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test ( 269/ 1024)-Loss: 0.367|Top1 Acc: 91.252|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.07it/s]\u001b[0m\n",
      "[Train( 270/ 1024)-Total: 0.333|Labeled: 0.034|Unlabeled: 0.300]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 270/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.51it/s]\u001b[0m\n",
      "[Valid( 270/ 1024)-Loss: 0.333|Top1 Acc: 91.787|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.42it/s]\u001b[0m\n",
      "[Test ( 270/ 1024)-Loss: 0.363|Top1 Acc: 91.421|Top5 Acc: 99.721]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.87it/s]\u001b[0m\n",
      "[Train( 271/ 1024)-Total: 0.334|Labeled: 0.037|Unlabeled: 0.297]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:22<00:00,  5.05it/s]\u001b[0m\n",
      "[Train( 271/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 271/ 1024)-Loss: 0.340|Top1 Acc: 91.506|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.90it/s]\u001b[0m\n",
      "[Test ( 271/ 1024)-Loss: 0.362|Top1 Acc: 91.451|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.12it/s]\u001b[0m\n",
      "[Train( 272/ 1024)-Total: 0.328|Labeled: 0.035|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.04it/s]\u001b[0m\n",
      "[Train( 272/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 272/ 1024)-Loss: 0.339|Top1 Acc: 91.506|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.94it/s]\u001b[0m\n",
      "[Test ( 272/ 1024)-Loss: 0.362|Top1 Acc: 91.252|Top5 Acc: 99.711]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.54it/s]\u001b[0m\n",
      "[Train( 273/ 1024)-Total: 0.328|Labeled: 0.036|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.84it/s]\u001b[0m\n",
      "[Train( 273/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 20.77it/s]\u001b[0m\n",
      "[Valid( 273/ 1024)-Loss: 0.337|Top1 Acc: 91.526|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.54it/s]\u001b[0m\n",
      "[Test ( 273/ 1024)-Loss: 0.362|Top1 Acc: 91.182|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.61it/s]\u001b[0m\n",
      "[Train( 274/ 1024)-Total: 0.325|Labeled: 0.035|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.77it/s]\u001b[0m\n",
      "[Train( 274/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.94it/s]\u001b[0m\n",
      "[Valid( 274/ 1024)-Loss: 0.342|Top1 Acc: 91.506|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.38it/s]\u001b[0m\n",
      "[Test ( 274/ 1024)-Loss: 0.368|Top1 Acc: 91.103|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.94it/s]\u001b[0m\n",
      "[Train( 275/ 1024)-Total: 0.328|Labeled: 0.035|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:32<00:00,  4.83it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 275/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.86it/s]\u001b[0m\n",
      "[Valid( 275/ 1024)-Loss: 0.342|Top1 Acc: 91.667|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test ( 275/ 1024)-Loss: 0.369|Top1 Acc: 91.093|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.23it/s]\u001b[0m\n",
      "[Train( 276/ 1024)-Total: 0.328|Labeled: 0.034|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:25<00:00,  4.99it/s]\u001b[0m\n",
      "[Train( 276/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 276/ 1024)-Loss: 0.338|Top1 Acc: 91.567|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.05it/s]\u001b[0m\n",
      "[Test ( 276/ 1024)-Loss: 0.368|Top1 Acc: 91.152|Top5 Acc: 99.632]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.17it/s]\u001b[0m\n",
      "[Train( 277/ 1024)-Total: 0.328|Labeled: 0.034|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:26<00:00,  4.95it/s]\u001b[0m\n",
      "[Train( 277/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.98it/s]\u001b[0m\n",
      "[Valid( 277/ 1024)-Loss: 0.335|Top1 Acc: 91.647|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 38.04it/s]\u001b[0m\n",
      "[Test ( 277/ 1024)-Loss: 0.370|Top1 Acc: 91.123|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.27it/s]\u001b[0m\n",
      "[Train( 278/ 1024)-Total: 0.327|Labeled: 0.035|Unlabeled: 0.292]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:25<00:00,  4.99it/s]\u001b[0m\n",
      "[Train( 278/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.54it/s]\u001b[0m\n",
      "[Valid( 278/ 1024)-Loss: 0.332|Top1 Acc: 91.526|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.85it/s]\u001b[0m\n",
      "[Test ( 278/ 1024)-Loss: 0.362|Top1 Acc: 91.202|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.15it/s]\u001b[0m\n",
      "[Train( 279/ 1024)-Total: 0.325|Labeled: 0.034|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:26<00:00,  4.96it/s]\u001b[0m\n",
      "[Train( 279/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 25.01it/s]\u001b[0m\n",
      "[Valid( 279/ 1024)-Loss: 0.334|Top1 Acc: 91.366|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.09it/s]\u001b[0m\n",
      "[Test ( 279/ 1024)-Loss: 0.366|Top1 Acc: 91.282|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.04it/s]\u001b[0m\n",
      "[Train( 280/ 1024)-Total: 0.327|Labeled: 0.034|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:27<00:00,  4.94it/s]\u001b[0m\n",
      "[Train( 280/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.52it/s]\u001b[0m\n",
      "[Valid( 280/ 1024)-Loss: 0.338|Top1 Acc: 91.486|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.68it/s]\u001b[0m\n",
      "[Test ( 280/ 1024)-Loss: 0.360|Top1 Acc: 91.361|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.06it/s]\u001b[0m\n",
      "[Train( 281/ 1024)-Total: 0.320|Labeled: 0.034|Unlabeled: 0.286]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.73it/s]\u001b[0m\n",
      "[Train( 281/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.11it/s]\u001b[0m\n",
      "[Valid( 281/ 1024)-Loss: 0.334|Top1 Acc: 91.867|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 35.57it/s]\u001b[0m\n",
      "[Test ( 281/ 1024)-Loss: 0.363|Top1 Acc: 91.212|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.38it/s]\u001b[0m\n",
      "[Train( 282/ 1024)-Total: 0.325|Labeled: 0.035|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.78it/s]\u001b[0m\n",
      "[Train( 282/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.61it/s]\u001b[0m\n",
      "[Valid( 282/ 1024)-Loss: 0.333|Top1 Acc: 91.847|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.43it/s]\u001b[0m\n",
      "[Test ( 282/ 1024)-Loss: 0.361|Top1 Acc: 91.103|Top5 Acc: 99.642]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.82it/s]\u001b[0m\n",
      "[Train( 283/ 1024)-Total: 0.328|Labeled: 0.035|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.73it/s]\u001b[0m\n",
      "[Train( 283/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.85it/s]\u001b[0m\n",
      "[Valid( 283/ 1024)-Loss: 0.329|Top1 Acc: 91.987|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.50it/s]\u001b[0m\n",
      "[Test ( 283/ 1024)-Loss: 0.367|Top1 Acc: 91.152|Top5 Acc: 99.682]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.16it/s]\u001b[0m\n",
      "[Train( 284/ 1024)-Total: 0.325|Labeled: 0.034|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:37<00:00,  4.71it/s]\u001b[0m\n",
      "[Train( 284/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.33it/s]\u001b[0m\n",
      "[Valid( 284/ 1024)-Loss: 0.335|Top1 Acc: 91.727|Top5 Acc: 99.720]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 35.06it/s]\u001b[0m\n",
      "[Test ( 284/ 1024)-Loss: 0.366|Top1 Acc: 91.103|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.36it/s]\u001b[0m\n",
      "[Train( 285/ 1024)-Total: 0.330|Labeled: 0.036|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.73it/s]\u001b[0m\n",
      "[Train( 285/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.26it/s]\u001b[0m\n",
      "[Valid( 285/ 1024)-Loss: 0.332|Top1 Acc: 91.727|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.12it/s]\u001b[0m\n",
      "[Test ( 285/ 1024)-Loss: 0.356|Top1 Acc: 91.371|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.64it/s]\u001b[0m\n",
      "[Train( 286/ 1024)-Total: 0.333|Labeled: 0.035|Unlabeled: 0.298]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.72it/s]\u001b[0m\n",
      "[Train( 286/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.78it/s]\u001b[0m\n",
      "[Valid( 286/ 1024)-Loss: 0.339|Top1 Acc: 91.647|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 33.83it/s]\u001b[0m\n",
      "[Test ( 286/ 1024)-Loss: 0.360|Top1 Acc: 91.322|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.32it/s]\u001b[0m\n",
      "[Train( 287/ 1024)-Total: 0.329|Labeled: 0.034|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.73it/s]\u001b[0m\n",
      "[Train( 287/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.01it/s]\u001b[0m\n",
      "[Valid( 287/ 1024)-Loss: 0.332|Top1 Acc: 91.807|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.59it/s]\u001b[0m\n",
      "[Test ( 287/ 1024)-Loss: 0.360|Top1 Acc: 91.282|Top5 Acc: 99.731]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.66it/s]\u001b[0m\n",
      "[Train( 288/ 1024)-Total: 0.329|Labeled: 0.035|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.78it/s]\u001b[0m\n",
      "[Train( 288/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.77it/s]\u001b[0m\n",
      "[Valid( 288/ 1024)-Loss: 0.332|Top1 Acc: 91.607|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 33.70it/s]\u001b[0m\n",
      "[Test ( 288/ 1024)-Loss: 0.364|Top1 Acc: 91.133|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.20it/s]\u001b[0m\n",
      "[Train( 289/ 1024)-Total: 0.328|Labeled: 0.035|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:36<00:00,  4.73it/s]\u001b[0m\n",
      "[Train( 289/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.01it/s]\u001b[0m\n",
      "[Valid( 289/ 1024)-Loss: 0.336|Top1 Acc: 91.647|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.14it/s]\u001b[0m\n",
      "[Test ( 289/ 1024)-Loss: 0.367|Top1 Acc: 91.242|Top5 Acc: 99.711]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.15it/s]\u001b[0m\n",
      "[Train( 290/ 1024)-Total: 0.322|Labeled: 0.034|Unlabeled: 0.289]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:37<00:00,  4.71it/s]\u001b[0m\n",
      "[Train( 290/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 22.72it/s]\u001b[0m\n",
      "[Valid( 290/ 1024)-Loss: 0.341|Top1 Acc: 91.627|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.81it/s]\u001b[0m\n",
      "[Test ( 290/ 1024)-Loss: 0.356|Top1 Acc: 91.352|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.04it/s]\u001b[0m\n",
      "[Train( 291/ 1024)-Total: 0.327|Labeled: 0.034|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.77it/s]\u001b[0m\n",
      "[Train( 291/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.45it/s]\u001b[0m\n",
      "[Valid( 291/ 1024)-Loss: 0.341|Top1 Acc: 91.587|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.32it/s]\u001b[0m\n",
      "[Test ( 291/ 1024)-Loss: 0.361|Top1 Acc: 91.332|Top5 Acc: 99.721]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.48it/s]\u001b[0m\n",
      "[Train( 292/ 1024)-Total: 0.327|Labeled: 0.033|Unlabeled: 0.294]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.76it/s]\u001b[0m\n",
      "[Train( 292/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.22it/s]\u001b[0m\n",
      "[Valid( 292/ 1024)-Loss: 0.333|Top1 Acc: 91.827|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.72it/s]\u001b[0m\n",
      "[Test ( 292/ 1024)-Loss: 0.367|Top1 Acc: 91.352|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.28it/s]\u001b[0m\n",
      "[Train( 293/ 1024)-Total: 0.330|Labeled: 0.035|Unlabeled: 0.295]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:34<00:00,  4.78it/s]\u001b[0m\n",
      "[Train( 293/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.08it/s]\u001b[0m\n",
      "[Valid( 293/ 1024)-Loss: 0.334|Top1 Acc: 91.747|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.93it/s]\u001b[0m\n",
      "[Test ( 293/ 1024)-Loss: 0.372|Top1 Acc: 91.103|Top5 Acc: 99.672]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.49it/s]\u001b[0m\n",
      "[Train( 294/ 1024)-Total: 0.322|Labeled: 0.034|Unlabeled: 0.287]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:33<00:00,  4.80it/s]\u001b[0m\n",
      "[Train( 294/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.62it/s]\u001b[0m\n",
      "[Valid( 294/ 1024)-Loss: 0.339|Top1 Acc: 91.807|Top5 Acc: 99.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.80it/s]\u001b[0m\n",
      "[Test ( 294/ 1024)-Loss: 0.373|Top1 Acc: 91.083|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.78it/s]\u001b[0m\n",
      "[Train( 295/ 1024)-Total: 0.323|Labeled: 0.033|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:31<00:00,  4.85it/s]\u001b[0m\n",
      "[Train( 295/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.25it/s]\u001b[0m\n",
      "[Valid( 295/ 1024)-Loss: 0.336|Top1 Acc: 91.747|Top5 Acc: 99.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.76it/s]\u001b[0m\n",
      "[Test ( 295/ 1024)-Loss: 0.377|Top1 Acc: 90.983|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.02it/s]\u001b[0m\n",
      "[Train( 296/ 1024)-Total: 0.327|Labeled: 0.036|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:32<00:00,  4.82it/s]\u001b[0m\n",
      "[Train( 296/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.17it/s]\u001b[0m\n",
      "[Valid( 296/ 1024)-Loss: 0.338|Top1 Acc: 91.767|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.54it/s]\u001b[0m\n",
      "[Test ( 296/ 1024)-Loss: 0.380|Top1 Acc: 91.023|Top5 Acc: 99.711]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.64it/s]\u001b[0m\n",
      "[Train( 297/ 1024)-Total: 0.327|Labeled: 0.034|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:32<00:00,  4.81it/s]\u001b[0m\n",
      "[Train( 297/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.39it/s]\u001b[0m\n",
      "[Valid( 297/ 1024)-Loss: 0.338|Top1 Acc: 91.647|Top5 Acc: 99.780]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.99it/s]\u001b[0m\n",
      "[Test ( 297/ 1024)-Loss: 0.371|Top1 Acc: 91.292|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 35.00it/s]\u001b[0m\n",
      "[Train( 298/ 1024)-Total: 0.325|Labeled: 0.035|Unlabeled: 0.289]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:32<00:00,  4.82it/s]\u001b[0m\n",
      "[Train( 298/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.32it/s]\u001b[0m\n",
      "[Valid( 298/ 1024)-Loss: 0.332|Top1 Acc: 91.827|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 34.92it/s]\u001b[0m\n",
      "[Test ( 298/ 1024)-Loss: 0.369|Top1 Acc: 91.332|Top5 Acc: 99.622]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 34.96it/s]\u001b[0m\n",
      "[Train( 299/ 1024)-Total: 0.324|Labeled: 0.033|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:26<00:00,  4.95it/s]\u001b[0m\n",
      "[Train( 299/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.89it/s]\u001b[0m\n",
      "[Valid( 299/ 1024)-Loss: 0.334|Top1 Acc: 91.647|Top5 Acc: 99.900]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.93it/s]\u001b[0m\n",
      "[Test ( 299/ 1024)-Loss: 0.360|Top1 Acc: 91.481|Top5 Acc: 99.652]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.04it/s]\u001b[0m\n",
      "[Train( 300/ 1024)-Total: 0.326|Labeled: 0.035|Unlabeled: 0.291]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.01it/s]\u001b[0m\n",
      "[Train( 300/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.96it/s]\u001b[0m\n",
      "[Valid( 300/ 1024)-Loss: 0.331|Top1 Acc: 91.687|Top5 Acc: 99.820]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.78it/s]\u001b[0m\n",
      "[Test ( 300/ 1024)-Loss: 0.362|Top1 Acc: 91.232|Top5 Acc: 99.701]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.12it/s]\u001b[0m\n",
      "[Train( 301/ 1024)-Total: 0.325|Labeled: 0.032|Unlabeled: 0.293]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.01it/s]\u001b[0m\n",
      "[Train( 301/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.91it/s]\u001b[0m\n",
      "[Valid( 301/ 1024)-Loss: 0.326|Top1 Acc: 92.067|Top5 Acc: 99.880]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.91it/s]\u001b[0m\n",
      "[Test ( 301/ 1024)-Loss: 0.365|Top1 Acc: 91.282|Top5 Acc: 99.691]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 37.44it/s]\u001b[0m\n",
      "[Train( 302/ 1024)-Total: 0.324|Labeled: 0.034|Unlabeled: 0.290]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:24<00:00,  5.00it/s]\u001b[0m\n",
      "[Train( 302/ 1024)-Loss: 0.000|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.87it/s]\u001b[0m\n",
      "[Valid( 302/ 1024)-Loss: 0.325|Top1 Acc: 92.188|Top5 Acc: 99.860]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:02<00:00, 37.71it/s]\u001b[0m\n",
      "[Test ( 302/ 1024)-Loss: 0.362|Top1 Acc: 91.192|Top5 Acc: 99.662]: 100%|\u001b[91m█████████████████████\u001b[39m| [00:04<00:00, 38.09it/s]\u001b[0m\n",
      "[Train( 918/ 1024)-Total: 0.328|Labeled: 0.036|Unlabeled: 0.292]:  90%|\u001b[94m███████████████████▋  \u001b[39m| [03:13<00:22,  4.75it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlPCugRo71vcLXM5mz4PAo",
   "collapsed_sections": [],
   "name": "FixMatch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1519005239f2de3440a81beb718df9ab72fdd1ec6a07fd4a7f663a9215b4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
