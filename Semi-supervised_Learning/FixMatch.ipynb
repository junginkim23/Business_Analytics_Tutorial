{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FixMatch PyTorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 패키지 중 이미 다운 받아진 패키지 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1647328279368,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "p4HGUQjvTyb1"
   },
   "outputs": [],
   "source": [
    "import sys, os, copy, random, argparse, math\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageEnhance\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from colorama import Fore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variable 정의하기\n",
    "#### PARAMETER_MAX, cifar10의 mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647328279369,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "6QzixtWaT0CS"
   },
   "outputs": [],
   "source": [
    "########### 이 값을 두는 이유는 뭘까? ###########\n",
    "PARAMETER_MAX = 10\n",
    "\n",
    "# 이미지 정규화를 위한 평균 및 표준편차\n",
    "mean_cifar10 = (0.4914, 0.4822, 0.4465)\n",
    "std_cifar10 = (0.2471, 0.2345, 0.2616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647328279884,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "slW12bm8UL2U"
   },
   "outputs": [],
   "source": [
    "def _float_parameter(v, max_v):\n",
    "    return float(v) * max_v / PARAMETER_MAX\n",
    "\n",
    "\n",
    "def _int_parameter(v, max_v):\n",
    "    return int(v * max_v / PARAMETER_MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIL 패키지 내 각종 Data Augmentation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279884,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "gBHAD6IoT0yK"
   },
   "outputs": [],
   "source": [
    "# Augmentation 함수들을 정의\n",
    "\n",
    "def AutoContrast(img, **kwargs):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Brightness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Contrast(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v, **kwargs):\n",
    "    w, h = img.size\n",
    "    x0, y0 = np.random.uniform(0, w), np.random.uniform(0, h)\n",
    "    x0, y0 = int(max(0, x0 - v / 2.)), int(max(0, y0 - v / 2.))\n",
    "\n",
    "    x1, y1 = int(min(w, x0 + v)), int(min(h, y0 + v))\n",
    "\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    # gray\n",
    "    color = (127, 127, 127)\n",
    "    img = img.copy()\n",
    "    \n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def Cutout(img, v, max_v, bias=0):\n",
    "    if v == 0:\n",
    "        return img\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    v = int(v * min(img.size))\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def Equalize(img, **kwargs):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Identity(img, **kwargs):\n",
    "    return img\n",
    "\n",
    "\n",
    "def Invert(img, **kwargs):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Posterize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Rotate(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def ShearX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def Solarize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.solarize(img, 256 - v)\n",
    "\n",
    "\n",
    "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    img_np = np.array(img).astype(np.int)\n",
    "    img_np = img_np + v\n",
    "    img_np = np.clip(img_np, 0, 255)\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    img = Image.fromarray(img_np)\n",
    "    return PIL.ImageOps.solarize(img, threshold)\n",
    "\n",
    "\n",
    "def TranslateX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[0])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[1])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647328279885,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "pdfdIvkWUQXY"
   },
   "outputs": [],
   "source": [
    "# RandAugment를 사용하기 위한 전체 Augmentation List를 정의\n",
    "\n",
    "def flexmatch_augment_pool():\n",
    "    \n",
    "    '''\n",
    "    augs: 활용할 Augmentation의 전체집합\n",
    "    '''\n",
    "    \n",
    "    augs = [(AutoContrast, None, None),\n",
    "            (Brightness, 0.9, 0.05),\n",
    "            (Color, 0.9, 0.05),\n",
    "            (Contrast, 0.9, 0.05),\n",
    "            (Equalize, None, None),\n",
    "            (Identity, None, None),\n",
    "            (Posterize, 4, 4),\n",
    "            (Rotate, 30, 0),\n",
    "            (Sharpness, 0.9, 0.05),\n",
    "            (ShearX, 0.3, 0),\n",
    "            (ShearY, 0.3, 0),\n",
    "            (Solarize, 256, 0),\n",
    "            (TranslateX, 0.3, 0),\n",
    "            (TranslateY, 0.3, 0)]\n",
    "    return augs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandAugment를 위한 class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 구현된 Augmentpool에서 랜덤으로 선정하여 실제 Augmentation을 구현\n",
    "\n",
    "class RandAugmentMC(object):\n",
    "    \n",
    "    def __init__(self, n, m):\n",
    "        \n",
    "        '''\n",
    "        초기값 지정\n",
    "        n: 1~\n",
    "        m: 1~10\n",
    "        augment_pool: augmentation 함수들이 모여있는 집합\n",
    "        '''\n",
    "        \n",
    "        assert n >= 1\n",
    "        assert 1 <= m <= 10\n",
    "        \n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.augment_pool = flexmatch_augment_pool()\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "        '''\n",
    "        1. 함수가 불리면 augment_pool에서 n개만큼 선택\n",
    "        2. m범위에서 랜덤하게 operation 강도를 선정\n",
    "        3. 50$의 확률로 위 2가지 과정을 진행할지 결정\n",
    "        4. 마지막에는 Cutout Augmentation 진행\n",
    "        '''\n",
    "        \n",
    "        ops = random.choices(self.augment_pool, k=self.n)\n",
    "        \n",
    "        for op, max_v, bias in ops:\n",
    "            v = np.random.randint(1, self.m)\n",
    "            if random.random() < 0.5:\n",
    "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
    "\n",
    "        img = CutoutAbs(img, int(32*0.5))\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279885,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "UQlTwYXAUQpv"
   },
   "outputs": [],
   "source": [
    "# train_data를 생성하는 함수\n",
    "\n",
    "class CIFAR10_SSL(datasets.CIFAR10):\n",
    "    \n",
    "    def __init__(self, root, indexs, train=True,\n",
    "                transform=None, target_transform=None,\n",
    "                download=False):\n",
    "        \n",
    "        '''\n",
    "        초기값 지정: Indexs가 None이 아니면, 해당 Index만큼 Train으로 설정할 것임\n",
    "        self.data: train_x\n",
    "        self.targets: train_y\n",
    "        '''\n",
    "        \n",
    "        super(CIFAR10_SSL, self).__init__(\n",
    "            root, train=train, transform=transform,\n",
    "            target_transform=target_transform, download=download\n",
    "        )\n",
    "\n",
    "        if indexs is not None:\n",
    "            self.data = self.data[indexs]\n",
    "            self.targets = np.array(self.targets)[indexs]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        '''\n",
    "        getitem: index에 접근할 때 작동하는 함수\n",
    "        1. self.data 및 self.targets (즉, train_x, train_y)에서 각각 index에 해당하는 값을 불러온다.\n",
    "        2. transform이 지정되었다면, img를 Transform(Augmentation) 진행\n",
    "        '''\n",
    "        \n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279885,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "N0xtM10qUQsR"
   },
   "outputs": [],
   "source": [
    "# weak_augmentation과 strong_augmentation된 객체를 반환\n",
    "\n",
    "class TransformFlexMatch(object):\n",
    "    \n",
    "    def __init__(self, mean=mean_cifar10, std=std_cifar10):\n",
    "        \n",
    "        '''\n",
    "        Augmentation하는 함수 초깃값 지정\n",
    "        self.weak_transform: 약한 왜곡의 Augmentation으로 구성\n",
    "        self.strong_transform: 큰 왜곡의 Augmentation으로 구성 --> Weak Augmentation에 추가적인 왜곡을 지정\n",
    "        self.normalize: 정규화하는 함수 정의 ((N, H, W, C)-> (N, C, H, W))\n",
    "        '''\n",
    "        \n",
    "        self.weak_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=32,\n",
    "                                padding=int(32*0.125),\n",
    "                                padding_mode='reflect')\n",
    "        ])\n",
    "\n",
    "        self.strong_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=32,\n",
    "                                padding=int(32*0.125),\n",
    "                                padding_mode='reflect'),\n",
    "            RandAugmentMC(n=2, m=10)\n",
    "        ])\n",
    "\n",
    "        self.normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ]) \n",
    "    \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        '''\n",
    "        함수가 불리면 Weak Aug객체와 Strong Aug객체를 각각 생성 후 정규화한 값들을 반환\n",
    "        '''\n",
    "        \n",
    "        weak = self.weak_transform(x)\n",
    "        strong = self.strong_transform(x)\n",
    "\n",
    "        return self.normalize(weak), self.normalize(strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647328279886,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "OZGgVTRhUQu9"
   },
   "outputs": [],
   "source": [
    "# Labeled data와 Unlabeled data를 분리\n",
    "\n",
    "def split_labeled_unlabeled(args, labels):\n",
    "    \n",
    "    '''\n",
    "    1. 클래스 당 Labeled data의 개수를 정의\n",
    "    2. Labeled data, Unlabeled data, Validation data의 Index를 담을 수 있는 List 초기화\n",
    "    3. 각 Label별로 1에서 정의한 개수만큼 Labeled data를 지정하고, Validation data는 500개, 그 외 데이터는 모두 Unlabeled data로 지정\n",
    "    4. 각 Index를 Shuffle\n",
    "    5. Return Labeled data의 Index, Unlabeled data의 Index, Validation data의 Index\n",
    "    '''\n",
    "    \n",
    "    label_per_class = args.n_labeled // args.n_classes\n",
    "    labels = np.array(labels, dtype=int)\n",
    "    indice_labeled, indice_unlabeled, indice_val = [], [], []\n",
    "\n",
    "    for i in range(10):\n",
    "        indice_tmp = np.where(labels==i)[0]\n",
    "\n",
    "        indice_labeled.extend(indice_tmp[: label_per_class])\n",
    "        indice_unlabeled.extend(indice_tmp[label_per_class: -500])\n",
    "        indice_val.extend(indice_tmp[-500: ])\n",
    "    \n",
    "    for i in [indice_labeled, indice_unlabeled, indice_val]:\n",
    "        np.random.shuffle(i)\n",
    "    \n",
    "    return np.array(indice_labeled), np.array(indice_unlabeled), np.array(indice_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328279886,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "BW-EzldfUQxR"
   },
   "outputs": [],
   "source": [
    "def get_cifar10(args, data_dir):\n",
    "    \n",
    "    '''\n",
    "    1. labeled data의 tranform정의 \n",
    "    2. validation data의 tranform 정의: 정규화만 진행\n",
    "    3. Cifar10 데이터셋을 불러온 후 Index에 따라 Labeled, Unlabeled, Validation data를 분류\n",
    "    '''\n",
    "    \n",
    "    transform_labeled = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(size=32, padding=int(32*0.125), padding_mode='reflect'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_cifar10, std=std_cifar10)\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_cifar10, std=std_cifar10)\n",
    "    ])\n",
    "\n",
    "    base_dataset = datasets.CIFAR10(data_dir, train=True, download=True)\n",
    "\n",
    "    indice_labeled, indice_unlabeled, indice_val = split_labeled_unlabeled(args, base_dataset.targets)\n",
    "\n",
    "    '''\n",
    "    4. labeled dataset에 대해서는 transform_labeled augmentation 만 적용\n",
    "    5. Unlabeled dataset에 대해서는 transform_labeled augmentation 및 strong augmentation 동시 적용 \n",
    "    6. validation, test dataset에 대해서는 ToTensor & Normalization transformation 만 적용\n",
    "    '''\n",
    "    \n",
    "    labeled_dataset = CIFAR10_SSL(\n",
    "        data_dir, indice_labeled, train=True,\n",
    "        transform=transform_labeled\n",
    "    )\n",
    "\n",
    "    unlabeled_dataset = CIFAR10_SSL(\n",
    "        data_dir, indice_unlabeled, train=True,\n",
    "        transform=TransformFlexMatch(mean=mean_cifar10, std=std_cifar10)\n",
    "    )\n",
    "\n",
    "    val_dataset = CIFAR10_SSL(\n",
    "        data_dir, indice_val, train=True, transform=transform_val, download=False\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        data_dir, train=False, transform=transform_val, download=False\n",
    "    )\n",
    "    \n",
    "    return labeled_dataset, unlabeled_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet (MixMatch 와 동일)\n",
    " - WideResNet Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1647328280379,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "Cu8-zR_HUQz1"
   },
   "outputs": [],
   "source": [
    "# BasicBlock을 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual == True:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "    \n",
    "# Network Block을 정의\n",
    "class NetworkBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual)\n",
    "        \n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate, activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "# WideResNet 모델 정의\n",
    "class WideResNet(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    위에서 정의한 Basic Block 및 Network Block을 기반으로 Wide ResNet 모델 정의\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_classes, depth=28, widen_factor=2, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, activate_before_residual=True)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647328280379,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "J8MGfe4KUQ3t"
   },
   "outputs": [],
   "source": [
    "# WeightEMA로 Parameter를 Update하는 함수를 정의 (EMA=Exponential Moving Average)\n",
    "\n",
    "class WeightEMA(object): \n",
    "    \n",
    "    '''\n",
    "    MixMatch와 hyperparameter 이름만 변경\n",
    "    WeightEMA를 하는 이유는 학습시간이 길어지거나, Trivial Solution을 방지, 과적합 방지 등. \n",
    "    --> 가중치를 업데이트 시 a(최근가중치)+(1-a)(이전가중치)\n",
    "    --> summary: ema_params_new = self.decay*ema_params_old + (1-self.decay)*params\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model, decay):\n",
    "        \n",
    "        self.ema = copy.deepcopy(model)\n",
    "        self.ema.eval()\n",
    "\n",
    "        self.decay = decay\n",
    "\n",
    "        self.ema_has_module = hasattr(self.ema, 'module')\n",
    "\n",
    "        self.param_keys = [k for k, _ in self.ema.named_parameters()]\n",
    "        self.buffer_keys = [k for k, _ in self.ema.named_buffers()]\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def step(self, model):\n",
    "        needs_module = hasattr(model, 'module') and not self.ema_has_module\n",
    "        with torch.no_grad():\n",
    "            msd = model.state_dict()\n",
    "            esd = self.ema.state_dict()\n",
    "            for k in self.param_keys:\n",
    "                if needs_module:\n",
    "                    j = 'module.' + k\n",
    "                else:\n",
    "                    j = k\n",
    "                model_v = msd[j].detach()\n",
    "                ema_v = esd[k]\n",
    "                esd[k].copy_(ema_v * self.decay + (1. - self.decay) * model_v)\n",
    "\n",
    "            for k in self.buffer_keys:\n",
    "                if needs_module:\n",
    "                    j = 'module.' + k\n",
    "                else:\n",
    "                    j = k\n",
    "                esd[k].copy_(msd[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647328280379,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "x7_m766lVDNu"
   },
   "outputs": [],
   "source": [
    "# TopK Accuracy를 구하는 함수를 정의\n",
    "def accuracy(output, target, topk=(1, )):\n",
    "    \n",
    "    '''  \n",
    "    Pred값이 TopK개내에 있다면, 맞춘 것으로 정의\n",
    "    '''\n",
    "    \n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        if k == 1:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        if k > 1:\n",
    "            correct_k = correct[:k].float().sum(0).sum(0)\n",
    "        acc = correct_k.mul_(100.0 / batch_size)\n",
    "        acc = acc.detach().cpu().numpy()\n",
    "        res.append(acc)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328280380,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "Di-FhnXPVDQw"
   },
   "outputs": [],
   "source": [
    "# tqdm config 함수 정의\n",
    "def get_tqdm_config(total, leave=True, color='white'):\n",
    "    fore_colors = {\n",
    "        'red': Fore.LIGHTRED_EX,\n",
    "        'green': Fore.LIGHTGREEN_EX,\n",
    "        'yellow': Fore.LIGHTYELLOW_EX,\n",
    "        'blue': Fore.LIGHTBLUE_EX,\n",
    "        'magenta': Fore.LIGHTMAGENTA_EX,\n",
    "        'cyan': Fore.LIGHTCYAN_EX,\n",
    "        'white': Fore.LIGHTWHITE_EX,\n",
    "    }\n",
    "    return {\n",
    "        'file': sys.stdout,\n",
    "        'total': total,\n",
    "        'desc': \" \",\n",
    "        'dynamic_ncols': True,\n",
    "        'bar_format':\n",
    "            \"{l_bar}%s{bar}%s| [{elapsed}<{remaining}, {rate_fmt}{postfix}]\" % (fore_colors[color], Fore.RESET),\n",
    "        'leave': leave\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647328280380,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "UwHulI5UVDT8"
   },
   "outputs": [],
   "source": [
    "# Warmup을 적용한 Learning rate Scheduler 적용\n",
    "def get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps, num_training_steps,\n",
    "    num_cycles=7.0/16.0, last_epoch=-1\n",
    "    ):\n",
    "    \n",
    "    def _lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step)/float(max(1, num_warmup_steps))\n",
    "        \n",
    "        no_progress = float(current_step-num_warmup_steps)/\\\n",
    "            (float(max(1, num_training_steps-num_warmup_steps)))\n",
    "        return max(0.0, math.cos(math.pi*num_cycles*no_progress))\n",
    "    \n",
    "    return LambdaLR(optimizer, _lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1647328280640,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "0GJwI58MVDWu"
   },
   "outputs": [],
   "source": [
    "# trainer를 정의\n",
    "class FlexMatchTrainer():\n",
    "    \n",
    "    '''\n",
    "    DataLoader 내 num_workers 옵션에 대한 사설\n",
    "    Window10는 다중 CPU 코어 사용 시 순차적으로 작동 시작\n",
    "    Linux(Ubuntu, CentOS) 계열은 동시에 CPU 코어 작동을 시작 가능\n",
    "    (Windows10+PyTorch)를 사용해 Deep Learning 모델 학습 시 num_workers=0을 사용하는 것을 권유\n",
    "    (Linux계열 운영체제+PyTorch)를 사용해 Deep Learning 모델 학습 시 CPU&GPU 사용량이 최대가 될 수 있도록 num_workers 조정 권유\n",
    "    '''\n",
    "    \n",
    "    # 초깃값 지정\n",
    "    def __init__(self, args):\n",
    "        \n",
    "        '''\n",
    "        초깃값 지정\n",
    "        1. argument\n",
    "        2. directory\n",
    "        3. Dataset\n",
    "        4. DataLoader\n",
    "        5. Model(EMA Model), Optimzer, Model_parameter, LR Scheduler, Loss Function\n",
    "        6. Tensorboard 객체\n",
    "        '''\n",
    "        \n",
    "        # argment를 받아오기\n",
    "        self.args = args\n",
    "        \n",
    "        # 각종 Directory를 지정\n",
    "        root_dir = '/content/FlexMatch' ### Project Directory\n",
    "        data_dir = os.path.join(root_dir, 'data') ### Data Directory\n",
    "        \n",
    "        self.experiment_dir = os.path.join(root_dir, 'results') ### 학습된 모델을 저장할 큰 폴더\n",
    "        os.makedirs(self.experiment_dir, exist_ok=True)\n",
    "\n",
    "        name_exp = \"_\".join([str(self.args.n_labeled), str(self.args.T)]) ### 학습된 모델을 저장할 세부 폴더 (하이퍼파라미터로 지정)\n",
    "        self.experiment_dir = os.path.join(self.experiment_dir, name_exp)\n",
    "        os.makedirs(self.experiment_dir, exist_ok=True)\n",
    "        \n",
    "        # Load Dataset (Labeled, Unlabeled, Valid, Test dataset)\n",
    "        print(\"==> Preparing CIFAR10 dataset\")\n",
    "        labeled_set, unlabeled_set, val_set, test_set = get_cifar10(self.args, data_dir=data_dir)\n",
    "        \n",
    "        # DataLoader를 각각 정의 (Labeled, Unlabeled, Valid, Test dataset)                 \n",
    "        self.labeled_loader = DataLoader(\n",
    "            labeled_set,\n",
    "            sampler=RandomSampler(labeled_set), ### RandomSampler: DataLoader(shuffle=True) 와 동일한 역할\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        self.unlabeled_loader = DataLoader(\n",
    "            unlabeled_set,\n",
    "            sampler=RandomSampler(unlabeled_set),\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        self.val_loader = DataLoader(\n",
    "            val_set,\n",
    "            sampler=SequentialSampler(val_set), ### SequentialSampler: DataLoader(shuffle=False) 와 동일한 역할\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        self.test_loader = DataLoader(\n",
    "            test_set,\n",
    "            sampler=SequentialSampler(test_set),\n",
    "            batch_size=self.args.batch_size,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # WideResNet모델 정의\n",
    "        print(\"==> Preparing WideResNet\")\n",
    "        self.model = WideResNet(self.args.n_classes).to(self.args.cuda)\n",
    "        \n",
    "        # 모델의 Gradient 초기화 및 Loss Function을 정의\n",
    "        self.model.zero_grad()\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.cuda)\n",
    "\n",
    "        # Optimzer를 정의: params의 이름 내 bias, bn이 들어가지 않는 경우에만 weight_decay 적용\n",
    "        no_decay = ['bias', 'bn']\n",
    "        grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(\n",
    "                nd in n for nd in no_decay)], 'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(\n",
    "                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "        self.optimizer = torch.optim.SGD(grouped_parameters, lr=self.args.lr,\n",
    "                            momentum=0.9, nesterov=self.args.nesterov)\n",
    "        \n",
    "        # Learning rate Scheduler를 적용\n",
    "        \n",
    "        '''\n",
    "        Learning scheduler의 경우 사용이 까다로움\n",
    "         - 특정 scheduler는 각각 iteration 마다 step을 진행\n",
    "         - 또 다른 scheduler그룹은 한 epoch 종료 후 step 진행\n",
    "         - 아래 Documentation 에서 사용할 lr_scheduler에 대한 설명을 정확히 읽고 사용\n",
    "           - https://pytorch.org/docs/stable/optim.html\n",
    "        '''\n",
    "        \n",
    "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer,\n",
    "                                                    self.args.warmup,\n",
    "                                                    self.args.total_steps)\n",
    "        \n",
    "        # EMA Model을 쓸건지 안 쓸건지 명시\n",
    "        if self.args.use_ema:  \n",
    "            self.ema_model = WeightEMA(self.model, self.args.ema_decay)\n",
    "        \n",
    "        # Tensorboard에 기록할 객체 정의\n",
    "        self.writer = SummaryWriter(self.experiment_dir)\n",
    "\n",
    "        \n",
    "    # train을 위한 함수\n",
    "    def train(self, epoch):\n",
    "        \n",
    "        # total, labeled, unlabeled loss 초기화 및 Mask probs(Threshold를 넘었는지 여부를 표시한 것) 초기화\n",
    "        losses_t, losses_x, losses_u, mask_probs = 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        # 훈련모드 전환\n",
    "        self.model.train()\n",
    "        \n",
    "        # iter함수로 Labeled data 및 Unlabeled data 불러오기\n",
    "        iter_labeled = iter(self.labeled_loader)\n",
    "        iter_unlabeled = iter(self.unlabeled_loader)\n",
    "\n",
    "        with tqdm(**get_tqdm_config(total=self.args.eval_step,\n",
    "                leave=True, color='blue')) as pbar:\n",
    "            \n",
    "            for batch_idx in range(self.args.eval_step): ### eval_step: 1024 // batch_size: 64\n",
    "                \n",
    "                '''\n",
    "                왜 try-except 문을 사용하나?\n",
    "                 - 코드 작성 후 iter&next가 정확히 작용하지 않는 경우가 있음을 확인\n",
    "                 - 다시 iter_labeled, iter_unlabeled를 정의해 학습에 문제가 없도록 다시 선언\n",
    "                '''\n",
    "                \n",
    "                ### Labeled Data(각각 데이터와 Target)\n",
    "                try:\n",
    "                    inputs_x, targets_x = next(iter_labeled)\n",
    "                except:\n",
    "                    iter_labeled = iter(self.labeled_loader)\n",
    "                    inputs_x, targets_x = next(iter_labeled)\n",
    "                real_B = inputs_x.size(0)\n",
    "                \n",
    "                ### Unlabeled Data (각각 Weak Aug, Strong Aug)\n",
    "                try:\n",
    "                    (inputs_u_w, inputs_u_s), _ = next(iter_unlabeled)\n",
    "                except:\n",
    "                    iter_unlabeled = iter(self.unlabeled_loader)\n",
    "                    (inputs_u_w, inputs_u_s), _ = next(iter_unlabeled)\n",
    "                \n",
    "                ### Labeled data, Weak_aug Unlabeled data, Strong_aug Unlabeled data Concat하여 Input으로 활용\n",
    "                inputs = torch.cat((inputs_x, inputs_u_w, inputs_u_s), dim=0).to(self.args.cuda)\n",
    "                targets_x = targets_x.type(torch.LongTensor)\n",
    "                targets_x = targets_x.to(self.args.cuda)\n",
    "                \n",
    "                logits = self.model(inputs) ##### 예측값이 들어있음\n",
    "                \n",
    "                ### Labeled data와 Unlabeled data를 구분\n",
    "                \n",
    "                '''\n",
    "                real_B까지가 Labeled data Index, 그 외가 Unlabeled임\n",
    "                --> chunk함수로 weak_aug 및 strong_aug 구분 (Unlabeled data에 이미 weak, strong aug 각각 적용한 객체가 남아있는 형태)\n",
    "                '''\n",
    "                \n",
    "                logits_x = logits[:real_B]\n",
    "                logits_u_w, logits_u_s = logits[real_B:].chunk(2)\n",
    "                del(logits)\n",
    "\n",
    "                # Labeled data에 대한 loss계산\n",
    "                loss_x = F.cross_entropy(logits_x, targets_x, reduction='mean')\n",
    "\n",
    "                # Unlabeled data에 대한 loss계산\n",
    "                \n",
    "                '''\n",
    "                Unlabeled 데이터에 대한 로짓 산출 및 Temparature hyperparameter를 사용한 Sharpening\n",
    "                 --> Pseudo label 생성\n",
    "                1) Unlabeled data에 대한 예측값(logits_u_w)에 Softmax를 통과시킨 후 Sharpen 적용\n",
    "                2) 가장 높은 확률을 Label로 지정 (targets_u)\n",
    "                3) threshold값과 비교하여 mask 객체 생성\n",
    "                 - 이는 각 샘플에 대하여 확률이 도출되고, 배치 내 있는 데이터 만큼 Threshold를 넘었는지 여부를 T/F로 도출 [T, T, F, T..]\n",
    "                 - 근데, 지금 1개씩 가져와서 실험하다보니 결국 1개 sample에 대해서만 진행\n",
    "                '''\n",
    "                \n",
    "                pseudo_labels = torch.softmax(logits_u_w.detach()/self.args.T, dim=-1) \n",
    "                max_prob, targets_u = torch.max(pseudo_labels, dim=-1)\n",
    "                mask = max_prob.ge(self.args.threshold).float() ##### mask: Threshold보다 크면 True, 작으면 False를 반환\n",
    "\n",
    "                ### strong augmentation된 이미지에서 산출된 logit과 Pseudo label 사이 cross_entropy 계산\n",
    "                '''\n",
    "                여기서 mask를 곱해줌으로써 True면 1, False면 0을 곱해주게 된다.\n",
    "                --> 이를 통해 False일 경우 Loss연산에 이를 반영하지 않음\n",
    "                '''\n",
    "                loss_u = (F.cross_entropy(logits_u_s, targets_u, reduction='none')*mask).mean()\n",
    "\n",
    "                ### Total loss: Labeled data loss와 Unlabeled data loss의 가중합\n",
    "                loss = loss_x + self.args.lambda_u * loss_u\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                if self.args.use_ema:\n",
    "                    self.ema_model.step(self.model)\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                \n",
    "                ### Tensorboard를 위해 loss값들을 기록\n",
    "                losses_x += loss_x.item()\n",
    "                losses_u += loss_u.item()\n",
    "                losses_t += loss.item()\n",
    "                mask_probs += max_prob.mean().item()\n",
    "                \n",
    "                ### Print log\n",
    "                self.writer.add_scalars(\n",
    "                    'Training steps', {\n",
    "                        'Total_loss': losses_t/(batch_idx+1),\n",
    "                        'Labeled_loss':losses_x/(batch_idx+1),\n",
    "                        'Unlabeled_loss':losses_u/(batch_idx+1),\n",
    "                        'Mask probs': mask_probs/(batch_idx+1)\n",
    "                    }, global_step=epoch*self.args.batch_size+batch_idx\n",
    "                )\n",
    "\n",
    "                pbar.set_description(\n",
    "                    '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n",
    "                        (batch_idx+1), self.args.eval_step,\n",
    "                        losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.set_description(\n",
    "                '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n",
    "                    epoch, self.args.epochs,\n",
    "                    losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "                )\n",
    "            )\n",
    "        return losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "\n",
    "    \n",
    "    # Validation 함수 (MixMatch와 동일)\n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch, phase):\n",
    "        if phase == 'Train': ### Train Loss\n",
    "            data_loader = self.labeled_loader\n",
    "            c = 'blue'\n",
    "        elif phase == 'Valid': ### Valid Loss\n",
    "            data_loader = self.val_loader\n",
    "            c = 'green'\n",
    "        elif phase == 'Test ': ### Test Loss\n",
    "            data_loader = self.test_loader\n",
    "            c = 'red'\n",
    "        \n",
    "        ### 값 초기화\n",
    "        losses = 0.0\n",
    "        top1s, top5s = [], []\n",
    "        \n",
    "        ### 데이터를 넣은 후 Output 및 Loss값, 정확도 산출\n",
    "        with tqdm(**get_tqdm_config(total=len(data_loader),\n",
    "                leave=True, color=c)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "                \n",
    "                targets = targets.type(torch.LongTensor)\n",
    "                inputs, targets = inputs.to(self.args.cuda), targets.to(self.args.cuda)\n",
    "\n",
    "                outputs = self.ema_model.ema(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "                losses += loss.item()\n",
    "                top1s.append(prec1)\n",
    "                top5s.append(prec5)\n",
    "\n",
    "                self.writer.add_scalars(\n",
    "                    f'{phase} steps', {\n",
    "                        'Total_loss': losses/(batch_idx+1),\n",
    "                        'Top1 Acc': np.mean(top1s),\n",
    "                        'Top5 Acc': np.mean(top5s)\n",
    "                    }, global_step=epoch*self.args.batch_size+batch_idx\n",
    "                )\n",
    "\n",
    "                pbar.set_description(\n",
    "                    '[%s-Loss: %.3f|Top1 Acc: %.3f|Top5 Acc: %.3f]'%(\n",
    "                        phase,\n",
    "                        losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.set_description(\n",
    "                '[%s(%4d/ %4d)-Loss: %.3f|Top1 Acc: %.3f|Top5 Acc: %.3f]'%(\n",
    "                    phase,\n",
    "                    epoch, self.args.epochs,\n",
    "                    losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647328280640,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "k-qr4I-2XwBJ"
   },
   "outputs": [],
   "source": [
    "# Argument 정의\n",
    "def FlexMatch_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"FlexMatch PyTorch Implementation for BA\")\n",
    "    \n",
    "    # method arguments\n",
    "    parser.add_argument('--n-labeled', type=int, default=4000) # labeled dat의 수\n",
    "    parser.add_argument('--n-classes', type=int, default=10) # Class의 수\n",
    "    parser.add_argument(\"--expand-labels\", action=\"store_true\", \n",
    "                        help=\"expand labels to fit eval steps\")\n",
    "\n",
    "    # training hyperparameters\n",
    "    parser.add_argument('--batch-size', type=int, default=64) # 배치 사이즈\n",
    "    parser.add_argument('--total-steps', default=9000, type=int) # iteration마다 Scheduler가 적용되기에, Epoch가 아닌, Total-step을 정의\n",
    "    parser.add_argument('--eval-step', type=int, default=300) # Evaluation Step의 수\n",
    "    parser.add_argument('--lr', type=float, default=0.03) # Learning rate\n",
    "    parser.add_argument('--weight-decay', type=float, default=5e-4) # Weight Decay 정도\n",
    "    parser.add_argument('--nesterov', action='store_true', default=True) # Nesterov Momentum\n",
    "    parser.add_argument('--warmup', type=float, default=0.0) # Warmup 정도\n",
    "\n",
    "    parser.add_argument('--use-ema', action='store_true', default=True) # EMA 사용여부\n",
    "    parser.add_argument('--ema-decay', type=float, default=0.999) # EMA에서 Decay 정도\n",
    "\n",
    "    parser.add_argument('--mu', type=int, default=7) # Labeled data의 mu배를 Unlabeled 데이터의 개수로 정의하기 위한 함수 (근데 위 Trainer에서는 안 쓰임)\n",
    "    parser.add_argument('--T', type=float, default=1.0) # Sharpening 함수에 들어가는 하이퍼 파라미터\n",
    "\n",
    "    parser.add_argument('--threshold', type=float, default=0.95) # Pseudo-Labeling이 진행되는 Threshold 정의\n",
    "    parser.add_argument('--lambda-u', type=float, default=1.0) # Loss 가중치 정도\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647328280640,
     "user": {
      "displayName": "‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64",
      "userId": "06670976543419023521"
     },
     "user_tz": -540
    },
    "id": "_z6O-zHBXwIa"
   },
   "outputs": [],
   "source": [
    "# main함수 정의\n",
    "\n",
    "def main():\n",
    "    \n",
    "    '''\n",
    "    1. 사용자의 Parser를 받아온 후, Cuda지정 및 epoch 산정\n",
    "    2. Trainer를 정의\n",
    "    3. Loss값 초기화 \n",
    "    4. 전체 Loss, Labeled data의 Loss, Unlabeled data의 Loss를 담을 리스트 초기화\n",
    "    5. Train, Valid, Test 각각에 대해 Loss, top1 acc, top5 acc를 저장하기 위한 리스트 초기화\n",
    "    6. 각 Epoch 단위로 학습할 때 마다 성능들을 기록 및 Checkpoint 저장\n",
    "    7. 학습 중 Best_loss보다 개선되면, Best Loss를 변환 및 Model Save\n",
    "    '''\n",
    "    \n",
    "    parser = FlexMatch_parser()\n",
    "    args = parser.parse_args([])\n",
    "    args.cuda = torch.device(\"cuda:0\")\n",
    "    args.epochs = math.ceil(args.total_steps/args.eval_step)\n",
    "\n",
    "    trainer = FlexMatchTrainer(args)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    losses, losses_x, losses_u = [], [], []\n",
    "    \n",
    "    train_losses, train_top1s, train_top5s = [], [], []\n",
    "    val_losses, val_top1s, val_top5s = [], [], []\n",
    "    test_losses, test_top1s, test_top5s = [], [], []\n",
    "    \n",
    "    # 각 Epoch단위로 학습할 때 마다 성능들을 기록\n",
    "    for epoch in range(1, args.epochs+1, 1):\n",
    "        loss, loss_x, loss_u = trainer.train(epoch)\n",
    "        losses.append(loss)\n",
    "        losses_x.append(loss_x)\n",
    "        losses_u.append(loss_u)\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Train')\n",
    "        train_losses.append(loss)\n",
    "        train_top1s.append(top1)\n",
    "        train_top5s.append(top5)\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Valid')\n",
    "        val_losses.append(loss)\n",
    "        val_top1s.append(top1)\n",
    "        val_top5s.append(top5)\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(trainer.model, os.path.join(trainer.experiment_dir, 'model.pth'))\n",
    "            torch.save(trainer.ema_model, os.path.join(trainer.experiment_dir, 'ema_model.pth'))\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Test ')\n",
    "        test_losses.append(loss)\n",
    "        test_top1s.append(top1)\n",
    "        test_top5s.append(top5)\n",
    "\n",
    "        torch.save(trainer.model, os.path.join(trainer.experiment_dir, 'checkpooint_model.pth'))\n",
    "        torch.save(trainer.ema_model, os.path.join(trainer.experiment_dir, 'checkpoint_ema_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gn8znG3LX16K",
    "outputId": "4feb12dc-428f-483c-ed43-756ae3ae127b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing CIFAR10 dataset\n",
      "Files already downloaded and verified\n",
      "==> Preparing WideResNet\n",
      "[Train(   1/  300)-Total: 2.554|Labeled: 2.554|Unlabeled: 0.000]:   0%|\u001b[94m          \u001b[39m| [00:00<00:53,  5.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNGINKIM\\AppData\\Local\\Temp\\ipykernel_119056\\246649347.py:86: DeprecationWarning: AFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n",
      "  return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
      "C:\\Users\\JUNGINKIM\\AppData\\Local\\Temp\\ipykernel_119056\\246649347.py:119: DeprecationWarning: AFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n",
      "  return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
      "C:\\Users\\JUNGINKIM\\AppData\\Local\\Temp\\ipykernel_119056\\246649347.py:111: DeprecationWarning: AFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n",
      "  return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
      "C:\\Users\\JUNGINKIM\\AppData\\Local\\Temp\\ipykernel_119056\\246649347.py:79: DeprecationWarning: AFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n",
      "  return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train(   1/   30)-Total: 1.586|Labeled: 1.584|Unlabeled: 0.001]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.22it/s]\n",
      "[Train(   1/   30)-Loss: 2.526|Top1 Acc: 11.366|Top5 Acc: 63.886]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.34it/s]\n",
      "[Valid(   1/   30)-Loss: 2.536|Top1 Acc: 10.998|Top5 Acc: 63.021]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.34it/s]\n",
      "[Test (   1/   30)-Loss: 2.532|Top1 Acc: 11.425|Top5 Acc: 62.381]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.97it/s]\n",
      "[Train(   2/   30)-Total: 1.226|Labeled: 1.193|Unlabeled: 0.032]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.29it/s]\n",
      "[Train(   2/   30)-Loss: 2.045|Top1 Acc: 18.800|Top5 Acc: 77.797]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 22.68it/s]\n",
      "[Valid(   2/   30)-Loss: 2.051|Top1 Acc: 19.331|Top5 Acc: 76.823]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.99it/s]\n",
      "[Test (   2/   30)-Loss: 2.045|Top1 Acc: 19.666|Top5 Acc: 76.503]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.67it/s]\n",
      "[Train(   3/   30)-Total: 1.060|Labeled: 0.988|Unlabeled: 0.072]: 100%|\u001b[94m██████████\u001b[39m| [00:59<00:00,  5.07it/s]\n",
      "[Train(   3/   30)-Loss: 1.793|Top1 Acc: 33.997|Top5 Acc: 87.601]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 24.59it/s]\n",
      "[Valid(   3/   30)-Loss: 1.799|Top1 Acc: 33.293|Top5 Acc: 87.560]: 100%|\u001b[92m██████████\u001b[39m| [00:01<00:00, 41.17it/s]\n",
      "[Test (   3/   30)-Loss: 1.795|Top1 Acc: 34.146|Top5 Acc: 87.470]: 100%|\u001b[91m██████████\u001b[39m| [00:03<00:00, 40.84it/s]\n",
      "[Train(   4/   30)-Total: 0.947|Labeled: 0.843|Unlabeled: 0.104]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.25it/s]\n",
      "[Train(   4/   30)-Loss: 1.517|Top1 Acc: 46.699|Top5 Acc: 92.792]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.43it/s]\n",
      "[Valid(   4/   30)-Loss: 1.522|Top1 Acc: 46.254|Top5 Acc: 92.648]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.54it/s]\n",
      "[Test (   4/   30)-Loss: 1.525|Top1 Acc: 45.920|Top5 Acc: 92.546]: 100%|\u001b[91m██████████\u001b[39m| [00:03<00:00, 40.30it/s]\n",
      "[Train(   5/   30)-Total: 0.866|Labeled: 0.735|Unlabeled: 0.132]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.27it/s]\n",
      "[Train(   5/   30)-Loss: 1.224|Top1 Acc: 58.972|Top5 Acc: 95.514]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.90it/s]\n",
      "[Valid(   5/   30)-Loss: 1.256|Top1 Acc: 56.510|Top5 Acc: 95.012]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.46it/s]\n",
      "[Test (   5/   30)-Loss: 1.268|Top1 Acc: 55.713|Top5 Acc: 94.447]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.90it/s]\n",
      "[Train(   6/   30)-Total: 0.804|Labeled: 0.646|Unlabeled: 0.158]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.32it/s]\n",
      "[Train(   6/   30)-Loss: 1.002|Top1 Acc: 67.061|Top5 Acc: 96.951]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.81it/s]\n",
      "[Valid(   6/   30)-Loss: 1.069|Top1 Acc: 63.401|Top5 Acc: 96.034]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.02it/s]\n",
      "[Test (   6/   30)-Loss: 1.090|Top1 Acc: 62.082|Top5 Acc: 95.701]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.31it/s]\n",
      "[Train(   7/   30)-Total: 0.759|Labeled: 0.565|Unlabeled: 0.193]: 100%|\u001b[94m██████████\u001b[39m| [00:58<00:00,  5.13it/s]\n",
      "[Train(   7/   30)-Loss: 0.822|Top1 Acc: 73.790|Top5 Acc: 98.185]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.57it/s]\n",
      "[Valid(   7/   30)-Loss: 0.940|Top1 Acc: 67.087|Top5 Acc: 96.895]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.04it/s]\n",
      "[Test (   7/   30)-Loss: 0.966|Top1 Acc: 66.232|Top5 Acc: 96.636]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.29it/s]\n",
      "[Train(   8/   30)-Total: 0.715|Labeled: 0.496|Unlabeled: 0.220]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.24it/s]\n",
      "[Train(   8/   30)-Loss: 0.658|Top1 Acc: 79.209|Top5 Acc: 98.942]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.47it/s]\n",
      "[Valid(   8/   30)-Loss: 0.835|Top1 Acc: 71.134|Top5 Acc: 97.536]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.56it/s]\n",
      "[Test (   8/   30)-Loss: 0.865|Top1 Acc: 69.626|Top5 Acc: 97.482]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.65it/s]\n",
      "[Train(   9/   30)-Total: 0.680|Labeled: 0.439|Unlabeled: 0.241]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.28it/s]\n",
      "[Train(   9/   30)-Loss: 0.519|Top1 Acc: 83.619|Top5 Acc: 99.420]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.83it/s]\n",
      "[Valid(   9/   30)-Loss: 0.759|Top1 Acc: 73.738|Top5 Acc: 98.017]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.81it/s]\n",
      "[Test (   9/   30)-Loss: 0.788|Top1 Acc: 72.572|Top5 Acc: 98.189]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.10it/s]\n",
      "[Train(  10/   30)-Total: 0.641|Labeled: 0.387|Unlabeled: 0.254]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.35it/s]\n",
      "[Train(  10/   30)-Loss: 0.411|Top1 Acc: 87.298|Top5 Acc: 99.647]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 21.10it/s]\n",
      "[Valid(  10/   30)-Loss: 0.701|Top1 Acc: 75.481|Top5 Acc: 98.417]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.78it/s]\n",
      "[Test (  10/   30)-Loss: 0.729|Top1 Acc: 74.940|Top5 Acc: 98.567]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.27it/s]\n",
      "[Train(  11/   30)-Total: 0.610|Labeled: 0.333|Unlabeled: 0.277]: 100%|\u001b[94m██████████\u001b[39m| [00:58<00:00,  5.14it/s]\n",
      "[Train(  11/   30)-Loss: 0.319|Top1 Acc: 90.751|Top5 Acc: 99.748]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.01it/s]\n",
      "[Valid(  11/   30)-Loss: 0.666|Top1 Acc: 77.224|Top5 Acc: 98.578]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.75it/s]\n",
      "[Test (  11/   30)-Loss: 0.692|Top1 Acc: 76.652|Top5 Acc: 98.726]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.76it/s]\n",
      "[Train(  12/   30)-Total: 0.600|Labeled: 0.309|Unlabeled: 0.291]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.28it/s]\n",
      "[Train(  12/   30)-Loss: 0.250|Top1 Acc: 92.818|Top5 Acc: 99.899]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 21.04it/s]\n",
      "[Valid(  12/   30)-Loss: 0.643|Top1 Acc: 78.325|Top5 Acc: 98.698]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.49it/s]\n",
      "[Test (  12/   30)-Loss: 0.666|Top1 Acc: 77.727|Top5 Acc: 98.865]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.57it/s]\n",
      "[Train(  13/   30)-Total: 0.560|Labeled: 0.269|Unlabeled: 0.291]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.22it/s]\n",
      "[Train(  13/   30)-Loss: 0.201|Top1 Acc: 94.456|Top5 Acc: 99.899]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 23.95it/s]\n",
      "[Valid(  13/   30)-Loss: 0.627|Top1 Acc: 79.247|Top5 Acc: 98.798]: 100%|\u001b[92m██████████\u001b[39m| [00:01<00:00, 42.73it/s]\n",
      "[Test (  13/   30)-Loss: 0.649|Top1 Acc: 78.931|Top5 Acc: 98.925]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 39.02it/s]\n",
      "[Train(  14/   30)-Total: 0.546|Labeled: 0.236|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.25it/s]\n",
      "[Train(  14/   30)-Loss: 0.164|Top1 Acc: 95.615|Top5 Acc: 99.950]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.80it/s]\n",
      "[Valid(  14/   30)-Loss: 0.618|Top1 Acc: 79.928|Top5 Acc: 98.918]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.94it/s]\n",
      "[Test (  14/   30)-Loss: 0.638|Top1 Acc: 79.528|Top5 Acc: 98.985]: 100%|\u001b[91m██████████\u001b[39m| [00:03<00:00, 42.61it/s]\n",
      "[Train(  15/   30)-Total: 0.533|Labeled: 0.210|Unlabeled: 0.323]: 100%|\u001b[94m██████████\u001b[39m| [00:58<00:00,  5.14it/s]\n",
      "[Train(  15/   30)-Loss: 0.123|Top1 Acc: 97.102|Top5 Acc: 99.975]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.51it/s]\n",
      "[Valid(  15/   30)-Loss: 0.614|Top1 Acc: 80.369|Top5 Acc: 98.958]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.39it/s]\n",
      "[Test (  15/   30)-Loss: 0.633|Top1 Acc: 80.444|Top5 Acc: 99.035]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 33.39it/s]\n",
      "[Train(  16/   30)-Total: 0.507|Labeled: 0.186|Unlabeled: 0.321]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.29it/s]\n",
      "[Train(  16/   30)-Loss: 0.092|Top1 Acc: 98.009|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.67it/s]\n",
      "[Valid(  16/   30)-Loss: 0.614|Top1 Acc: 80.950|Top5 Acc: 98.998]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.32it/s]\n",
      "[Test (  16/   30)-Loss: 0.632|Top1 Acc: 80.782|Top5 Acc: 99.084]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.01it/s]\n",
      "[Train(  17/   30)-Total: 0.500|Labeled: 0.178|Unlabeled: 0.322]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.23it/s]\n",
      "[Train(  17/   30)-Loss: 0.075|Top1 Acc: 98.337|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.51it/s]\n",
      "[Valid(  17/   30)-Loss: 0.615|Top1 Acc: 81.530|Top5 Acc: 98.978]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.64it/s]\n",
      "[Test (  17/   30)-Loss: 0.634|Top1 Acc: 81.190|Top5 Acc: 99.114]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.16it/s]\n",
      "[Train(  18/   30)-Total: 0.486|Labeled: 0.158|Unlabeled: 0.329]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.30it/s]\n",
      "[Train(  18/   30)-Loss: 0.059|Top1 Acc: 98.891|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.34it/s]\n",
      "[Valid(  18/   30)-Loss: 0.618|Top1 Acc: 81.951|Top5 Acc: 99.119]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.00it/s]\n",
      "[Test (  18/   30)-Loss: 0.637|Top1 Acc: 81.539|Top5 Acc: 99.104]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.25it/s]\n",
      "[Train(  19/   30)-Total: 0.472|Labeled: 0.138|Unlabeled: 0.334]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.24it/s]\n",
      "[Train(  19/   30)-Loss: 0.047|Top1 Acc: 99.143|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.62it/s]\n",
      "[Valid(  19/   30)-Loss: 0.621|Top1 Acc: 82.232|Top5 Acc: 99.139]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 32.09it/s]\n",
      "[Test (  19/   30)-Loss: 0.641|Top1 Acc: 81.568|Top5 Acc: 99.084]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 33.16it/s]\n",
      "[Train(  20/   30)-Total: 0.451|Labeled: 0.120|Unlabeled: 0.331]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.22it/s]\n",
      "[Train(  20/   30)-Loss: 0.038|Top1 Acc: 99.521|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.23it/s]\n",
      "[Valid(  20/   30)-Loss: 0.621|Top1 Acc: 82.812|Top5 Acc: 99.038]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.79it/s]\n",
      "[Test (  20/   30)-Loss: 0.645|Top1 Acc: 81.947|Top5 Acc: 99.074]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.65it/s]\n",
      "[Train(  21/   30)-Total: 0.440|Labeled: 0.108|Unlabeled: 0.331]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.24it/s]\n",
      "[Train(  21/   30)-Loss: 0.031|Top1 Acc: 99.597|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.46it/s]\n",
      "[Valid(  21/   30)-Loss: 0.625|Top1 Acc: 83.053|Top5 Acc: 98.998]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.34it/s]\n",
      "[Test (  21/   30)-Loss: 0.648|Top1 Acc: 82.295|Top5 Acc: 99.055]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.01it/s]\n",
      "[Train(  22/   30)-Total: 0.439|Labeled: 0.099|Unlabeled: 0.340]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.33it/s]\n",
      "[Train(  22/   30)-Loss: 0.024|Top1 Acc: 99.723|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 24.01it/s]\n",
      "[Valid(  22/   30)-Loss: 0.632|Top1 Acc: 83.113|Top5 Acc: 99.079]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.26it/s]\n",
      "[Test (  22/   30)-Loss: 0.650|Top1 Acc: 82.395|Top5 Acc: 99.055]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.97it/s]\n",
      "[Train(  23/   30)-Total: 0.426|Labeled: 0.082|Unlabeled: 0.344]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.25it/s]\n",
      "[Train(  23/   30)-Loss: 0.020|Top1 Acc: 99.798|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 24.68it/s]\n",
      "[Valid(  23/   30)-Loss: 0.637|Top1 Acc: 83.293|Top5 Acc: 99.018]: 100%|\u001b[92m██████████\u001b[39m| [00:01<00:00, 41.56it/s]\n",
      "[Test (  23/   30)-Loss: 0.653|Top1 Acc: 82.613|Top5 Acc: 99.094]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.36it/s]\n",
      "[Train(  24/   30)-Total: 0.416|Labeled: 0.077|Unlabeled: 0.339]: 100%|\u001b[94m██████████\u001b[39m| [00:58<00:00,  5.11it/s]\n",
      "[Train(  24/   30)-Loss: 0.016|Top1 Acc: 99.950|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.63it/s]\n",
      "[Valid(  24/   30)-Loss: 0.641|Top1 Acc: 83.373|Top5 Acc: 98.998]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.59it/s]\n",
      "[Test (  24/   30)-Loss: 0.655|Top1 Acc: 82.952|Top5 Acc: 99.104]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 36.61it/s]\n",
      "[Train(  25/   30)-Total: 0.396|Labeled: 0.068|Unlabeled: 0.328]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.22it/s]\n",
      "[Train(  25/   30)-Loss: 0.013|Top1 Acc: 99.950|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.78it/s]\n",
      "[Valid(  25/   30)-Loss: 0.640|Top1 Acc: 83.614|Top5 Acc: 98.998]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 33.81it/s]\n",
      "[Test (  25/   30)-Loss: 0.652|Top1 Acc: 83.061|Top5 Acc: 99.154]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.32it/s]\n",
      "[Train(  26/   30)-Total: 0.391|Labeled: 0.058|Unlabeled: 0.333]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.28it/s]\n",
      "[Train(  26/   30)-Loss: 0.012|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:02<00:00, 20.73it/s]\n",
      "[Valid(  26/   30)-Loss: 0.641|Top1 Acc: 83.854|Top5 Acc: 99.058]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 35.29it/s]\n",
      "[Test (  26/   30)-Loss: 0.652|Top1 Acc: 83.161|Top5 Acc: 99.214]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.22it/s]\n",
      "[Train(  27/   30)-Total: 0.377|Labeled: 0.049|Unlabeled: 0.328]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.30it/s]\n",
      "[Train(  27/   30)-Loss: 0.011|Top1 Acc: 99.899|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.38it/s]\n",
      "[Valid(  27/   30)-Loss: 0.640|Top1 Acc: 83.934|Top5 Acc: 98.998]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.53it/s]\n",
      "[Test (  27/   30)-Loss: 0.652|Top1 Acc: 83.400|Top5 Acc: 99.204]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.88it/s]\n",
      "[Train(  28/   30)-Total: 0.362|Labeled: 0.040|Unlabeled: 0.322]: 100%|\u001b[94m██████████\u001b[39m| [00:58<00:00,  5.12it/s]\n",
      "[Train(  28/   30)-Loss: 0.009|Top1 Acc: 99.950|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 19.93it/s]\n",
      "[Valid(  28/   30)-Loss: 0.637|Top1 Acc: 84.095|Top5 Acc: 99.099]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.61it/s]\n",
      "[Test (  28/   30)-Loss: 0.651|Top1 Acc: 83.499|Top5 Acc: 99.234]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.73it/s]\n",
      "[Train(  29/   30)-Total: 0.353|Labeled: 0.033|Unlabeled: 0.320]: 100%|\u001b[94m██████████\u001b[39m| [00:57<00:00,  5.23it/s]\n",
      "[Train(  29/   30)-Loss: 0.009|Top1 Acc: 99.950|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.42it/s]\n",
      "[Valid(  29/   30)-Loss: 0.637|Top1 Acc: 84.295|Top5 Acc: 99.099]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.36it/s]\n",
      "[Test (  29/   30)-Loss: 0.651|Top1 Acc: 83.569|Top5 Acc: 99.224]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 34.96it/s]\n",
      "[Train(  30/   30)-Total: 0.344|Labeled: 0.026|Unlabeled: 0.318]: 100%|\u001b[94m██████████\u001b[39m| [00:56<00:00,  5.27it/s]\n",
      "[Train(  30/   30)-Loss: 0.008|Top1 Acc: 99.950|Top5 Acc: 100.000]: 100%|\u001b[94m██████████\u001b[39m| [00:03<00:00, 20.56it/s]\n",
      "[Valid(  30/   30)-Loss: 0.638|Top1 Acc: 84.335|Top5 Acc: 99.139]: 100%|\u001b[92m██████████\u001b[39m| [00:02<00:00, 34.73it/s]\n",
      "[Test (  30/   30)-Loss: 0.649|Top1 Acc: 83.877|Top5 Acc: 99.244]: 100%|\u001b[91m██████████\u001b[39m| [00:04<00:00, 35.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlPCugRo71vcLXM5mz4PAo",
   "collapsed_sections": [],
   "name": "FixMatch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1519005239f2de3440a81beb718df9ab72fdd1ec6a07fd4a7f663a9215b4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
