{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QFHP0Js1JBSs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4gCQgfpOHkb7"
   },
   "outputs": [],
   "source": [
    "import os, math, sys, argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from colorama import Fore\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7-gtzL_IHmEn"
   },
   "outputs": [],
   "source": [
    "# Custom Transform 함수 정의 --> 2가지 종류의 Augmentation 산출\n",
    "\n",
    "class Transform_Twice:\n",
    "    \n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        out1 = self.transform(img)\n",
    "        out2 = self.transform(img)\n",
    "        \n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3sOUFnwmHmHc"
   },
   "outputs": [],
   "source": [
    "# Labeled data를 생성하는 함수\n",
    "\n",
    "class Labeled_CIFAR10(torchvision.datasets.CIFAR10):\n",
    "    \n",
    "    def __init__(self, root, indices=None,\n",
    "                train=True, transform=None,\n",
    "                target_transform=None, download=False):\n",
    "        \n",
    "        super(Labeled_CIFAR10, self).__init__(root,\n",
    "                                        train=train,\n",
    "                                        transform=transform,\n",
    "                                        target_transform=target_transform,\n",
    "                                        download=download)\n",
    "\n",
    "        if indices is not None:\n",
    "            self.data = self.data[indices]\n",
    "            self.targets = np.array(self.targets)[indices]\n",
    "        \n",
    "        self.data = Transpose(Normalize(self.data))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mI3l2iwGHmJy"
   },
   "outputs": [],
   "source": [
    "# Unlabeled data를 생성하는 함수\n",
    "\n",
    "'''\n",
    "Unlabeled data의 Label은 -1로 지정\n",
    "'''\n",
    "\n",
    "class Unlabeled_CIFAR10(Labeled_CIFAR10):\n",
    "    \n",
    "    def __init__(self, root, indices, train=True, transform=None, target_transform=None, download=False):\n",
    "        \n",
    "        super(Unlabeled_CIFAR10, self).__init__(root, indices, train,\n",
    "                                            transform=transform,\n",
    "                                            target_transform=target_transform,\n",
    "                                            download=download)\n",
    "        \n",
    "        self.targets = np.array([-1 for i in range(len(self.targets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PNJw-5pdHmMe"
   },
   "outputs": [],
   "source": [
    "# 데이터셋을 분할하기 위해서 Index를 섞는 함수 정의\n",
    "\n",
    "def split_datasets(labels, n_labeled_per_class):\n",
    "    \n",
    "    '''\n",
    "    - n_labeled_per_class: labeled data의 개수\n",
    "    - 클래스 내 500개 데이터는 validation data로 정의\n",
    "    - 클래스 당 n_labeled_per_class 개수 만큼 labeled data로 정의\n",
    "    - 나머지 이미지는 unlabeled data로 정의\n",
    "    '''\n",
    "    \n",
    "    ### labeled, unlabeled, validation data 분할할 list 초기화\n",
    "    labels = np.array(labels, dtype=int) \n",
    "    indice_labeled, indice_unlabeled, indice_val = [], [], [] \n",
    "    \n",
    "    ### 각 class 단위로 loop 생성\n",
    "    for i in range(10): \n",
    "\n",
    "        # 각각 labeled, unlabeled, validation data를 할당\n",
    "        indice_tmp = np.where(labels==i)[0]\n",
    "        \n",
    "        indice_labeled.extend(indice_tmp[: n_labeled_per_class])\n",
    "        indice_unlabeled.extend(indice_tmp[n_labeled_per_class: -500])\n",
    "        indice_val.extend(indice_tmp[-500: ])\n",
    "    \n",
    "    ### 각 index를 Shuffle\n",
    "    for i in [indice_labeled, indice_unlabeled, indice_val]:\n",
    "        np.random.shuffle(i)\n",
    "    \n",
    "    return indice_labeled, indice_unlabeled, indice_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "45-rzXQKHmPE"
   },
   "outputs": [],
   "source": [
    "# CIFAR10에 대하여 labeled, unlabeled, validation, test dataset 생성\n",
    "\n",
    "def get_cifar10(data_dir: str, n_labeled: int,\n",
    "                transform_train=None, transform_val=None,\n",
    "                download=True):\n",
    "    \n",
    "    ### Torchvision에서 제공해주는 CIFAR10 dataset Download\n",
    "    base_dataset = torchvision.datasets.CIFAR10(data_dir, train=True, download=download)\n",
    "    \n",
    "    ### labeled, unlabeled, validation data에 해당하는 index를 가져오기\n",
    "    indice_labeled, indice_unlabeled, indice_val = split_datasets(base_dataset.targets, int(n_labeled/10)) ### n_labeled는 아래 MixMatch_argparser 함수에서 정의\n",
    "    \n",
    "    ### index를 기반으로 dataset을 생성\n",
    "    '''\n",
    "    왜 unlabeled가 Transform_twice가 적용되었을까?\n",
    "    '''\n",
    "    train_labeled_set = Labeled_CIFAR10(data_dir, indice_labeled, train=True, transform=transform_train) \n",
    "    train_unlabeled_set = Unlabeled_CIFAR10(data_dir, indice_unlabeled, train=True, transform=Transform_Twice(transform_train))\n",
    "    val_set = Labeled_CIFAR10(data_dir, indice_val, train=True, transform=transform_val, download=True) \n",
    "    test_set = Labeled_CIFAR10(data_dir, train=False, transform=transform_val, download=True) \n",
    "\n",
    "    return train_labeled_set, train_unlabeled_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "4Wc-3Z1fHmRi"
   },
   "outputs": [],
   "source": [
    "# Image를 전처리 하기 위한 함수\n",
    "\n",
    "### 데이터를 정규화 하기 위한 함수\n",
    "def Normalize(x, m=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2345, 0.2616)):\n",
    "        \n",
    "    ##### x, m, std를 각각 array화\n",
    "    x, m, std = [np.array(a, np.float32) for a in (x, m, std)] \n",
    "\n",
    "    ##### 데이터 정규화\n",
    "    x -= m * 255 \n",
    "    x *= 1.0/(255*std)\n",
    "    return x\n",
    "\n",
    "### 데이터를 (B, C, H, W)로 수정해주기 위한 함수 (from torchvision.transforms 내 ToTensor 와 동일한 함수)\n",
    "def Transpose(x, source='NHWC', target='NCHW'):\n",
    "    return x.transpose([source.index(d) for d in target])\n",
    "\n",
    "### 특정 이미지에 동서남북 방향으로 4만큼 픽셀을 추가해주기 위한 학습\n",
    "def pad(x, border=4):\n",
    "    return np.pad(x, [(0, 0), (border, border), (border, border)], mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lYm7Pt1vHmUL"
   },
   "outputs": [],
   "source": [
    "# Image를 Augmentation하기 위한 함수\n",
    "\n",
    "### Image를 Padding 및 Crop적용\n",
    "'''\n",
    "1. object는 써도 되고 안써도 되는 것\n",
    "2. assert는 오류를 유도하기 위함 (나중에 이렇게 해놓으면 디버깅이 편함) --> 여기선 적절한 데이터 인풋의 형태를 유도\n",
    "'''\n",
    "class RandomPadandCrop(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = pad(x, 4)\n",
    "        \n",
    "        old_h, old_w = x.shape[1: ]\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        top = np.random.randint(0, old_h-new_h)\n",
    "        left = np.random.randint(0, old_w-new_w)\n",
    "        \n",
    "        x = x[:, top:top+new_h, left:left+new_w]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "### RandomFlip하는 함수 정의\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, x):\n",
    "        if np.random.rand() < 0.5:\n",
    "            x = x[:, :, ::-1]\n",
    "        \n",
    "        return x.copy()\n",
    "    \n",
    "    \n",
    "### GaussianNoise를 추가하는 함수 정의\n",
    "class GaussianNoise(object):\n",
    "    def __call__(self, x):\n",
    "        c, h, w = x.shape\n",
    "        x += np.random.randn(c, h, w)*0.15\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "SJcg4AIpHmbo"
   },
   "outputs": [],
   "source": [
    "# Numpy를 Tensor로 변환하는 함수\n",
    "class ToTensor(object):\n",
    "    def __call__(self, x):\n",
    "        x = torch.from_numpy(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_a9lgAOhHmeF"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual == True:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0F-BjNbBH8z1"
   },
   "outputs": [],
   "source": [
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate, activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "iP1ftgvYH82i"
   },
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, num_classes, depth=28, widen_factor=2, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, activate_before_residual=True)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised loss function\n",
    "#### Semi-supervised loss = Loss(Labeled, x) + lambda * Loss(Unlabeled, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1HxAJDO2IoFA"
   },
   "outputs": [],
   "source": [
    "class Loss_Semisupervised(object):\n",
    "    def __call__(self, args, outputs_x, target_x, outputs_u, targets_u, epoch):\n",
    "        self.args = args\n",
    "        probs_u = torch.softmax(outputs_u, dim=1)\n",
    "\n",
    "        loss_x = -torch.mean(\n",
    "            torch.sum(F.log_softmax(outputs_x, dim=1)*target_x, dim=1)\n",
    "        )\n",
    "\n",
    "        loss_u = torch.mean((probs_u-targets_u)**2)\n",
    "\n",
    "        return loss_x, loss_u, self.args.lambda_u*linear_rampup(epoch, self.args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "CfMVPGCvIoOt"
   },
   "outputs": [],
   "source": [
    "def linear_rampup(current, rampup_length):\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current/rampup_length, 0.0, 1.0)\n",
    "        return float(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "3KyEyMQPIobG"
   },
   "outputs": [],
   "source": [
    "class WeightEMA(object): # EMA=Exponential Moving Average\n",
    "    \n",
    "    '''\n",
    "    이를 하는 이유는 학습시간이 길어지거나, Trivial Solution을 방지, 과적합 방지 등. --> 가중치를 업데이트 시 a(최근가중치)+(1-a)(이전가중치)\n",
    "    '''\n",
    "    def __init__(self, model, ema_model, lr, alpha=0.999):\n",
    "        self.model = model\n",
    "        self.ema_model = ema_model\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.params = list(self.model.state_dict().items())\n",
    "        self.ema_params = list(self.ema_model.state_dict().items())\n",
    "\n",
    "        self.wd = 0.02 * lr\n",
    "\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            param[1].data.copy_(ema_param[1].data)\n",
    "    \n",
    "    def step(self):\n",
    "        inverse_alpha = 1.0 - self.alpha\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            if ema_param[1].dtype == torch.float32:\n",
    "                ema_param[1].mul_(self.alpha) # ema_params_new = self.alpha * ema_params_old\n",
    "                ema_param[1].add_(param[1]*inverse_alpha) # ema_params_Double_new = (1-self.alpha)*params\n",
    "\n",
    "                # summary: ema_params_new = self.alpha*ema_params_old + (1-self.alpha)*params\n",
    "                # params: 학습되고 있는 모델 parameter\n",
    "                param[1].mul_(1-self.wd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qoESnZ41IzOZ"
   },
   "outputs": [],
   "source": [
    "def interleave_offsets(batch_size, nu):\n",
    "    \n",
    "    '''\n",
    "    이것도 assert의 목적으로 활용되는 code\n",
    "    '''\n",
    "    \n",
    "    groups = [batch_size//(nu+1)]*(nu+1)\n",
    "    for x in range(batch_size-sum(groups)):\n",
    "        groups[-x-1] += 1\n",
    "\n",
    "    offsets = [0]\n",
    "    for g in groups:\n",
    "        offsets.append(offsets[-1]+g)\n",
    "    \n",
    "    assert offsets[-1] == batch_size\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "pW0CqEc7IokG"
   },
   "outputs": [],
   "source": [
    "def interleave(xy, batch_size):\n",
    "    \n",
    "    '''\n",
    "    이것도 assert의 목적으로 활용되는 code\n",
    "    '''\n",
    "    \n",
    "    nu = len(xy) - 1\n",
    "    offsets = interleave_offsets(batch_size, nu)\n",
    "\n",
    "    xy = [[v[offsets[p]:offsets[p+1]] for p in range(nu+1)] for v in xy]\n",
    "    for i in range(1, nu+1):\n",
    "        xy[0][i], xy[i][i] = xy[i][i], xy[0][i]\n",
    "    return [torch.cat(v, dim=0) for v in xy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0ekZyGFLI7MS"
   },
   "outputs": [],
   "source": [
    "def get_tqdm_config(total, leave=True, color='white'):\n",
    "    fore_colors = {\n",
    "        'red': Fore.LIGHTRED_EX,\n",
    "        'green': Fore.LIGHTGREEN_EX,\n",
    "        'yellow': Fore.LIGHTYELLOW_EX,\n",
    "        'blue': Fore.LIGHTBLUE_EX,\n",
    "        'magenta': Fore.LIGHTMAGENTA_EX,\n",
    "        'cyan': Fore.LIGHTCYAN_EX,\n",
    "        'white': Fore.LIGHTWHITE_EX,\n",
    "    }\n",
    "    return {\n",
    "        'file': sys.stdout,\n",
    "        'total': total,\n",
    "        'desc': \" \",\n",
    "        'dynamic_ncols': True,\n",
    "        'bar_format':\n",
    "            \"{l_bar}%s{bar}%s| [{elapsed}<{remaining}, {rate_fmt}{postfix}]\" % (fore_colors[color], Fore.RESET),\n",
    "        'leave': leave\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric\n",
    "#### top1 accuracy, top5 accuracy\n",
    "#### top1 accuracy: (확률 값이 가장 높은 범주와 실제 범주가 일치하는 관측치 수)/ 전체 관측치\n",
    "#### top5 accuracy: (확률 값 상위 5개 중 실제 범주가 존재하는 관측치 수)/ 전체 관측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6sDCabk8JaGy"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1, )):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        if k == 1:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        if k > 1:\n",
    "            correct_k = correct[:k].float().sum(0).sum(0)\n",
    "        acc = correct_k.mul_(100.0 / batch_size)\n",
    "        acc = acc.detach().cpu().numpy()\n",
    "        res.append(acc)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "njMqQgRKH85I"
   },
   "outputs": [],
   "source": [
    "class MixMatchTrainer():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        root_dir = '/content/MixMatch' # PROJECT directory\n",
    "        self.experiment_dir = os.path.join(root_dir, 'results') # 학습된 모델을 저장할 폴더 경로 정의 및 폴더 생성\n",
    "        os.makedirs(self.experiment_dir, exist_ok=True)\n",
    "\n",
    "        name_exp = \"_\".join([str(self.args.n_labeled), str(self.args.T)]) # 주요 하이퍼 파라미터로 폴더 저장 경로 지정 \n",
    "        self.experiment_dir = os.path.join(self.experiment_dir, name_exp)\n",
    "        os.makedirs(self.experiment_dir, exist_ok=True)\n",
    "\n",
    "        # Data\n",
    "        print(\"==> Preparing CIFAR10 dataset\")\n",
    "        transform_train = transforms.Compose([\n",
    "            RandomPadandCrop(32),\n",
    "            RandomFlip(),\n",
    "            ToTensor()\n",
    "        ]) # 학습에 사용할 data augmentation 정의\n",
    "\n",
    "        transform_val = transforms.Compose([\n",
    "            ToTensor()\n",
    "        ]) # validation, test dataset에 대한 data augmentation 정의\n",
    "           # 합성곱 신경망에 입력 될 수 있도록만 지정(Augmentation 사용하지 않는 것과 동일)\n",
    "\n",
    "        train_labeled_set, train_unlabeled_set, val_set, test_set = \\\n",
    "            get_cifar10(\n",
    "                data_dir=os.path.join(root_dir, 'data'),\n",
    "                n_labeled=self.args.n_labeled,\n",
    "                transform_train=transform_train,\n",
    "                transform_val=transform_val\n",
    "            ) # 앞에서 정의한 (def) get_cifar10 함수에서 train_labeled, train_unlabeled, validation, test dataset\n",
    "        \n",
    "        # DataLoader 정의\n",
    "        self.labeled_loader = DataLoader(\n",
    "            dataset=train_labeled_set,\n",
    "            batch_size=self.args.batch_size,\n",
    "            shuffle=True, num_workers=0, drop_last=True\n",
    "        )\n",
    "\n",
    "        self.unlabeled_loader = DataLoader(\n",
    "            dataset=train_unlabeled_set,\n",
    "            batch_size=self.args.batch_size,\n",
    "            shuffle=True, num_workers=0, drop_last=True\n",
    "        )\n",
    "\n",
    "        self.val_loader = DataLoader(\n",
    "            dataset=val_set, shuffle=False, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "        self.test_loader = DataLoader(\n",
    "            dataset=test_set, shuffle=False, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "        # Build WideResNet\n",
    "        print(\"==> Preparing WideResNet\")\n",
    "        self.model = self.create_model(ema=False)\n",
    "        self.ema_model = self.create_model(ema=True)\n",
    "\n",
    "        # Define loss functions\n",
    "        self.criterion_train = Loss_Semisupervised()\n",
    "        self.criterion_val = nn.CrossEntropyLoss().to(self.args.cuda)\n",
    "\n",
    "        # Define optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n",
    "        self.ema_optimizer = WeightEMA(self.model, self.ema_model, lr=self.args.lr, alpha=self.args.ema_decay)\n",
    "\n",
    "        # 학습 결과를 저장할 Tensorboard 정의\n",
    "        self.writer = SummaryWriter(self.experiment_dir)\n",
    "\n",
    "    def create_model(self, ema=False):\n",
    "        # Build WideResNet & EMA model\n",
    "        model = WideResNet(num_classes=10)\n",
    "        model = model.to(self.args.cuda)\n",
    "\n",
    "        if ema:\n",
    "            for param in model.parameters():\n",
    "                param.detach_()\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        # 모델 학습 함수\n",
    "        losses_t, losses_x, losses_u, ws = 0.0, 0.0, 0.0, 0.0\n",
    "        self.model.train()\n",
    "\n",
    "        # iter & next remind\n",
    "        # iter: list 내 batch size 만큼 랜덤하게 불러오게 하는 함수\n",
    "        # next: iter 함수가 작동하도록 하는 명령어\n",
    "        iter_labeled = iter(self.labeled_loader)\n",
    "        iter_unlabeled = iter(self.unlabeled_loader)\n",
    "\n",
    "        with tqdm(**get_tqdm_config(total=self.args.num_iter,\n",
    "                leave=True, color='blue')) as pbar:\n",
    "            for batch_idx in range(self.args.num_iter):\n",
    "                # 왜 try-except 문을 사용하나?\n",
    "                # 코드 작성 후 iter&next가 정확히 작용하지 않는 경우가 있음을 확인\n",
    "                # 다시 iter_labeled, iter_unlabeled를 정의해 학습에 문제가 없도록 다시 선언\n",
    "                try:\n",
    "                    inputs_x, targets_x = next(iter_labeled)\n",
    "                except:\n",
    "                    iter_labeled = iter(self.labeled_loader)\n",
    "                    inputs_x, targets_x = next(iter_labeled)\n",
    "                real_B = inputs_x.size(0)\n",
    "\n",
    "                # Transform label to one-hot\n",
    "                targets_x = torch.zeros(real_B, 10).scatter_(1, targets_x.view(-1,1).long(), 1)\n",
    "                inputs_x, targets_x = inputs_x.to(self.args.cuda), targets_x.to(self.args.cuda)\n",
    "\n",
    "                try:\n",
    "                    tmp_inputs, _ = next(iter_unlabeled)\n",
    "                except:\n",
    "                    iter_unlabeled = iter(self.unlabeled_loader)\n",
    "                    tmp_inputs, _ = next(iter_unlabeled)\n",
    "\n",
    "                inputs_u1, inputs_u2 = tmp_inputs[0], tmp_inputs[1]\n",
    "                inputs_u1, inputs_u2 = inputs_u1.to(self.args.cuda), inputs_u2.to(self.args.cuda)\n",
    "\n",
    "                # Unlabeled data에 대한 실제 값 생성\n",
    "                # 서로 다른 Augmentation 결과의 출력 값의 평균 계산\n",
    "                # Temperature 값으로 실제 값 스케일링\n",
    "                with torch.no_grad():\n",
    "                    outputs_u1 = self.model(inputs_u1)\n",
    "                    outputs_u2 = self.model(inputs_u2)\n",
    "\n",
    "                    pt = (torch.softmax(outputs_u1, dim=1)+torch.softmax(outputs_u2, dim=1)) / 2\n",
    "                    pt = pt**(1/self.args.T)\n",
    "\n",
    "                    targets_u = pt / pt.sum(dim=1, keepdim=True)\n",
    "                    targets_u = targets_u.detach()\n",
    "                \n",
    "                # MixUp\n",
    "                # 서로 다른 이미지와 레이블을 섞는 작업\n",
    "                # feature space 상에서 범주 별 Decision boundary를 정확하게 잡아주는 역할\n",
    "                inputs = torch.cat([inputs_x, inputs_u1, inputs_u2], dim=0)\n",
    "                targets = torch.cat([targets_x, targets_u, targets_u], dim=0)\n",
    "\n",
    "                l_mixup = np.random.beta(self.args.alpha, self.args.alpha)\n",
    "                l_mixup = max(l_mixup, 1-l_mixup)\n",
    "\n",
    "                # inputs의 index를 섞어 서로 다른 범주끼리 섞도록 하는 역할\n",
    "                B = inputs.size(0)\n",
    "                random_idx = torch.randperm(B)\n",
    "\n",
    "                inputs_a, inputs_b = inputs, inputs[random_idx]\n",
    "                targets_a, targets_b = targets, targets[random_idx]\n",
    "\n",
    "                mixed_input = l_mixup*inputs_a + (1-l_mixup)*inputs_b\n",
    "                mixed_target = l_mixup*targets_a + (1-l_mixup)*targets_b\n",
    "\n",
    "                # batch size 만큼 분할 진행 (2N, C, H, W) -> (N, C, H, W) & (N, C, H, W)\n",
    "                # 앞 부분은 labeled, 뒷 부분은 unlabeled\n",
    "                '''\n",
    "                이렇게 하는 이유는 첫 B는 Label 데이터로 활용, 나중 B는 Unlabeled data로 활용하기 위함 (관용적 활용법)\n",
    "                '''\n",
    "                \n",
    "                mixed_input = list(torch.split(mixed_input, real_B))\n",
    "                mixed_input = interleave(mixed_input, real_B)\n",
    "\n",
    "                logits = [self.model(mixed_input[0])] # for labeled\n",
    "                for input in mixed_input[1:]:\n",
    "                    logits.append(self.model(input)) # for unlabeled\n",
    "\n",
    "                logits = interleave(logits, real_B) # interleave: 정확히 섞이었는지 확인\n",
    "                logits_x = logits[0]\n",
    "                logits_u = torch.cat(logits[1:], dim=0)\n",
    "\n",
    "                loss_x, loss_u, w = \\\n",
    "                    self.criterion_train(self.args,\n",
    "                                    logits_x, mixed_target[:real_B],\n",
    "                                    logits_u, mixed_target[real_B:],\n",
    "                                    epoch+batch_idx/self.args.num_iter) # Semi-supervised loss 계산\n",
    "\n",
    "                loss = loss_x + w * loss_u\n",
    "\n",
    "                # Backpropagation and Model parameter update\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.ema_optimizer.step()\n",
    "\n",
    "                losses_x += loss_x.item()\n",
    "                losses_u += loss_u.item()\n",
    "                losses_t += loss.item()\n",
    "                ws += w\n",
    "\n",
    "                self.writer.add_scalars(\n",
    "                    'Training steps', {\n",
    "                        'Total_loss': losses_t/(batch_idx+1),\n",
    "                        'Labeled_loss':losses_x/(batch_idx+1),\n",
    "                        'Unlabeled_loss':losses_u/(batch_idx+1),\n",
    "                        'W values': ws/(batch_idx+1)\n",
    "                    }, global_step=epoch*self.args.batch_size+batch_idx\n",
    "                )\n",
    "\n",
    "                pbar.set_description(\n",
    "                    '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n",
    "                        (batch_idx+1), self.args.num_iter,\n",
    "                        losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.set_description(\n",
    "                '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n",
    "                    epoch, self.args.epochs,\n",
    "                    losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch, phase):\n",
    "        self.ema_model.eval()\n",
    "\n",
    "        # Train, Validation, Test dataset 에 대한 DataLoader를 정의\n",
    "        if phase == 'Train':\n",
    "            data_loader = self.labeled_loader\n",
    "            c = 'blue'\n",
    "        elif phase == 'Valid':\n",
    "            data_loader = self.val_loader\n",
    "            c = 'green'\n",
    "        elif phase == 'Test ':        \n",
    "            data_loader = self.test_loader\n",
    "            c = 'red'\n",
    "\n",
    "        losses = 0.0\n",
    "        top1s, top5s = [], []\n",
    "\n",
    "        with tqdm(**get_tqdm_config(total=len(data_loader),\n",
    "                leave=True, color=c)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "                \n",
    "                targets = targets.type(torch.LongTensor)\n",
    "                inputs, targets = inputs.to(self.args.cuda), targets.to(self.args.cuda)\n",
    "                outputs = self.ema_model(inputs)\n",
    "                \n",
    "                loss = self.criterion_val(outputs, targets)\n",
    "                # labeled dataset에 대해서만 손실함수 계산\n",
    "                # torch.nn.CrossEntropyLoss()를 사용해서 손실함수 계산\n",
    "\n",
    "                prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "                losses += loss.item()\n",
    "                top1s.append(prec1)\n",
    "                top5s.append(prec5)\n",
    "\n",
    "                self.writer.add_scalars(\n",
    "                    f'{phase} steps', {\n",
    "                        'Total_loss': losses/(batch_idx+1),\n",
    "                        'Top1 Acc': np.mean(top1s),\n",
    "                        'Top5 Acc': np.mean(top5s)\n",
    "                    }, global_step=epoch*self.args.batch_size+batch_idx\n",
    "                )\n",
    "\n",
    "                pbar.set_description(\n",
    "                    '[%s-Loss: %.3f|Top1 Acc: %.3f|Top5 Acc: %.3f]'%(\n",
    "                        phase,\n",
    "                        losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.set_description(\n",
    "                '[%s(%4d/ %4d)-Loss: %.3f|Top1 Acc: %.3f|Top5 Acc: %.3f]'%(\n",
    "                    phase,\n",
    "                    epoch, self.args.epochs,\n",
    "                    losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return losses/(batch_idx+1), np.mean(top1s), np.mean(top5s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparamters\n",
    "#### argparser라는 패키지를 이용해 각종 hyperparameter 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "wscpGd8NH87k"
   },
   "outputs": [],
   "source": [
    "def MixMatch_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"MixMatch PyTorch Implementation for LG Electornics education\")\n",
    "    \n",
    "    # method arguments\n",
    "    parser.add_argument('--n-labeled', type=int, default=4000)\n",
    "    parser.add_argument('--num-iter', type=int, default=1024,\n",
    "                        help=\"The number of iteration per epoch\")\n",
    "    parser.add_argument('--alpha', type=float, default=0.75)\n",
    "    parser.add_argument('--lambda-u', type=float, default=75)\n",
    "    parser.add_argument('--T', default=0.5, type=float)\n",
    "    parser.add_argument('--ema-decay', type=float, default=0.999)\n",
    "\n",
    "    parser.add_argument('--epochs', type=int, default=1024)\n",
    "    parser.add_argument('--batch-size', type=int, default=64)\n",
    "    parser.add_argument('--lr', type=float, default=0.002)\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ZEjxA_eSH896"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = MixMatch_parser()\n",
    "    args = parser.parse_args([])\n",
    "    args.cuda = torch.device(\"cuda:0\")\n",
    "\n",
    "    trainer = MixMatchTrainer(args)\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    # best_loss of validation 기준으로 모멜 저장\n",
    "\n",
    "    losses, losses_x, losses_u = [], [], []\n",
    "    \n",
    "    train_losses, train_top1s, train_top5s = [], [], []\n",
    "    val_losses, val_top1s, val_top5s = [], [], []\n",
    "    test_losses, test_top1s, test_top5s = [], [], []\n",
    "    # accuracy 증가 속도, loss values 감소 속도를 그래프로 그리기\n",
    "    # list에 각종 값들을 저장\n",
    "    for epoch in range(1, args.epochs+1, 1):\n",
    "        loss, loss_x, loss_u = trainer.train(epoch)\n",
    "        losses.append(loss)\n",
    "        losses_x.append(loss_x)\n",
    "        losses_u.append(loss_u)\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Train')\n",
    "        train_losses.append(loss)\n",
    "        train_top1s.append(top1)\n",
    "        train_top5s.append(top5)\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Valid')\n",
    "        val_losses.append(loss)\n",
    "        val_top1s.append(top1)\n",
    "        val_top5s.append(top5)\n",
    "\n",
    "        # validation loss 기준 모델 저장\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(trainer.model, os.path.join(trainer.experiment_dir, 'model.pth'))\n",
    "            torch.save(trainer.ema_model, os.path.join(trainer.experiment_dir, 'ema_model.pth'))\n",
    "\n",
    "        loss, top1, top5 = trainer.validate(epoch, 'Test ')\n",
    "        test_losses.append(loss)\n",
    "        test_top1s.append(top1)\n",
    "        test_top5s.append(top5)\n",
    "\n",
    "        torch.save(trainer.model, os.path.join(trainer.experiment_dir, 'checkpooint_model.pth'))\n",
    "        torch.save(trainer.ema_model, os.path.join(trainer.experiment_dir, 'checkpoint_ema_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "eIPcmsY5Hmgz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing CIFAR10 dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Preparing WideResNet\n",
      "[Train(   1/ 1024)-Total: 1.696|Labeled: 1.695|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.88it/s]\u001b[0m\n",
      "[Train(   1/ 1024)-Loss: 2.129|Top1 Acc: 20.111|Top5 Acc: 71.144]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:01<00:00, 45.11it/s]\u001b[0m\n",
      "[Valid(   1/ 1024)-Loss: 2.129|Top1 Acc: 19.840|Top5 Acc: 71.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.73it/s]\u001b[0m\n",
      "[Test (   1/ 1024)-Loss: 2.125|Top1 Acc: 20.300|Top5 Acc: 71.890]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:49<00:00, 91.71it/s]\u001b[0m\n",
      "[Train(   2/ 1024)-Total: 1.404|Labeled: 1.403|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.96it/s]\u001b[0m\n",
      "[Train(   2/ 1024)-Loss: 1.323|Top1 Acc: 57.056|Top5 Acc: 95.691]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:01<00:00, 44.92it/s]\u001b[0m\n",
      "[Valid(   2/ 1024)-Loss: 1.337|Top1 Acc: 55.860|Top5 Acc: 95.160]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 116.26it/s]\u001b[0m\n",
      "[Test (   2/ 1024)-Loss: 1.354|Top1 Acc: 55.790|Top5 Acc: 94.490]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 90.02it/s]\u001b[0m\n",
      "[Train(   3/ 1024)-Total: 1.261|Labeled: 1.258|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.00it/s]\u001b[0m\n",
      "[Train(   3/ 1024)-Loss: 0.749|Top1 Acc: 81.653|Top5 Acc: 99.143]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:01<00:00, 45.54it/s]\u001b[0m\n",
      "[Valid(   3/ 1024)-Loss: 0.874|Top1 Acc: 73.720|Top5 Acc: 97.820]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.22it/s]\u001b[0m\n",
      "[Test (   3/ 1024)-Loss: 0.903|Top1 Acc: 72.360|Top5 Acc: 97.880]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 88.42it/s]\u001b[0m\n",
      "[Train(   4/ 1024)-Total: 1.169|Labeled: 1.165|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.98it/s]\u001b[0m\n",
      "[Train(   4/ 1024)-Loss: 0.467|Top1 Acc: 91.003|Top5 Acc: 99.748]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:01<00:00, 43.91it/s]\u001b[0m\n",
      "[Valid(   4/ 1024)-Loss: 0.698|Top1 Acc: 79.000|Top5 Acc: 98.280]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.29it/s]\u001b[0m\n",
      "[Test (   4/ 1024)-Loss: 0.724|Top1 Acc: 77.840|Top5 Acc: 98.420]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.47it/s]\u001b[0m\n",
      "[Train(   5/ 1024)-Total: 1.081|Labeled: 1.076|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.85it/s]\u001b[0m\n",
      "[Train(   5/ 1024)-Loss: 0.299|Top1 Acc: 95.791|Top5 Acc: 99.899]: 100%|\u001b[94m█████████████████████\u001b[39m| [00:01<00:00, 45.50it/s]\u001b[0m\n",
      "[Valid(   5/ 1024)-Loss: 0.620|Top1 Acc: 80.720|Top5 Acc: 98.620]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 113.50it/s]\u001b[0m\n",
      "[Test (   5/ 1024)-Loss: 0.642|Top1 Acc: 79.940|Top5 Acc: 98.760]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.43it/s]\u001b[0m\n",
      "[Train(   6/ 1024)-Total: 1.018|Labeled: 1.013|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.96it/s]\u001b[0m\n",
      "[Train(   6/ 1024)-Loss: 0.208|Top1 Acc: 98.059|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:01<00:00, 45.26it/s]\u001b[0m\n",
      "[Valid(   6/ 1024)-Loss: 0.590|Top1 Acc: 81.740|Top5 Acc: 98.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.90it/s]\u001b[0m\n",
      "[Test (   6/ 1024)-Loss: 0.610|Top1 Acc: 80.900|Top5 Acc: 98.670]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.49it/s]\u001b[0m\n",
      "[Train(   7/ 1024)-Total: 1.004|Labeled: 0.997|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(   7/ 1024)-Loss: 0.143|Top1 Acc: 99.496|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:01<00:00, 44.09it/s]\u001b[0m\n",
      "[Valid(   7/ 1024)-Loss: 0.565|Top1 Acc: 82.660|Top5 Acc: 98.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.10it/s]\u001b[0m\n",
      "[Test (   7/ 1024)-Loss: 0.583|Top1 Acc: 81.950|Top5 Acc: 98.810]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 88.93it/s]\u001b[0m\n",
      "[Train(   8/ 1024)-Total: 0.991|Labeled: 0.983|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.96it/s]\u001b[0m\n",
      "[Train(   8/ 1024)-Loss: 0.117|Top1 Acc: 99.824|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:01<00:00, 42.90it/s]\u001b[0m\n",
      "[Valid(   8/ 1024)-Loss: 0.556|Top1 Acc: 83.460|Top5 Acc: 98.600]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.34it/s]\u001b[0m\n",
      "[Test (   8/ 1024)-Loss: 0.574|Top1 Acc: 82.250|Top5 Acc: 98.700]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.39it/s]\u001b[0m\n",
      "[Train(   9/ 1024)-Total: 0.960|Labeled: 0.952|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.97it/s]\u001b[0m\n",
      "[Train(   9/ 1024)-Loss: 0.111|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:01<00:00, 44.09it/s]\u001b[0m\n",
      "[Valid(   9/ 1024)-Loss: 0.548|Top1 Acc: 83.980|Top5 Acc: 98.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.09it/s]\u001b[0m\n",
      "[Test (   9/ 1024)-Loss: 0.567|Top1 Acc: 82.890|Top5 Acc: 98.660]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.81it/s]\u001b[0m\n",
      "[Train(  10/ 1024)-Total: 0.948|Labeled: 0.938|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.94it/s]\u001b[0m\n",
      "[Train(  10/ 1024)-Loss: 0.109|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.52it/s]\u001b[0m\n",
      "[Valid(  10/ 1024)-Loss: 0.536|Top1 Acc: 84.600|Top5 Acc: 98.600]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.17it/s]\u001b[0m\n",
      "[Test (  10/ 1024)-Loss: 0.556|Top1 Acc: 83.480|Top5 Acc: 98.740]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 88.29it/s]\u001b[0m\n",
      "[Train(  11/ 1024)-Total: 0.915|Labeled: 0.905|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  5.99it/s]\u001b[0m\n",
      "[Train(  11/ 1024)-Loss: 0.109|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.24it/s]\u001b[0m\n",
      "[Valid(  11/ 1024)-Loss: 0.536|Top1 Acc: 84.520|Top5 Acc: 98.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 109.85it/s]\u001b[0m\n",
      "[Test (  11/ 1024)-Loss: 0.553|Top1 Acc: 83.950|Top5 Acc: 98.560]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:54<00:00, 87.60it/s]\u001b[0m\n",
      "[Train(  12/ 1024)-Total: 0.921|Labeled: 0.910|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.82it/s]\u001b[0m\n",
      "[Train(  12/ 1024)-Loss: 0.108|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.98it/s]\u001b[0m\n",
      "[Valid(  12/ 1024)-Loss: 0.531|Top1 Acc: 84.880|Top5 Acc: 98.420]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:51<00:00, 96.45it/s]\u001b[0m\n",
      "[Test (  12/ 1024)-Loss: 0.546|Top1 Acc: 84.040|Top5 Acc: 98.670]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:01<00:00, 82.29it/s]\u001b[0m\n",
      "[Train(  13/ 1024)-Total: 0.875|Labeled: 0.863|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.84it/s]\u001b[0m\n",
      "[Train(  13/ 1024)-Loss: 0.109|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.28it/s]\u001b[0m\n",
      "[Valid(  13/ 1024)-Loss: 0.526|Top1 Acc: 84.840|Top5 Acc: 98.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 111.87it/s]\u001b[0m\n",
      "[Test (  13/ 1024)-Loss: 0.539|Top1 Acc: 84.310|Top5 Acc: 98.690]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:55<00:00, 86.73it/s]\u001b[0m\n",
      "[Train(  14/ 1024)-Total: 0.904|Labeled: 0.891|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.82it/s]\u001b[0m\n",
      "[Train(  14/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.36it/s]\u001b[0m\n",
      "[Valid(  14/ 1024)-Loss: 0.530|Top1 Acc: 85.360|Top5 Acc: 98.420]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:56<00:00, 88.45it/s]\u001b[0m\n",
      "[Test (  14/ 1024)-Loss: 0.543|Top1 Acc: 84.580|Top5 Acc: 98.580]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:15<00:00, 74.03it/s]\u001b[0m\n",
      "[Train(  15/ 1024)-Total: 0.899|Labeled: 0.886|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.92it/s]\u001b[0m\n",
      "[Train(  15/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.15it/s]\u001b[0m\n",
      "[Valid(  15/ 1024)-Loss: 0.528|Top1 Acc: 85.020|Top5 Acc: 98.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 107.33it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test (  15/ 1024)-Loss: 0.542|Top1 Acc: 84.840|Top5 Acc: 98.450]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:49<00:00, 91.47it/s]\u001b[0m\n",
      "[Train(  16/ 1024)-Total: 0.877|Labeled: 0.863|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.98it/s]\u001b[0m\n",
      "[Train(  16/ 1024)-Loss: 0.122|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.66it/s]\u001b[0m\n",
      "[Valid(  16/ 1024)-Loss: 0.527|Top1 Acc: 84.880|Top5 Acc: 98.540]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:53<00:00, 92.71it/s]\u001b[0m\n",
      "[Test (  16/ 1024)-Loss: 0.539|Top1 Acc: 85.040|Top5 Acc: 98.640]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:22<00:00, 70.21it/s]\u001b[0m\n",
      "[Train(  17/ 1024)-Total: 0.850|Labeled: 0.836|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:56<00:00,  5.82it/s]\u001b[0m\n",
      "[Train(  17/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 40.72it/s]\u001b[0m\n",
      "[Valid(  17/ 1024)-Loss: 0.518|Top1 Acc: 85.600|Top5 Acc: 98.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:48<00:00, 102.60it/s]\u001b[0m\n",
      "[Test (  17/ 1024)-Loss: 0.529|Top1 Acc: 84.990|Top5 Acc: 98.530]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:12<00:00, 75.48it/s]\u001b[0m\n",
      "[Train(  18/ 1024)-Total: 0.900|Labeled: 0.883|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.84it/s]\u001b[0m\n",
      "[Train(  18/ 1024)-Loss: 0.125|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.92it/s]\u001b[0m\n",
      "[Valid(  18/ 1024)-Loss: 0.518|Top1 Acc: 85.300|Top5 Acc: 98.540]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 99.70it/s]\u001b[0m\n",
      "[Test (  18/ 1024)-Loss: 0.532|Top1 Acc: 85.010|Top5 Acc: 98.610]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:06<00:00, 79.26it/s]\u001b[0m\n",
      "[Train(  19/ 1024)-Total: 0.855|Labeled: 0.839|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  19/ 1024)-Loss: 0.127|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.85it/s]\u001b[0m\n",
      "[Valid(  19/ 1024)-Loss: 0.507|Top1 Acc: 85.840|Top5 Acc: 98.600]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 108.35it/s]\u001b[0m\n",
      "[Test (  19/ 1024)-Loss: 0.524|Top1 Acc: 85.370|Top5 Acc: 98.590]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:13<00:00, 74.71it/s]\u001b[0m\n",
      "[Train(  20/ 1024)-Total: 0.871|Labeled: 0.854|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.84it/s]\u001b[0m\n",
      "[Train(  20/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.59it/s]\u001b[0m\n",
      "[Valid(  20/ 1024)-Loss: 0.510|Top1 Acc: 86.100|Top5 Acc: 98.680]: 100%|\u001b[92m████████████████████\u001b[39m| [00:49<00:00, 100.64it/s]\u001b[0m\n",
      "[Test (  20/ 1024)-Loss: 0.524|Top1 Acc: 85.620|Top5 Acc: 98.650]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:06<00:00, 78.82it/s]\u001b[0m\n",
      "[Train(  21/ 1024)-Total: 0.857|Labeled: 0.839|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.86it/s]\u001b[0m\n",
      "[Train(  21/ 1024)-Loss: 0.131|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.52it/s]\u001b[0m\n",
      "[Valid(  21/ 1024)-Loss: 0.507|Top1 Acc: 86.100|Top5 Acc: 98.660]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:51<00:00, 97.17it/s]\u001b[0m\n",
      "[Test (  21/ 1024)-Loss: 0.525|Top1 Acc: 85.560|Top5 Acc: 98.450]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:34<00:00, 64.89it/s]\u001b[0m\n",
      "[Train(  22/ 1024)-Total: 0.866|Labeled: 0.847|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.86it/s]\u001b[0m\n",
      "[Train(  22/ 1024)-Loss: 0.131|Top1 Acc: 99.975|Top5 Acc: 100.000]: 100%|\u001b[94m████████████████████\u001b[39m| [00:01<00:00, 42.72it/s]\u001b[0m\n",
      "[Valid(  22/ 1024)-Loss: 0.498|Top1 Acc: 86.540|Top5 Acc: 98.820]: 100%|\u001b[92m████████████████████\u001b[39m| [00:49<00:00, 101.10it/s]\u001b[0m\n",
      "[Test (  22/ 1024)-Loss: 0.518|Top1 Acc: 85.960|Top5 Acc: 98.640]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:25<00:00, 68.66it/s]\u001b[0m\n",
      "[Train(  23/ 1024)-Total: 0.863|Labeled: 0.843|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:58<00:00,  5.72it/s]\u001b[0m\n",
      "[Train(  23/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 39.74it/s]\u001b[0m\n",
      "[Valid(  23/ 1024)-Loss: 0.492|Top1 Acc: 86.480|Top5 Acc: 98.800]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:10<00:00, 71.24it/s]\u001b[0m\n",
      "[Test (  23/ 1024)-Loss: 0.509|Top1 Acc: 86.270|Top5 Acc: 98.660]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:07<00:00, 78.29it/s]\u001b[0m\n",
      "[Train(  24/ 1024)-Total: 0.847|Labeled: 0.827|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.83it/s]\u001b[0m\n",
      "[Train(  24/ 1024)-Loss: 0.133|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.24it/s]\u001b[0m\n",
      "[Valid(  24/ 1024)-Loss: 0.496|Top1 Acc: 86.640|Top5 Acc: 98.660]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 99.99it/s]\u001b[0m\n",
      "[Test (  24/ 1024)-Loss: 0.513|Top1 Acc: 85.940|Top5 Acc: 98.610]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:10<00:00, 76.78it/s]\u001b[0m\n",
      "[Train(  25/ 1024)-Total: 0.874|Labeled: 0.852|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.87it/s]\u001b[0m\n",
      "[Train(  25/ 1024)-Loss: 0.134|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.22it/s]\u001b[0m\n",
      "[Valid(  25/ 1024)-Loss: 0.495|Top1 Acc: 86.880|Top5 Acc: 98.740]: 100%|\u001b[92m████████████████████\u001b[39m| [00:48<00:00, 103.31it/s]\u001b[0m\n",
      "[Test (  25/ 1024)-Loss: 0.508|Top1 Acc: 86.240|Top5 Acc: 98.660]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:01<00:00, 82.19it/s]\u001b[0m\n",
      "[Train(  26/ 1024)-Total: 0.862|Labeled: 0.839|Unlabeled: 0.012]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  26/ 1024)-Loss: 0.132|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.76it/s]\u001b[0m\n",
      "[Valid(  26/ 1024)-Loss: 0.497|Top1 Acc: 86.760|Top5 Acc: 98.760]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 106.61it/s]\u001b[0m\n",
      "[Test (  26/ 1024)-Loss: 0.503|Top1 Acc: 86.360|Top5 Acc: 98.690]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:00<00:00, 83.05it/s]\u001b[0m\n",
      "[Train(  27/ 1024)-Total: 0.862|Labeled: 0.839|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.88it/s]\u001b[0m\n",
      "[Train(  27/ 1024)-Loss: 0.134|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.13it/s]\u001b[0m\n",
      "[Valid(  27/ 1024)-Loss: 0.496|Top1 Acc: 86.740|Top5 Acc: 98.660]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 107.26it/s]\u001b[0m\n",
      "[Test (  27/ 1024)-Loss: 0.503|Top1 Acc: 86.440|Top5 Acc: 98.700]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:00<00:00, 83.10it/s]\u001b[0m\n",
      "[Train(  28/ 1024)-Total: 0.848|Labeled: 0.824|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  28/ 1024)-Loss: 0.136|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.91it/s]\u001b[0m\n",
      "[Valid(  28/ 1024)-Loss: 0.489|Top1 Acc: 87.260|Top5 Acc: 98.780]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 106.72it/s]\u001b[0m\n",
      "[Test (  28/ 1024)-Loss: 0.498|Top1 Acc: 86.940|Top5 Acc: 98.690]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.20it/s]\u001b[0m\n",
      "[Train(  29/ 1024)-Total: 0.856|Labeled: 0.831|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.97it/s]\u001b[0m\n",
      "[Train(  29/ 1024)-Loss: 0.135|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.47it/s]\u001b[0m\n",
      "[Valid(  29/ 1024)-Loss: 0.485|Top1 Acc: 87.220|Top5 Acc: 98.780]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 113.84it/s]\u001b[0m\n",
      "[Test (  29/ 1024)-Loss: 0.498|Top1 Acc: 86.720|Top5 Acc: 98.660]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 88.67it/s]\u001b[0m\n",
      "[Train(  30/ 1024)-Total: 0.842|Labeled: 0.817|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.85it/s]\u001b[0m\n",
      "[Train(  30/ 1024)-Loss: 0.139|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.24it/s]\u001b[0m\n",
      "[Valid(  30/ 1024)-Loss: 0.483|Top1 Acc: 87.420|Top5 Acc: 98.840]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:53<00:00, 92.94it/s]\u001b[0m\n",
      "[Test (  30/ 1024)-Loss: 0.495|Top1 Acc: 86.890|Top5 Acc: 98.760]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:32<00:00, 65.37it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train(  31/ 1024)-Total: 0.833|Labeled: 0.808|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:12<00:00,  5.31it/s]\u001b[0m\n",
      "[Train(  31/ 1024)-Loss: 0.135|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.33it/s]\u001b[0m\n",
      "[Valid(  31/ 1024)-Loss: 0.485|Top1 Acc: 87.460|Top5 Acc: 98.760]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.47it/s]\u001b[0m\n",
      "[Test (  31/ 1024)-Loss: 0.496|Top1 Acc: 86.960|Top5 Acc: 98.650]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 87.98it/s]\u001b[0m\n",
      "[Train(  32/ 1024)-Total: 0.849|Labeled: 0.823|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:09<00:00,  5.40it/s]\u001b[0m\n",
      "[Train(  32/ 1024)-Loss: 0.136|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.10it/s]\u001b[0m\n",
      "[Valid(  32/ 1024)-Loss: 0.488|Top1 Acc: 87.080|Top5 Acc: 98.740]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.53it/s]\u001b[0m\n",
      "[Test (  32/ 1024)-Loss: 0.496|Top1 Acc: 86.860|Top5 Acc: 98.590]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:49<00:00, 91.06it/s]\u001b[0m\n",
      "[Train(  33/ 1024)-Total: 0.830|Labeled: 0.803|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.95it/s]\u001b[0m\n",
      "[Train(  33/ 1024)-Loss: 0.138|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.17it/s]\u001b[0m\n",
      "[Valid(  33/ 1024)-Loss: 0.484|Top1 Acc: 87.420|Top5 Acc: 98.680]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 113.26it/s]\u001b[0m\n",
      "[Test (  33/ 1024)-Loss: 0.491|Top1 Acc: 87.240|Top5 Acc: 98.710]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.57it/s]\u001b[0m\n",
      "[Train(  34/ 1024)-Total: 0.854|Labeled: 0.826|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  34/ 1024)-Loss: 0.138|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.99it/s]\u001b[0m\n",
      "[Valid(  34/ 1024)-Loss: 0.482|Top1 Acc: 87.500|Top5 Acc: 98.800]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.25it/s]\u001b[0m\n",
      "[Test (  34/ 1024)-Loss: 0.487|Top1 Acc: 87.120|Top5 Acc: 98.840]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.23it/s]\u001b[0m\n",
      "[Train(  35/ 1024)-Total: 0.833|Labeled: 0.805|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  35/ 1024)-Loss: 0.132|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.97it/s]\u001b[0m\n",
      "[Valid(  35/ 1024)-Loss: 0.475|Top1 Acc: 87.660|Top5 Acc: 98.720]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 105.70it/s]\u001b[0m\n",
      "[Test (  35/ 1024)-Loss: 0.483|Top1 Acc: 87.050|Top5 Acc: 98.820]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.27it/s]\u001b[0m\n",
      "[Train(  36/ 1024)-Total: 0.842|Labeled: 0.813|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  36/ 1024)-Loss: 0.135|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.96it/s]\u001b[0m\n",
      "[Valid(  36/ 1024)-Loss: 0.475|Top1 Acc: 87.740|Top5 Acc: 98.820]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 106.21it/s]\u001b[0m\n",
      "[Test (  36/ 1024)-Loss: 0.484|Top1 Acc: 87.170|Top5 Acc: 98.800]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.05it/s]\u001b[0m\n",
      "[Train(  37/ 1024)-Total: 0.855|Labeled: 0.824|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  37/ 1024)-Loss: 0.136|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.87it/s]\u001b[0m\n",
      "[Valid(  37/ 1024)-Loss: 0.472|Top1 Acc: 88.040|Top5 Acc: 98.940]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 106.93it/s]\u001b[0m\n",
      "[Test (  37/ 1024)-Loss: 0.477|Top1 Acc: 87.260|Top5 Acc: 98.850]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.19it/s]\u001b[0m\n",
      "[Train(  38/ 1024)-Total: 0.843|Labeled: 0.812|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  38/ 1024)-Loss: 0.137|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.08it/s]\u001b[0m\n",
      "[Valid(  38/ 1024)-Loss: 0.477|Top1 Acc: 87.640|Top5 Acc: 98.960]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 105.66it/s]\u001b[0m\n",
      "[Test (  38/ 1024)-Loss: 0.480|Top1 Acc: 87.390|Top5 Acc: 98.690]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:58<00:00, 84.58it/s]\u001b[0m\n",
      "[Train(  39/ 1024)-Total: 0.850|Labeled: 0.818|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  39/ 1024)-Loss: 0.135|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.90it/s]\u001b[0m\n",
      "[Valid(  39/ 1024)-Loss: 0.467|Top1 Acc: 87.520|Top5 Acc: 98.980]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 105.90it/s]\u001b[0m\n",
      "[Test (  39/ 1024)-Loss: 0.472|Top1 Acc: 87.480|Top5 Acc: 98.940]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 84.87it/s]\u001b[0m\n",
      "[Train(  40/ 1024)-Total: 0.825|Labeled: 0.794|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  40/ 1024)-Loss: 0.134|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.67it/s]\u001b[0m\n",
      "[Valid(  40/ 1024)-Loss: 0.465|Top1 Acc: 87.960|Top5 Acc: 98.940]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 105.86it/s]\u001b[0m\n",
      "[Test (  40/ 1024)-Loss: 0.476|Top1 Acc: 87.350|Top5 Acc: 98.780]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:58<00:00, 84.50it/s]\u001b[0m\n",
      "[Train(  41/ 1024)-Total: 0.863|Labeled: 0.829|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.90it/s]\u001b[0m\n",
      "[Train(  41/ 1024)-Loss: 0.140|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.84it/s]\u001b[0m\n",
      "[Valid(  41/ 1024)-Loss: 0.471|Top1 Acc: 87.840|Top5 Acc: 98.940]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 105.12it/s]\u001b[0m\n",
      "[Test (  41/ 1024)-Loss: 0.481|Top1 Acc: 87.430|Top5 Acc: 98.650]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:58<00:00, 84.20it/s]\u001b[0m\n",
      "[Train(  42/ 1024)-Total: 0.845|Labeled: 0.811|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  42/ 1024)-Loss: 0.134|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.69it/s]\u001b[0m\n",
      "[Valid(  42/ 1024)-Loss: 0.459|Top1 Acc: 87.820|Top5 Acc: 99.000]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 104.68it/s]\u001b[0m\n",
      "[Test (  42/ 1024)-Loss: 0.471|Top1 Acc: 87.440|Top5 Acc: 98.760]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:00<00:00, 82.65it/s]\u001b[0m\n",
      "[Train(  43/ 1024)-Total: 0.842|Labeled: 0.807|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:56<00:00,  5.80it/s]\u001b[0m\n",
      "[Train(  43/ 1024)-Loss: 0.137|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.39it/s]\u001b[0m\n",
      "[Valid(  43/ 1024)-Loss: 0.456|Top1 Acc: 88.180|Top5 Acc: 99.080]: 100%|\u001b[92m████████████████████\u001b[39m| [00:49<00:00, 100.80it/s]\u001b[0m\n",
      "[Test (  43/ 1024)-Loss: 0.468|Top1 Acc: 87.680|Top5 Acc: 98.860]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:41<00:00, 61.85it/s]\u001b[0m\n",
      "[Train(  44/ 1024)-Total: 0.841|Labeled: 0.806|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:37<00:00,  4.70it/s]\u001b[0m\n",
      "[Train(  44/ 1024)-Loss: 0.133|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 32.58it/s]\u001b[0m\n",
      "[Valid(  44/ 1024)-Loss: 0.453|Top1 Acc: 88.040|Top5 Acc: 98.940]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:44<00:00, 48.04it/s]\u001b[0m\n",
      "[Test (  44/ 1024)-Loss: 0.462|Top1 Acc: 87.980|Top5 Acc: 98.900]: 100%|\u001b[91m█████████████████████\u001b[39m| [03:08<00:00, 53.02it/s]\u001b[0m\n",
      "[Train(  45/ 1024)-Total: 0.860|Labeled: 0.823|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:57<00:00,  5.78it/s]\u001b[0m\n",
      "[Train(  45/ 1024)-Loss: 0.132|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.00it/s]\u001b[0m\n",
      "[Valid(  45/ 1024)-Loss: 0.451|Top1 Acc: 87.940|Top5 Acc: 99.000]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:00<00:00, 82.71it/s]\u001b[0m\n",
      "[Test (  45/ 1024)-Loss: 0.459|Top1 Acc: 87.970|Top5 Acc: 98.870]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:39<00:00, 62.59it/s]\u001b[0m\n",
      "[Train(  46/ 1024)-Total: 0.843|Labeled: 0.806|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:01<00:00,  5.63it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train(  46/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.98it/s]\u001b[0m\n",
      "[Valid(  46/ 1024)-Loss: 0.452|Top1 Acc: 88.060|Top5 Acc: 98.940]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.73it/s]\u001b[0m\n",
      "[Test (  46/ 1024)-Loss: 0.462|Top1 Acc: 87.750|Top5 Acc: 98.830]: 100%|\u001b[91m█████████████████████\u001b[39m| [03:27<00:00, 48.23it/s]\u001b[0m\n",
      "[Train(  47/ 1024)-Total: 0.817|Labeled: 0.781|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [04:16<00:00,  3.99it/s]\u001b[0m\n",
      "[Train(  47/ 1024)-Loss: 0.131|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 24.90it/s]\u001b[0m\n",
      "[Valid(  47/ 1024)-Loss: 0.450|Top1 Acc: 88.240|Top5 Acc: 98.980]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:43<00:00, 48.27it/s]\u001b[0m\n",
      "[Test (  47/ 1024)-Loss: 0.462|Top1 Acc: 87.980|Top5 Acc: 98.840]: 100%|\u001b[91m█████████████████████\u001b[39m| [03:23<00:00, 49.05it/s]\u001b[0m\n",
      "[Train(  48/ 1024)-Total: 0.839|Labeled: 0.801|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [04:18<00:00,  3.96it/s]\u001b[0m\n",
      "[Train(  48/ 1024)-Loss: 0.129|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 32.34it/s]\u001b[0m\n",
      "[Valid(  48/ 1024)-Loss: 0.446|Top1 Acc: 88.480|Top5 Acc: 99.000]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:42<00:00, 48.99it/s]\u001b[0m\n",
      "[Test (  48/ 1024)-Loss: 0.458|Top1 Acc: 87.820|Top5 Acc: 98.880]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.04it/s]\u001b[0m\n",
      "[Train(  49/ 1024)-Total: 0.839|Labeled: 0.800|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [04:13<00:00,  4.03it/s]\u001b[0m\n",
      "[Train(  49/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 34.98it/s]\u001b[0m\n",
      "[Valid(  49/ 1024)-Loss: 0.444|Top1 Acc: 88.400|Top5 Acc: 99.000]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:20<00:00, 61.86it/s]\u001b[0m\n",
      "[Test (  49/ 1024)-Loss: 0.455|Top1 Acc: 88.050|Top5 Acc: 98.770]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:02<00:00, 81.89it/s]\u001b[0m\n",
      "[Train(  50/ 1024)-Total: 0.834|Labeled: 0.795|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.85it/s]\u001b[0m\n",
      "[Train(  50/ 1024)-Loss: 0.129|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.32it/s]\u001b[0m\n",
      "[Valid(  50/ 1024)-Loss: 0.441|Top1 Acc: 88.380|Top5 Acc: 99.200]: 100%|\u001b[92m████████████████████\u001b[39m| [00:49<00:00, 100.17it/s]\u001b[0m\n",
      "[Test (  50/ 1024)-Loss: 0.451|Top1 Acc: 88.330|Top5 Acc: 98.920]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:10<00:00, 76.80it/s]\u001b[0m\n",
      "[Train(  51/ 1024)-Total: 0.841|Labeled: 0.802|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.84it/s]\u001b[0m\n",
      "[Train(  51/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.44it/s]\u001b[0m\n",
      "[Valid(  51/ 1024)-Loss: 0.443|Top1 Acc: 88.060|Top5 Acc: 99.180]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 109.99it/s]\u001b[0m\n",
      "[Test (  51/ 1024)-Loss: 0.453|Top1 Acc: 88.160|Top5 Acc: 98.970]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:11<00:00, 76.21it/s]\u001b[0m\n",
      "[Train(  52/ 1024)-Total: 0.827|Labeled: 0.787|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.83it/s]\u001b[0m\n",
      "[Train(  52/ 1024)-Loss: 0.126|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.11it/s]\u001b[0m\n",
      "[Valid(  52/ 1024)-Loss: 0.448|Top1 Acc: 88.020|Top5 Acc: 99.180]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 98.63it/s]\u001b[0m\n",
      "[Test (  52/ 1024)-Loss: 0.454|Top1 Acc: 88.000|Top5 Acc: 98.880]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:10<00:00, 76.61it/s]\u001b[0m\n",
      "[Train(  53/ 1024)-Total: 0.849|Labeled: 0.807|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.86it/s]\u001b[0m\n",
      "[Train(  53/ 1024)-Loss: 0.126|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.58it/s]\u001b[0m\n",
      "[Valid(  53/ 1024)-Loss: 0.441|Top1 Acc: 88.620|Top5 Acc: 99.060]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.52it/s]\u001b[0m\n",
      "[Test (  53/ 1024)-Loss: 0.453|Top1 Acc: 88.090|Top5 Acc: 98.860]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.22it/s]\u001b[0m\n",
      "[Train(  54/ 1024)-Total: 0.838|Labeled: 0.796|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  54/ 1024)-Loss: 0.128|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.68it/s]\u001b[0m\n",
      "[Valid(  54/ 1024)-Loss: 0.439|Top1 Acc: 88.540|Top5 Acc: 99.040]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.05it/s]\u001b[0m\n",
      "[Test (  54/ 1024)-Loss: 0.451|Top1 Acc: 88.360|Top5 Acc: 98.850]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.44it/s]\u001b[0m\n",
      "[Train(  55/ 1024)-Total: 0.856|Labeled: 0.813|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  55/ 1024)-Loss: 0.129|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.62it/s]\u001b[0m\n",
      "[Valid(  55/ 1024)-Loss: 0.440|Top1 Acc: 88.520|Top5 Acc: 99.040]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.83it/s]\u001b[0m\n",
      "[Test (  55/ 1024)-Loss: 0.454|Top1 Acc: 88.310|Top5 Acc: 98.810]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.94it/s]\u001b[0m\n",
      "[Train(  56/ 1024)-Total: 0.835|Labeled: 0.792|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  56/ 1024)-Loss: 0.126|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.74it/s]\u001b[0m\n",
      "[Valid(  56/ 1024)-Loss: 0.428|Top1 Acc: 88.780|Top5 Acc: 99.260]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.08it/s]\u001b[0m\n",
      "[Test (  56/ 1024)-Loss: 0.443|Top1 Acc: 88.540|Top5 Acc: 98.980]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.77it/s]\u001b[0m\n",
      "[Train(  57/ 1024)-Total: 0.850|Labeled: 0.806|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  57/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.65it/s]\u001b[0m\n",
      "[Valid(  57/ 1024)-Loss: 0.428|Top1 Acc: 88.720|Top5 Acc: 99.260]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 116.57it/s]\u001b[0m\n",
      "[Test (  57/ 1024)-Loss: 0.444|Top1 Acc: 88.430|Top5 Acc: 99.030]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.89it/s]\u001b[0m\n",
      "[Train(  58/ 1024)-Total: 0.819|Labeled: 0.776|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  58/ 1024)-Loss: 0.126|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.45it/s]\u001b[0m\n",
      "[Valid(  58/ 1024)-Loss: 0.422|Top1 Acc: 88.740|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.77it/s]\u001b[0m\n",
      "[Test (  58/ 1024)-Loss: 0.438|Top1 Acc: 88.550|Top5 Acc: 99.040]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.86it/s]\u001b[0m\n",
      "[Train(  59/ 1024)-Total: 0.840|Labeled: 0.795|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  59/ 1024)-Loss: 0.129|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.65it/s]\u001b[0m\n",
      "[Valid(  59/ 1024)-Loss: 0.432|Top1 Acc: 88.820|Top5 Acc: 99.180]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.90it/s]\u001b[0m\n",
      "[Test (  59/ 1024)-Loss: 0.442|Top1 Acc: 88.430|Top5 Acc: 98.990]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.75it/s]\u001b[0m\n",
      "[Train(  60/ 1024)-Total: 0.822|Labeled: 0.778|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  60/ 1024)-Loss: 0.125|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.73it/s]\u001b[0m\n",
      "[Valid(  60/ 1024)-Loss: 0.432|Top1 Acc: 88.460|Top5 Acc: 99.140]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.30it/s]\u001b[0m\n",
      "[Test (  60/ 1024)-Loss: 0.439|Top1 Acc: 88.610|Top5 Acc: 98.940]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.54it/s]\u001b[0m\n",
      "[Train(  61/ 1024)-Total: 0.858|Labeled: 0.811|Unlabeled: 0.011]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  61/ 1024)-Loss: 0.130|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.67it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid(  61/ 1024)-Loss: 0.433|Top1 Acc: 88.740|Top5 Acc: 98.940]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.21it/s]\u001b[0m\n",
      "[Test (  61/ 1024)-Loss: 0.438|Top1 Acc: 88.880|Top5 Acc: 99.000]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:45<00:00, 94.81it/s]\u001b[0m\n",
      "[Train(  62/ 1024)-Total: 0.843|Labeled: 0.796|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  62/ 1024)-Loss: 0.129|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.87it/s]\u001b[0m\n",
      "[Valid(  62/ 1024)-Loss: 0.434|Top1 Acc: 88.860|Top5 Acc: 98.980]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.86it/s]\u001b[0m\n",
      "[Test (  62/ 1024)-Loss: 0.442|Top1 Acc: 88.530|Top5 Acc: 98.790]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.83it/s]\u001b[0m\n",
      "[Train(  63/ 1024)-Total: 0.843|Labeled: 0.794|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  63/ 1024)-Loss: 0.129|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.82it/s]\u001b[0m\n",
      "[Valid(  63/ 1024)-Loss: 0.430|Top1 Acc: 89.120|Top5 Acc: 99.000]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.27it/s]\u001b[0m\n",
      "[Test (  63/ 1024)-Loss: 0.436|Top1 Acc: 88.840|Top5 Acc: 99.010]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.83it/s]\u001b[0m\n",
      "[Train(  64/ 1024)-Total: 0.845|Labeled: 0.796|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  64/ 1024)-Loss: 0.126|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.89it/s]\u001b[0m\n",
      "[Valid(  64/ 1024)-Loss: 0.426|Top1 Acc: 88.680|Top5 Acc: 99.160]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.85it/s]\u001b[0m\n",
      "[Test (  64/ 1024)-Loss: 0.432|Top1 Acc: 88.990|Top5 Acc: 98.900]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.61it/s]\u001b[0m\n",
      "[Train(  65/ 1024)-Total: 0.830|Labeled: 0.781|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  65/ 1024)-Loss: 0.125|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.51it/s]\u001b[0m\n",
      "[Valid(  65/ 1024)-Loss: 0.422|Top1 Acc: 88.840|Top5 Acc: 99.060]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.01it/s]\u001b[0m\n",
      "[Test (  65/ 1024)-Loss: 0.428|Top1 Acc: 89.060|Top5 Acc: 98.960]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.97it/s]\u001b[0m\n",
      "[Train(  66/ 1024)-Total: 0.855|Labeled: 0.805|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  66/ 1024)-Loss: 0.126|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.67it/s]\u001b[0m\n",
      "[Valid(  66/ 1024)-Loss: 0.423|Top1 Acc: 88.860|Top5 Acc: 98.960]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.10it/s]\u001b[0m\n",
      "[Test (  66/ 1024)-Loss: 0.430|Top1 Acc: 88.910|Top5 Acc: 99.040]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.44it/s]\u001b[0m\n",
      "[Train(  67/ 1024)-Total: 0.850|Labeled: 0.799|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.97it/s]\u001b[0m\n",
      "[Train(  67/ 1024)-Loss: 0.125|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.55it/s]\u001b[0m\n",
      "[Valid(  67/ 1024)-Loss: 0.420|Top1 Acc: 89.300|Top5 Acc: 99.060]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.99it/s]\u001b[0m\n",
      "[Test (  67/ 1024)-Loss: 0.429|Top1 Acc: 89.000|Top5 Acc: 98.930]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:54<00:00, 87.03it/s]\u001b[0m\n",
      "[Train(  68/ 1024)-Total: 0.850|Labeled: 0.798|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  68/ 1024)-Loss: 0.124|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.10it/s]\u001b[0m\n",
      "[Valid(  68/ 1024)-Loss: 0.419|Top1 Acc: 89.520|Top5 Acc: 98.980]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.08it/s]\u001b[0m\n",
      "[Test (  68/ 1024)-Loss: 0.429|Top1 Acc: 88.910|Top5 Acc: 98.960]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:50<00:00, 90.71it/s]\u001b[0m\n",
      "[Train(  69/ 1024)-Total: 0.824|Labeled: 0.773|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  69/ 1024)-Loss: 0.124|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.17it/s]\u001b[0m\n",
      "[Valid(  69/ 1024)-Loss: 0.413|Top1 Acc: 89.560|Top5 Acc: 99.160]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 111.11it/s]\u001b[0m\n",
      "[Test (  69/ 1024)-Loss: 0.422|Top1 Acc: 89.130|Top5 Acc: 99.080]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:58<00:00, 84.67it/s]\u001b[0m\n",
      "[Train(  70/ 1024)-Total: 0.831|Labeled: 0.779|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  70/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.82it/s]\u001b[0m\n",
      "[Valid(  70/ 1024)-Loss: 0.417|Top1 Acc: 89.220|Top5 Acc: 99.120]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 111.83it/s]\u001b[0m\n",
      "[Test (  70/ 1024)-Loss: 0.423|Top1 Acc: 89.190|Top5 Acc: 99.020]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.73it/s]\u001b[0m\n",
      "[Train(  71/ 1024)-Total: 0.838|Labeled: 0.785|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.92it/s]\u001b[0m\n",
      "[Train(  71/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.30it/s]\u001b[0m\n",
      "[Valid(  71/ 1024)-Loss: 0.415|Top1 Acc: 89.140|Top5 Acc: 99.020]: 100%|\u001b[92m████████████████████\u001b[39m| [00:48<00:00, 102.23it/s]\u001b[0m\n",
      "[Test (  71/ 1024)-Loss: 0.419|Top1 Acc: 89.560|Top5 Acc: 99.030]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 87.94it/s]\u001b[0m\n",
      "[Train(  72/ 1024)-Total: 0.838|Labeled: 0.785|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.90it/s]\u001b[0m\n",
      "[Train(  72/ 1024)-Loss: 0.119|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.21it/s]\u001b[0m\n",
      "[Valid(  72/ 1024)-Loss: 0.419|Top1 Acc: 88.860|Top5 Acc: 99.040]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.35it/s]\u001b[0m\n",
      "[Test (  72/ 1024)-Loss: 0.419|Top1 Acc: 89.150|Top5 Acc: 98.990]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 88.53it/s]\u001b[0m\n",
      "[Train(  73/ 1024)-Total: 0.842|Labeled: 0.787|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.87it/s]\u001b[0m\n",
      "[Train(  73/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.06it/s]\u001b[0m\n",
      "[Valid(  73/ 1024)-Loss: 0.413|Top1 Acc: 89.300|Top5 Acc: 98.900]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.32it/s]\u001b[0m\n",
      "[Test (  73/ 1024)-Loss: 0.411|Top1 Acc: 89.390|Top5 Acc: 99.100]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 84.83it/s]\u001b[0m\n",
      "[Train(  74/ 1024)-Total: 0.831|Labeled: 0.777|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  74/ 1024)-Loss: 0.122|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.15it/s]\u001b[0m\n",
      "[Valid(  74/ 1024)-Loss: 0.411|Top1 Acc: 89.440|Top5 Acc: 99.080]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 111.18it/s]\u001b[0m\n",
      "[Test (  74/ 1024)-Loss: 0.415|Top1 Acc: 89.530|Top5 Acc: 99.020]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:54<00:00, 87.16it/s]\u001b[0m\n",
      "[Train(  75/ 1024)-Total: 0.817|Labeled: 0.763|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  75/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.97it/s]\u001b[0m\n",
      "[Valid(  75/ 1024)-Loss: 0.400|Top1 Acc: 89.960|Top5 Acc: 99.260]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 110.06it/s]\u001b[0m\n",
      "[Test (  75/ 1024)-Loss: 0.409|Top1 Acc: 89.400|Top5 Acc: 99.080]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.19it/s]\u001b[0m\n",
      "[Train(  76/ 1024)-Total: 0.845|Labeled: 0.789|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.97it/s]\u001b[0m\n",
      "[Train(  76/ 1024)-Loss: 0.118|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.55it/s]\u001b[0m\n",
      "[Valid(  76/ 1024)-Loss: 0.402|Top1 Acc: 89.600|Top5 Acc: 99.160]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.98it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test (  76/ 1024)-Loss: 0.411|Top1 Acc: 89.410|Top5 Acc: 99.070]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.50it/s]\u001b[0m\n",
      "[Train(  77/ 1024)-Total: 0.825|Labeled: 0.770|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  77/ 1024)-Loss: 0.119|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.66it/s]\u001b[0m\n",
      "[Valid(  77/ 1024)-Loss: 0.403|Top1 Acc: 89.580|Top5 Acc: 99.320]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 109.20it/s]\u001b[0m\n",
      "[Test (  77/ 1024)-Loss: 0.410|Top1 Acc: 89.440|Top5 Acc: 99.140]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.41it/s]\u001b[0m\n",
      "[Train(  78/ 1024)-Total: 0.862|Labeled: 0.803|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  78/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.78it/s]\u001b[0m\n",
      "[Valid(  78/ 1024)-Loss: 0.407|Top1 Acc: 89.440|Top5 Acc: 99.240]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 115.88it/s]\u001b[0m\n",
      "[Test (  78/ 1024)-Loss: 0.414|Top1 Acc: 89.360|Top5 Acc: 99.090]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 89.04it/s]\u001b[0m\n",
      "[Train(  79/ 1024)-Total: 0.864|Labeled: 0.805|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.91it/s]\u001b[0m\n",
      "[Train(  79/ 1024)-Loss: 0.124|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.28it/s]\u001b[0m\n",
      "[Valid(  79/ 1024)-Loss: 0.404|Top1 Acc: 89.640|Top5 Acc: 99.240]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 112.83it/s]\u001b[0m\n",
      "[Test (  79/ 1024)-Loss: 0.411|Top1 Acc: 89.370|Top5 Acc: 99.170]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 88.74it/s]\u001b[0m\n",
      "[Train(  80/ 1024)-Total: 0.863|Labeled: 0.802|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.92it/s]\u001b[0m\n",
      "[Train(  80/ 1024)-Loss: 0.122|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.91it/s]\u001b[0m\n",
      "[Valid(  80/ 1024)-Loss: 0.403|Top1 Acc: 89.520|Top5 Acc: 99.220]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 108.28it/s]\u001b[0m\n",
      "[Test (  80/ 1024)-Loss: 0.410|Top1 Acc: 89.530|Top5 Acc: 99.100]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:02<00:00, 81.54it/s]\u001b[0m\n",
      "[Train(  81/ 1024)-Total: 0.854|Labeled: 0.794|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.94it/s]\u001b[0m\n",
      "[Train(  81/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.62it/s]\u001b[0m\n",
      "[Valid(  81/ 1024)-Loss: 0.399|Top1 Acc: 89.660|Top5 Acc: 99.260]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 111.05it/s]\u001b[0m\n",
      "[Test (  81/ 1024)-Loss: 0.408|Top1 Acc: 89.730|Top5 Acc: 99.140]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:50<00:00, 90.32it/s]\u001b[0m\n",
      "[Train(  82/ 1024)-Total: 0.844|Labeled: 0.784|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.92it/s]\u001b[0m\n",
      "[Train(  82/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.00it/s]\u001b[0m\n",
      "[Valid(  82/ 1024)-Loss: 0.398|Top1 Acc: 89.540|Top5 Acc: 99.340]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.43it/s]\u001b[0m\n",
      "[Test (  82/ 1024)-Loss: 0.409|Top1 Acc: 89.420|Top5 Acc: 99.160]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.69it/s]\u001b[0m\n",
      "[Train(  83/ 1024)-Total: 0.844|Labeled: 0.783|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.87it/s]\u001b[0m\n",
      "[Train(  83/ 1024)-Loss: 0.121|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.90it/s]\u001b[0m\n",
      "[Valid(  83/ 1024)-Loss: 0.397|Top1 Acc: 89.680|Top5 Acc: 99.300]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 115.56it/s]\u001b[0m\n",
      "[Test (  83/ 1024)-Loss: 0.410|Top1 Acc: 89.490|Top5 Acc: 99.140]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:50<00:00, 90.16it/s]\u001b[0m\n",
      "[Train(  84/ 1024)-Total: 0.861|Labeled: 0.798|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.87it/s]\u001b[0m\n",
      "[Train(  84/ 1024)-Loss: 0.124|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.93it/s]\u001b[0m\n",
      "[Valid(  84/ 1024)-Loss: 0.401|Top1 Acc: 89.780|Top5 Acc: 99.180]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 115.78it/s]\u001b[0m\n",
      "[Test (  84/ 1024)-Loss: 0.412|Top1 Acc: 89.640|Top5 Acc: 99.070]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 88.11it/s]\u001b[0m\n",
      "[Train(  85/ 1024)-Total: 0.849|Labeled: 0.786|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.84it/s]\u001b[0m\n",
      "[Train(  85/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.52it/s]\u001b[0m\n",
      "[Valid(  85/ 1024)-Loss: 0.396|Top1 Acc: 89.960|Top5 Acc: 99.220]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.38it/s]\u001b[0m\n",
      "[Test (  85/ 1024)-Loss: 0.407|Top1 Acc: 89.560|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:54<00:00, 87.49it/s]\u001b[0m\n",
      "[Train(  86/ 1024)-Total: 0.856|Labeled: 0.792|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:56<00:00,  5.82it/s]\u001b[0m\n",
      "[Train(  86/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.73it/s]\u001b[0m\n",
      "[Valid(  86/ 1024)-Loss: 0.401|Top1 Acc: 89.480|Top5 Acc: 99.260]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 105.87it/s]\u001b[0m\n",
      "[Test (  86/ 1024)-Loss: 0.407|Top1 Acc: 89.700|Top5 Acc: 98.990]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 88.74it/s]\u001b[0m\n",
      "[Train(  87/ 1024)-Total: 0.845|Labeled: 0.782|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.93it/s]\u001b[0m\n",
      "[Train(  87/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.49it/s]\u001b[0m\n",
      "[Valid(  87/ 1024)-Loss: 0.392|Top1 Acc: 89.860|Top5 Acc: 99.280]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.14it/s]\u001b[0m\n",
      "[Test (  87/ 1024)-Loss: 0.400|Top1 Acc: 89.800|Top5 Acc: 99.100]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:59<00:00, 83.41it/s]\u001b[0m\n",
      "[Train(  88/ 1024)-Total: 0.838|Labeled: 0.775|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.87it/s]\u001b[0m\n",
      "[Train(  88/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.43it/s]\u001b[0m\n",
      "[Valid(  88/ 1024)-Loss: 0.385|Top1 Acc: 90.120|Top5 Acc: 99.200]: 100%|\u001b[92m████████████████████\u001b[39m| [00:48<00:00, 102.17it/s]\u001b[0m\n",
      "[Test (  88/ 1024)-Loss: 0.397|Top1 Acc: 89.890|Top5 Acc: 99.060]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 84.89it/s]\u001b[0m\n",
      "[Train(  89/ 1024)-Total: 0.844|Labeled: 0.780|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.82it/s]\u001b[0m\n",
      "[Train(  89/ 1024)-Loss: 0.114|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 42.94it/s]\u001b[0m\n",
      "[Valid(  89/ 1024)-Loss: 0.387|Top1 Acc: 89.920|Top5 Acc: 99.260]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 109.25it/s]\u001b[0m\n",
      "[Test (  89/ 1024)-Loss: 0.400|Top1 Acc: 90.020|Top5 Acc: 98.990]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:00<00:00, 82.91it/s]\u001b[0m\n",
      "[Train(  90/ 1024)-Total: 0.829|Labeled: 0.765|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train(  90/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.61it/s]\u001b[0m\n",
      "[Valid(  90/ 1024)-Loss: 0.387|Top1 Acc: 89.940|Top5 Acc: 99.280]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.48it/s]\u001b[0m\n",
      "[Test (  90/ 1024)-Loss: 0.396|Top1 Acc: 89.880|Top5 Acc: 99.080]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 89.05it/s]\u001b[0m\n",
      "[Train(  91/ 1024)-Total: 0.831|Labeled: 0.766|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.83it/s]\u001b[0m\n",
      "[Train(  91/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 40.84it/s]\u001b[0m\n",
      "[Valid(  91/ 1024)-Loss: 0.388|Top1 Acc: 89.960|Top5 Acc: 99.220]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 99.78it/s]\u001b[0m\n",
      "[Test (  91/ 1024)-Loss: 0.397|Top1 Acc: 89.900|Top5 Acc: 99.120]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:13<00:00, 75.09it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train(  92/ 1024)-Total: 0.862|Labeled: 0.795|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:54<00:00,  5.87it/s]\u001b[0m\n",
      "[Train(  92/ 1024)-Loss: 0.123|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.91it/s]\u001b[0m\n",
      "[Valid(  92/ 1024)-Loss: 0.393|Top1 Acc: 89.940|Top5 Acc: 99.320]: 100%|\u001b[92m████████████████████\u001b[39m| [00:47<00:00, 104.24it/s]\u001b[0m\n",
      "[Test (  92/ 1024)-Loss: 0.399|Top1 Acc: 89.960|Top5 Acc: 99.140]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:50<00:00, 90.88it/s]\u001b[0m\n",
      "[Train(  93/ 1024)-Total: 0.850|Labeled: 0.784|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  93/ 1024)-Loss: 0.121|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.89it/s]\u001b[0m\n",
      "[Valid(  93/ 1024)-Loss: 0.388|Top1 Acc: 89.940|Top5 Acc: 99.300]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.72it/s]\u001b[0m\n",
      "[Test (  93/ 1024)-Loss: 0.397|Top1 Acc: 90.250|Top5 Acc: 99.050]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:45<00:00, 94.79it/s]\u001b[0m\n",
      "[Train(  94/ 1024)-Total: 0.825|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train(  94/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.64it/s]\u001b[0m\n",
      "[Valid(  94/ 1024)-Loss: 0.382|Top1 Acc: 90.100|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.02it/s]\u001b[0m\n",
      "[Test (  94/ 1024)-Loss: 0.392|Top1 Acc: 90.200|Top5 Acc: 99.160]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.84it/s]\u001b[0m\n",
      "[Train(  95/ 1024)-Total: 0.837|Labeled: 0.770|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  95/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.68it/s]\u001b[0m\n",
      "[Valid(  95/ 1024)-Loss: 0.379|Top1 Acc: 90.160|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.93it/s]\u001b[0m\n",
      "[Test (  95/ 1024)-Loss: 0.389|Top1 Acc: 90.130|Top5 Acc: 99.190]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.03it/s]\u001b[0m\n",
      "[Train(  96/ 1024)-Total: 0.855|Labeled: 0.784|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  96/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.67it/s]\u001b[0m\n",
      "[Valid(  96/ 1024)-Loss: 0.386|Top1 Acc: 89.940|Top5 Acc: 99.400]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.67it/s]\u001b[0m\n",
      "[Test (  96/ 1024)-Loss: 0.395|Top1 Acc: 89.920|Top5 Acc: 99.040]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.71it/s]\u001b[0m\n",
      "[Train(  97/ 1024)-Total: 0.846|Labeled: 0.777|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  97/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.53it/s]\u001b[0m\n",
      "[Valid(  97/ 1024)-Loss: 0.382|Top1 Acc: 89.820|Top5 Acc: 99.300]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.53it/s]\u001b[0m\n",
      "[Test (  97/ 1024)-Loss: 0.390|Top1 Acc: 90.080|Top5 Acc: 99.070]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.48it/s]\u001b[0m\n",
      "[Train(  98/ 1024)-Total: 0.864|Labeled: 0.792|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  98/ 1024)-Loss: 0.121|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.79it/s]\u001b[0m\n",
      "[Valid(  98/ 1024)-Loss: 0.383|Top1 Acc: 89.800|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.90it/s]\u001b[0m\n",
      "[Test (  98/ 1024)-Loss: 0.395|Top1 Acc: 90.010|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.71it/s]\u001b[0m\n",
      "[Train(  99/ 1024)-Total: 0.841|Labeled: 0.769|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train(  99/ 1024)-Loss: 0.119|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.78it/s]\u001b[0m\n",
      "[Valid(  99/ 1024)-Loss: 0.383|Top1 Acc: 89.980|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.37it/s]\u001b[0m\n",
      "[Test (  99/ 1024)-Loss: 0.395|Top1 Acc: 89.900|Top5 Acc: 99.110]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.26it/s]\u001b[0m\n",
      "[Train( 100/ 1024)-Total: 0.835|Labeled: 0.764|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train( 100/ 1024)-Loss: 0.115|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.59it/s]\u001b[0m\n",
      "[Valid( 100/ 1024)-Loss: 0.378|Top1 Acc: 90.340|Top5 Acc: 99.320]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.92it/s]\u001b[0m\n",
      "[Test ( 100/ 1024)-Loss: 0.389|Top1 Acc: 90.080|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.97it/s]\u001b[0m\n",
      "[Train( 101/ 1024)-Total: 0.864|Labeled: 0.792|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.00it/s]\u001b[0m\n",
      "[Train( 101/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 19.44it/s]\u001b[0m\n",
      "[Valid( 101/ 1024)-Loss: 0.378|Top1 Acc: 90.440|Top5 Acc: 99.300]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 116.72it/s]\u001b[0m\n",
      "[Test ( 101/ 1024)-Loss: 0.389|Top1 Acc: 90.260|Top5 Acc: 99.100]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.02it/s]\u001b[0m\n",
      "[Train( 102/ 1024)-Total: 0.846|Labeled: 0.774|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train( 102/ 1024)-Loss: 0.119|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.92it/s]\u001b[0m\n",
      "[Valid( 102/ 1024)-Loss: 0.380|Top1 Acc: 90.240|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.22it/s]\u001b[0m\n",
      "[Test ( 102/ 1024)-Loss: 0.388|Top1 Acc: 90.260|Top5 Acc: 99.200]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.31it/s]\u001b[0m\n",
      "[Train( 103/ 1024)-Total: 0.855|Labeled: 0.782|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train( 103/ 1024)-Loss: 0.121|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.56it/s]\u001b[0m\n",
      "[Valid( 103/ 1024)-Loss: 0.380|Top1 Acc: 90.480|Top5 Acc: 99.240]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.45it/s]\u001b[0m\n",
      "[Test ( 103/ 1024)-Loss: 0.391|Top1 Acc: 90.350|Top5 Acc: 99.170]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.96it/s]\u001b[0m\n",
      "[Train( 104/ 1024)-Total: 0.855|Labeled: 0.781|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train( 104/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.64it/s]\u001b[0m\n",
      "[Valid( 104/ 1024)-Loss: 0.375|Top1 Acc: 90.640|Top5 Acc: 99.320]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.40it/s]\u001b[0m\n",
      "[Test ( 104/ 1024)-Loss: 0.389|Top1 Acc: 90.330|Top5 Acc: 99.160]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.98it/s]\u001b[0m\n",
      "[Train( 105/ 1024)-Total: 0.830|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train( 105/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.67it/s]\u001b[0m\n",
      "[Valid( 105/ 1024)-Loss: 0.378|Top1 Acc: 90.320|Top5 Acc: 99.220]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.32it/s]\u001b[0m\n",
      "[Test ( 105/ 1024)-Loss: 0.395|Top1 Acc: 90.030|Top5 Acc: 99.150]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.67it/s]\u001b[0m\n",
      "[Train( 106/ 1024)-Total: 0.841|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.00it/s]\u001b[0m\n",
      "[Train( 106/ 1024)-Loss: 0.114|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.59it/s]\u001b[0m\n",
      "[Valid( 106/ 1024)-Loss: 0.374|Top1 Acc: 90.660|Top5 Acc: 99.340]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:51<00:00, 97.11it/s]\u001b[0m\n",
      "[Test ( 106/ 1024)-Loss: 0.388|Top1 Acc: 90.080|Top5 Acc: 99.000]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.58it/s]\u001b[0m\n",
      "[Train( 107/ 1024)-Total: 0.843|Labeled: 0.769|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:55<00:00,  5.84it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 107/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.08it/s]\u001b[0m\n",
      "[Valid( 107/ 1024)-Loss: 0.375|Top1 Acc: 90.440|Top5 Acc: 99.280]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.02it/s]\u001b[0m\n",
      "[Test ( 107/ 1024)-Loss: 0.386|Top1 Acc: 90.130|Top5 Acc: 99.070]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:54<00:00, 87.45it/s]\u001b[0m\n",
      "[Train( 108/ 1024)-Total: 0.843|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.90it/s]\u001b[0m\n",
      "[Train( 108/ 1024)-Loss: 0.113|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.07it/s]\u001b[0m\n",
      "[Valid( 108/ 1024)-Loss: 0.374|Top1 Acc: 90.620|Top5 Acc: 99.340]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 115.37it/s]\u001b[0m\n",
      "[Test ( 108/ 1024)-Loss: 0.385|Top1 Acc: 90.190|Top5 Acc: 99.060]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 87.79it/s]\u001b[0m\n",
      "[Train( 109/ 1024)-Total: 0.863|Labeled: 0.786|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train( 109/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.52it/s]\u001b[0m\n",
      "[Valid( 109/ 1024)-Loss: 0.376|Top1 Acc: 90.540|Top5 Acc: 99.400]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 115.37it/s]\u001b[0m\n",
      "[Test ( 109/ 1024)-Loss: 0.386|Top1 Acc: 90.330|Top5 Acc: 99.050]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:53<00:00, 88.22it/s]\u001b[0m\n",
      "[Train( 110/ 1024)-Total: 0.873|Labeled: 0.795|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:08<00:00,  5.43it/s]\u001b[0m\n",
      "[Train( 110/ 1024)-Loss: 0.120|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 38.71it/s]\u001b[0m\n",
      "[Valid( 110/ 1024)-Loss: 0.373|Top1 Acc: 90.600|Top5 Acc: 99.460]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 98.40it/s]\u001b[0m\n",
      "[Test ( 110/ 1024)-Loss: 0.385|Top1 Acc: 90.300|Top5 Acc: 99.050]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:08<00:00, 78.02it/s]\u001b[0m\n",
      "[Train( 111/ 1024)-Total: 0.835|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:04<00:00,  5.54it/s]\u001b[0m\n",
      "[Train( 111/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.24it/s]\u001b[0m\n",
      "[Valid( 111/ 1024)-Loss: 0.369|Top1 Acc: 90.640|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:46<00:00, 107.11it/s]\u001b[0m\n",
      "[Test ( 111/ 1024)-Loss: 0.380|Top1 Acc: 90.390|Top5 Acc: 99.110]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:52<00:00, 89.20it/s]\u001b[0m\n",
      "[Train( 112/ 1024)-Total: 0.841|Labeled: 0.764|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:53<00:00,  5.89it/s]\u001b[0m\n",
      "[Train( 112/ 1024)-Loss: 0.113|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.39it/s]\u001b[0m\n",
      "[Valid( 112/ 1024)-Loss: 0.367|Top1 Acc: 90.660|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 113.84it/s]\u001b[0m\n",
      "[Test ( 112/ 1024)-Loss: 0.382|Top1 Acc: 90.400|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:57<00:00, 85.45it/s]\u001b[0m\n",
      "[Train( 113/ 1024)-Total: 0.841|Labeled: 0.764|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:23<00:00,  5.03it/s]\u001b[0m\n",
      "[Train( 113/ 1024)-Loss: 0.117|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.29it/s]\u001b[0m\n",
      "[Valid( 113/ 1024)-Loss: 0.366|Top1 Acc: 90.760|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:45<00:00, 109.33it/s]\u001b[0m\n",
      "[Test ( 113/ 1024)-Loss: 0.379|Top1 Acc: 90.140|Top5 Acc: 99.200]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:58<00:00, 84.74it/s]\u001b[0m\n",
      "[Train( 114/ 1024)-Total: 0.847|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:59<00:00,  4.27it/s]\u001b[0m\n",
      "[Train( 114/ 1024)-Loss: 0.114|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.27it/s]\u001b[0m\n",
      "[Valid( 114/ 1024)-Loss: 0.364|Top1 Acc: 90.820|Top5 Acc: 99.420]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:22<00:00, 60.55it/s]\u001b[0m\n",
      "[Test ( 114/ 1024)-Loss: 0.381|Top1 Acc: 90.170|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [04:34<00:00, 36.47it/s]\u001b[0m\n",
      "[Train( 115/ 1024)-Total: 0.857|Labeled: 0.777|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:44<00:00,  4.56it/s]\u001b[0m\n",
      "[Train( 115/ 1024)-Loss: 0.114|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.21it/s]\u001b[0m\n",
      "[Valid( 115/ 1024)-Loss: 0.365|Top1 Acc: 90.740|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 115.89it/s]\u001b[0m\n",
      "[Test ( 115/ 1024)-Loss: 0.380|Top1 Acc: 90.210|Top5 Acc: 99.180]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:29<00:00, 66.74it/s]\u001b[0m\n",
      "[Train( 116/ 1024)-Total: 0.862|Labeled: 0.780|Unlabeled: 0.010]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:30<00:00,  4.87it/s]\u001b[0m\n",
      "[Train( 116/ 1024)-Loss: 0.115|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.76it/s]\u001b[0m\n",
      "[Valid( 116/ 1024)-Loss: 0.371|Top1 Acc: 90.560|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.15it/s]\u001b[0m\n",
      "[Test ( 116/ 1024)-Loss: 0.383|Top1 Acc: 90.270|Top5 Acc: 99.120]: 100%|\u001b[91m█████████████████████\u001b[39m| [04:18<00:00, 38.73it/s]\u001b[0m\n",
      "[Train( 117/ 1024)-Total: 0.858|Labeled: 0.777|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [06:32<00:00,  2.61it/s]\u001b[0m\n",
      "[Train( 117/ 1024)-Loss: 0.116|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:02<00:00, 23.27it/s]\u001b[0m\n",
      "[Valid( 117/ 1024)-Loss: 0.367|Top1 Acc: 90.820|Top5 Acc: 99.320]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:53<00:00, 43.98it/s]\u001b[0m\n",
      "[Test ( 117/ 1024)-Loss: 0.382|Top1 Acc: 90.530|Top5 Acc: 99.090]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.33it/s]\u001b[0m\n",
      "[Train( 118/ 1024)-Total: 0.836|Labeled: 0.757|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:51<00:00,  5.97it/s]\u001b[0m\n",
      "[Train( 118/ 1024)-Loss: 0.110|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.61it/s]\u001b[0m\n",
      "[Valid( 118/ 1024)-Loss: 0.361|Top1 Acc: 90.720|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.57it/s]\u001b[0m\n",
      "[Test ( 118/ 1024)-Loss: 0.376|Top1 Acc: 90.570|Top5 Acc: 99.090]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.79it/s]\u001b[0m\n",
      "[Train( 119/ 1024)-Total: 0.863|Labeled: 0.780|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:52<00:00,  5.94it/s]\u001b[0m\n",
      "[Train( 119/ 1024)-Loss: 0.112|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.05it/s]\u001b[0m\n",
      "[Valid( 119/ 1024)-Loss: 0.362|Top1 Acc: 90.840|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:44<00:00, 111.91it/s]\u001b[0m\n",
      "[Test ( 119/ 1024)-Loss: 0.376|Top1 Acc: 90.330|Top5 Acc: 99.170]: 100%|\u001b[91m█████████████████████\u001b[39m| [04:21<00:00, 38.18it/s]\u001b[0m\n",
      "[Train( 120/ 1024)-Total: 0.824|Labeled: 0.745|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [06:48<00:00,  2.51it/s]\u001b[0m\n",
      "[Train( 120/ 1024)-Loss: 0.109|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.06it/s]\u001b[0m\n",
      "[Valid( 120/ 1024)-Loss: 0.352|Top1 Acc: 91.200|Top5 Acc: 99.480]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:41<00:00, 30.93it/s]\u001b[0m\n",
      "[Test ( 120/ 1024)-Loss: 0.364|Top1 Acc: 90.760|Top5 Acc: 99.220]: 100%|\u001b[91m█████████████████████\u001b[39m| [03:36<00:00, 46.09it/s]\u001b[0m\n",
      "[Train( 121/ 1024)-Total: 0.866|Labeled: 0.782|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:56<00:00,  5.80it/s]\u001b[0m\n",
      "[Train( 121/ 1024)-Loss: 0.113|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.50it/s]\u001b[0m\n",
      "[Valid( 121/ 1024)-Loss: 0.358|Top1 Acc: 91.160|Top5 Acc: 99.400]: 100%|\u001b[92m█████████████████████\u001b[39m| [01:26<00:00, 57.90it/s]\u001b[0m\n",
      "[Test ( 121/ 1024)-Loss: 0.371|Top1 Acc: 90.580|Top5 Acc: 99.070]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:51<00:00, 89.65it/s]\u001b[0m\n",
      "[Train( 122/ 1024)-Total: 0.843|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [04:56<00:00,  3.46it/s]\u001b[0m\n",
      "[Train( 122/ 1024)-Loss: 0.110|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 16.82it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid( 122/ 1024)-Loss: 0.360|Top1 Acc: 91.020|Top5 Acc: 99.360]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:48<00:00, 29.71it/s]\u001b[0m\n",
      "[Test ( 122/ 1024)-Loss: 0.374|Top1 Acc: 90.590|Top5 Acc: 99.100]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:59<00:00, 27.81it/s]\u001b[0m\n",
      "[Train( 123/ 1024)-Total: 0.873|Labeled: 0.787|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [03:58<00:00,  4.29it/s]\u001b[0m\n",
      "[Train( 123/ 1024)-Loss: 0.110|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.25it/s]\u001b[0m\n",
      "[Valid( 123/ 1024)-Loss: 0.356|Top1 Acc: 90.920|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.82it/s]\u001b[0m\n",
      "[Test ( 123/ 1024)-Loss: 0.372|Top1 Acc: 90.560|Top5 Acc: 99.150]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:59<00:00, 55.86it/s]\u001b[0m\n",
      "[Train( 124/ 1024)-Total: 0.836|Labeled: 0.752|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:34<00:00,  2.25it/s]\u001b[0m\n",
      "[Train( 124/ 1024)-Loss: 0.108|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 16.31it/s]\u001b[0m\n",
      "[Valid( 124/ 1024)-Loss: 0.352|Top1 Acc: 91.120|Top5 Acc: 99.520]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:46<00:00, 29.97it/s]\u001b[0m\n",
      "[Test ( 124/ 1024)-Loss: 0.368|Top1 Acc: 90.770|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:56<00:00, 28.06it/s]\u001b[0m\n",
      "[Train( 125/ 1024)-Total: 0.848|Labeled: 0.763|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:29<00:00,  2.28it/s]\u001b[0m\n",
      "[Train( 125/ 1024)-Loss: 0.106|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 18.91it/s]\u001b[0m\n",
      "[Valid( 125/ 1024)-Loss: 0.351|Top1 Acc: 91.120|Top5 Acc: 99.440]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:47<00:00, 29.94it/s]\u001b[0m\n",
      "[Test ( 125/ 1024)-Loss: 0.366|Top1 Acc: 90.840|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:54<00:00, 28.18it/s]\u001b[0m\n",
      "[Train( 126/ 1024)-Total: 0.848|Labeled: 0.763|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:26<00:00,  2.29it/s]\u001b[0m\n",
      "[Train( 126/ 1024)-Loss: 0.108|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 17.11it/s]\u001b[0m\n",
      "[Valid( 126/ 1024)-Loss: 0.352|Top1 Acc: 91.220|Top5 Acc: 99.380]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:45<00:00, 30.16it/s]\u001b[0m\n",
      "[Test ( 126/ 1024)-Loss: 0.364|Top1 Acc: 90.920|Top5 Acc: 99.130]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:55<00:00, 28.10it/s]\u001b[0m\n",
      "[Train( 127/ 1024)-Total: 0.872|Labeled: 0.784|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:28<00:00,  2.28it/s]\u001b[0m\n",
      "[Train( 127/ 1024)-Loss: 0.111|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 16.20it/s]\u001b[0m\n",
      "[Valid( 127/ 1024)-Loss: 0.353|Top1 Acc: 91.080|Top5 Acc: 99.300]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:46<00:00, 30.05it/s]\u001b[0m\n",
      "[Test ( 127/ 1024)-Loss: 0.365|Top1 Acc: 90.900|Top5 Acc: 99.070]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:56<00:00, 28.05it/s]\u001b[0m\n",
      "[Train( 128/ 1024)-Total: 0.855|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:28<00:00,  2.28it/s]\u001b[0m\n",
      "[Train( 128/ 1024)-Loss: 0.113|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 16.38it/s]\u001b[0m\n",
      "[Valid( 128/ 1024)-Loss: 0.355|Top1 Acc: 91.040|Top5 Acc: 99.420]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:45<00:00, 30.14it/s]\u001b[0m\n",
      "[Test ( 128/ 1024)-Loss: 0.369|Top1 Acc: 90.700|Top5 Acc: 99.090]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:55<00:00, 28.12it/s]\u001b[0m\n",
      "[Train( 129/ 1024)-Total: 0.856|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:27<00:00,  2.29it/s]\u001b[0m\n",
      "[Train( 129/ 1024)-Loss: 0.108|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 16.49it/s]\u001b[0m\n",
      "[Valid( 129/ 1024)-Loss: 0.348|Top1 Acc: 91.080|Top5 Acc: 99.340]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:46<00:00, 30.09it/s]\u001b[0m\n",
      "[Test ( 129/ 1024)-Loss: 0.364|Top1 Acc: 90.750|Top5 Acc: 99.080]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:55<00:00, 28.11it/s]\u001b[0m\n",
      "[Train( 130/ 1024)-Total: 0.842|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:26<00:00,  2.29it/s]\u001b[0m\n",
      "[Train( 130/ 1024)-Loss: 0.106|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 19.67it/s]\u001b[0m\n",
      "[Valid( 130/ 1024)-Loss: 0.346|Top1 Acc: 91.520|Top5 Acc: 99.400]: 100%|\u001b[92m█████████████████████\u001b[39m| [02:46<00:00, 30.03it/s]\u001b[0m\n",
      "[Test ( 130/ 1024)-Loss: 0.358|Top1 Acc: 91.050|Top5 Acc: 99.080]: 100%|\u001b[91m█████████████████████\u001b[39m| [05:56<00:00, 28.07it/s]\u001b[0m\n",
      "[Train( 131/ 1024)-Total: 0.875|Labeled: 0.784|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [07:26<00:00,  2.29it/s]\u001b[0m\n",
      "[Train( 131/ 1024)-Loss: 0.106|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:03<00:00, 16.38it/s]\u001b[0m\n",
      "[Valid( 131/ 1024)-Loss: 0.343|Top1 Acc: 91.400|Top5 Acc: 99.440]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 99.00it/s]\u001b[0m\n",
      "[Test ( 131/ 1024)-Loss: 0.357|Top1 Acc: 91.220|Top5 Acc: 99.160]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:50<00:00, 90.51it/s]\u001b[0m\n",
      "[Train( 132/ 1024)-Total: 0.853|Labeled: 0.764|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 132/ 1024)-Loss: 0.109|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.92it/s]\u001b[0m\n",
      "[Valid( 132/ 1024)-Loss: 0.350|Top1 Acc: 91.180|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.80it/s]\u001b[0m\n",
      "[Test ( 132/ 1024)-Loss: 0.365|Top1 Acc: 90.780|Top5 Acc: 99.180]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.06it/s]\u001b[0m\n",
      "[Train( 133/ 1024)-Total: 0.865|Labeled: 0.775|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 133/ 1024)-Loss: 0.107|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.98it/s]\u001b[0m\n",
      "[Valid( 133/ 1024)-Loss: 0.344|Top1 Acc: 91.220|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.82it/s]\u001b[0m\n",
      "[Test ( 133/ 1024)-Loss: 0.360|Top1 Acc: 90.930|Top5 Acc: 99.180]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.91it/s]\u001b[0m\n",
      "[Train( 134/ 1024)-Total: 0.852|Labeled: 0.763|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 134/ 1024)-Loss: 0.109|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.91it/s]\u001b[0m\n",
      "[Valid( 134/ 1024)-Loss: 0.348|Top1 Acc: 91.200|Top5 Acc: 99.320]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.03it/s]\u001b[0m\n",
      "[Test ( 134/ 1024)-Loss: 0.364|Top1 Acc: 91.050|Top5 Acc: 99.090]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.50it/s]\u001b[0m\n",
      "[Train( 135/ 1024)-Total: 0.851|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 135/ 1024)-Loss: 0.104|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.82it/s]\u001b[0m\n",
      "[Valid( 135/ 1024)-Loss: 0.340|Top1 Acc: 91.100|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.31it/s]\u001b[0m\n",
      "[Test ( 135/ 1024)-Loss: 0.356|Top1 Acc: 91.000|Top5 Acc: 99.270]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.97it/s]\u001b[0m\n",
      "[Train( 136/ 1024)-Total: 0.851|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 136/ 1024)-Loss: 0.104|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.06it/s]\u001b[0m\n",
      "[Valid( 136/ 1024)-Loss: 0.339|Top1 Acc: 91.180|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.94it/s]\u001b[0m\n",
      "[Test ( 136/ 1024)-Loss: 0.356|Top1 Acc: 90.850|Top5 Acc: 99.230]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.60it/s]\u001b[0m\n",
      "[Train( 137/ 1024)-Total: 0.859|Labeled: 0.767|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 137/ 1024)-Loss: 0.104|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.21it/s]\u001b[0m\n",
      "[Valid( 137/ 1024)-Loss: 0.342|Top1 Acc: 91.060|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.03it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test ( 137/ 1024)-Loss: 0.363|Top1 Acc: 90.790|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:45<00:00, 94.47it/s]\u001b[0m\n",
      "[Train( 138/ 1024)-Total: 0.862|Labeled: 0.769|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 138/ 1024)-Loss: 0.104|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.98it/s]\u001b[0m\n",
      "[Valid( 138/ 1024)-Loss: 0.341|Top1 Acc: 91.120|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.34it/s]\u001b[0m\n",
      "[Test ( 138/ 1024)-Loss: 0.360|Top1 Acc: 90.910|Top5 Acc: 99.250]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.96it/s]\u001b[0m\n",
      "[Train( 139/ 1024)-Total: 0.858|Labeled: 0.765|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 139/ 1024)-Loss: 0.106|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.04it/s]\u001b[0m\n",
      "[Valid( 139/ 1024)-Loss: 0.345|Top1 Acc: 91.180|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.71it/s]\u001b[0m\n",
      "[Test ( 139/ 1024)-Loss: 0.359|Top1 Acc: 90.980|Top5 Acc: 99.200]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.22it/s]\u001b[0m\n",
      "[Train( 140/ 1024)-Total: 0.877|Labeled: 0.781|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 140/ 1024)-Loss: 0.105|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.00it/s]\u001b[0m\n",
      "[Valid( 140/ 1024)-Loss: 0.341|Top1 Acc: 91.160|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.40it/s]\u001b[0m\n",
      "[Test ( 140/ 1024)-Loss: 0.359|Top1 Acc: 90.980|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.64it/s]\u001b[0m\n",
      "[Train( 141/ 1024)-Total: 0.851|Labeled: 0.758|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 141/ 1024)-Loss: 0.106|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.16it/s]\u001b[0m\n",
      "[Valid( 141/ 1024)-Loss: 0.337|Top1 Acc: 91.640|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.85it/s]\u001b[0m\n",
      "[Test ( 141/ 1024)-Loss: 0.359|Top1 Acc: 90.800|Top5 Acc: 99.230]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.72it/s]\u001b[0m\n",
      "[Train( 142/ 1024)-Total: 0.870|Labeled: 0.774|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 142/ 1024)-Loss: 0.103|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.02it/s]\u001b[0m\n",
      "[Valid( 142/ 1024)-Loss: 0.335|Top1 Acc: 91.300|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.21it/s]\u001b[0m\n",
      "[Test ( 142/ 1024)-Loss: 0.357|Top1 Acc: 90.940|Top5 Acc: 99.280]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.44it/s]\u001b[0m\n",
      "[Train( 143/ 1024)-Total: 0.882|Labeled: 0.784|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 143/ 1024)-Loss: 0.105|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.00it/s]\u001b[0m\n",
      "[Valid( 143/ 1024)-Loss: 0.338|Top1 Acc: 91.240|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.51it/s]\u001b[0m\n",
      "[Test ( 143/ 1024)-Loss: 0.357|Top1 Acc: 90.990|Top5 Acc: 99.170]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.20it/s]\u001b[0m\n",
      "[Train( 144/ 1024)-Total: 0.854|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 144/ 1024)-Loss: 0.103|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.94it/s]\u001b[0m\n",
      "[Valid( 144/ 1024)-Loss: 0.338|Top1 Acc: 91.320|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.50it/s]\u001b[0m\n",
      "[Test ( 144/ 1024)-Loss: 0.355|Top1 Acc: 90.920|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.96it/s]\u001b[0m\n",
      "[Train( 145/ 1024)-Total: 0.857|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 145/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.96it/s]\u001b[0m\n",
      "[Valid( 145/ 1024)-Loss: 0.337|Top1 Acc: 91.320|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.48it/s]\u001b[0m\n",
      "[Test ( 145/ 1024)-Loss: 0.355|Top1 Acc: 90.980|Top5 Acc: 99.150]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.47it/s]\u001b[0m\n",
      "[Train( 146/ 1024)-Total: 0.848|Labeled: 0.753|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 146/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.95it/s]\u001b[0m\n",
      "[Valid( 146/ 1024)-Loss: 0.336|Top1 Acc: 91.300|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.64it/s]\u001b[0m\n",
      "[Test ( 146/ 1024)-Loss: 0.353|Top1 Acc: 91.220|Top5 Acc: 99.150]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.03it/s]\u001b[0m\n",
      "[Train( 147/ 1024)-Total: 0.846|Labeled: 0.750|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 147/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.99it/s]\u001b[0m\n",
      "[Valid( 147/ 1024)-Loss: 0.333|Top1 Acc: 91.320|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.14it/s]\u001b[0m\n",
      "[Test ( 147/ 1024)-Loss: 0.355|Top1 Acc: 91.110|Top5 Acc: 99.200]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.95it/s]\u001b[0m\n",
      "[Train( 148/ 1024)-Total: 0.858|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 148/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.93it/s]\u001b[0m\n",
      "[Valid( 148/ 1024)-Loss: 0.332|Top1 Acc: 91.640|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.16it/s]\u001b[0m\n",
      "[Test ( 148/ 1024)-Loss: 0.354|Top1 Acc: 91.160|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.98it/s]\u001b[0m\n",
      "[Train( 149/ 1024)-Total: 0.856|Labeled: 0.758|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 149/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.80it/s]\u001b[0m\n",
      "[Valid( 149/ 1024)-Loss: 0.332|Top1 Acc: 91.320|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.56it/s]\u001b[0m\n",
      "[Test ( 149/ 1024)-Loss: 0.351|Top1 Acc: 91.310|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.65it/s]\u001b[0m\n",
      "[Train( 150/ 1024)-Total: 0.868|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 150/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.83it/s]\u001b[0m\n",
      "[Valid( 150/ 1024)-Loss: 0.330|Top1 Acc: 91.400|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.90it/s]\u001b[0m\n",
      "[Test ( 150/ 1024)-Loss: 0.351|Top1 Acc: 91.250|Top5 Acc: 99.250]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.67it/s]\u001b[0m\n",
      "[Train( 151/ 1024)-Total: 0.855|Labeled: 0.754|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 151/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.08it/s]\u001b[0m\n",
      "[Valid( 151/ 1024)-Loss: 0.333|Top1 Acc: 91.440|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.00it/s]\u001b[0m\n",
      "[Test ( 151/ 1024)-Loss: 0.354|Top1 Acc: 91.310|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.27it/s]\u001b[0m\n",
      "[Train( 152/ 1024)-Total: 0.878|Labeled: 0.777|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 152/ 1024)-Loss: 0.104|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.64it/s]\u001b[0m\n",
      "[Valid( 152/ 1024)-Loss: 0.334|Top1 Acc: 91.600|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.93it/s]\u001b[0m\n",
      "[Test ( 152/ 1024)-Loss: 0.351|Top1 Acc: 91.160|Top5 Acc: 99.220]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.08it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 153/ 1024)-Total: 0.862|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 153/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.99it/s]\u001b[0m\n",
      "[Valid( 153/ 1024)-Loss: 0.332|Top1 Acc: 91.400|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.40it/s]\u001b[0m\n",
      "[Test ( 153/ 1024)-Loss: 0.350|Top1 Acc: 91.060|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.95it/s]\u001b[0m\n",
      "[Train( 154/ 1024)-Total: 0.876|Labeled: 0.773|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 154/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.21it/s]\u001b[0m\n",
      "[Valid( 154/ 1024)-Loss: 0.335|Top1 Acc: 91.540|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.99it/s]\u001b[0m\n",
      "[Test ( 154/ 1024)-Loss: 0.355|Top1 Acc: 90.870|Top5 Acc: 99.250]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.78it/s]\u001b[0m\n",
      "[Train( 155/ 1024)-Total: 0.862|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 155/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.07it/s]\u001b[0m\n",
      "[Valid( 155/ 1024)-Loss: 0.330|Top1 Acc: 91.620|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.89it/s]\u001b[0m\n",
      "[Test ( 155/ 1024)-Loss: 0.352|Top1 Acc: 90.810|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.73it/s]\u001b[0m\n",
      "[Train( 156/ 1024)-Total: 0.849|Labeled: 0.749|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 156/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.09it/s]\u001b[0m\n",
      "[Valid( 156/ 1024)-Loss: 0.329|Top1 Acc: 91.720|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.96it/s]\u001b[0m\n",
      "[Test ( 156/ 1024)-Loss: 0.348|Top1 Acc: 91.110|Top5 Acc: 99.250]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.54it/s]\u001b[0m\n",
      "[Train( 157/ 1024)-Total: 0.860|Labeled: 0.757|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 157/ 1024)-Loss: 0.095|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.11it/s]\u001b[0m\n",
      "[Valid( 157/ 1024)-Loss: 0.326|Top1 Acc: 91.800|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.20it/s]\u001b[0m\n",
      "[Test ( 157/ 1024)-Loss: 0.348|Top1 Acc: 91.170|Top5 Acc: 99.250]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.70it/s]\u001b[0m\n",
      "[Train( 158/ 1024)-Total: 0.865|Labeled: 0.762|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 158/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.78it/s]\u001b[0m\n",
      "[Valid( 158/ 1024)-Loss: 0.332|Top1 Acc: 91.740|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.24it/s]\u001b[0m\n",
      "[Test ( 158/ 1024)-Loss: 0.347|Top1 Acc: 91.350|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.10it/s]\u001b[0m\n",
      "[Train( 159/ 1024)-Total: 0.845|Labeled: 0.743|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 159/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.94it/s]\u001b[0m\n",
      "[Valid( 159/ 1024)-Loss: 0.329|Top1 Acc: 91.540|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.46it/s]\u001b[0m\n",
      "[Test ( 159/ 1024)-Loss: 0.347|Top1 Acc: 91.110|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.48it/s]\u001b[0m\n",
      "[Train( 160/ 1024)-Total: 0.858|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 160/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.24it/s]\u001b[0m\n",
      "[Valid( 160/ 1024)-Loss: 0.330|Top1 Acc: 91.700|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.47it/s]\u001b[0m\n",
      "[Test ( 160/ 1024)-Loss: 0.347|Top1 Acc: 91.200|Top5 Acc: 99.270]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.41it/s]\u001b[0m\n",
      "[Train( 161/ 1024)-Total: 0.853|Labeled: 0.749|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 161/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.07it/s]\u001b[0m\n",
      "[Valid( 161/ 1024)-Loss: 0.330|Top1 Acc: 91.640|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.86it/s]\u001b[0m\n",
      "[Test ( 161/ 1024)-Loss: 0.344|Top1 Acc: 91.220|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.26it/s]\u001b[0m\n",
      "[Train( 162/ 1024)-Total: 0.871|Labeled: 0.766|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 162/ 1024)-Loss: 0.103|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.02it/s]\u001b[0m\n",
      "[Valid( 162/ 1024)-Loss: 0.334|Top1 Acc: 91.680|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.82it/s]\u001b[0m\n",
      "[Test ( 162/ 1024)-Loss: 0.348|Top1 Acc: 91.280|Top5 Acc: 99.230]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.06it/s]\u001b[0m\n",
      "[Train( 163/ 1024)-Total: 0.860|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 163/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.91it/s]\u001b[0m\n",
      "[Valid( 163/ 1024)-Loss: 0.331|Top1 Acc: 91.840|Top5 Acc: 99.340]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.57it/s]\u001b[0m\n",
      "[Test ( 163/ 1024)-Loss: 0.348|Top1 Acc: 91.170|Top5 Acc: 99.320]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.02it/s]\u001b[0m\n",
      "[Train( 164/ 1024)-Total: 0.875|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 164/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.05it/s]\u001b[0m\n",
      "[Valid( 164/ 1024)-Loss: 0.333|Top1 Acc: 91.840|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.40it/s]\u001b[0m\n",
      "[Test ( 164/ 1024)-Loss: 0.349|Top1 Acc: 90.940|Top5 Acc: 99.270]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.71it/s]\u001b[0m\n",
      "[Train( 165/ 1024)-Total: 0.869|Labeled: 0.762|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 165/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.89it/s]\u001b[0m\n",
      "[Valid( 165/ 1024)-Loss: 0.328|Top1 Acc: 91.640|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.41it/s]\u001b[0m\n",
      "[Test ( 165/ 1024)-Loss: 0.351|Top1 Acc: 91.050|Top5 Acc: 99.310]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.03it/s]\u001b[0m\n",
      "[Train( 166/ 1024)-Total: 0.879|Labeled: 0.769|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 166/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.82it/s]\u001b[0m\n",
      "[Valid( 166/ 1024)-Loss: 0.328|Top1 Acc: 91.620|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.21it/s]\u001b[0m\n",
      "[Test ( 166/ 1024)-Loss: 0.352|Top1 Acc: 91.120|Top5 Acc: 99.300]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.67it/s]\u001b[0m\n",
      "[Train( 167/ 1024)-Total: 0.880|Labeled: 0.771|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 167/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.84it/s]\u001b[0m\n",
      "[Valid( 167/ 1024)-Loss: 0.333|Top1 Acc: 91.600|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.42it/s]\u001b[0m\n",
      "[Test ( 167/ 1024)-Loss: 0.352|Top1 Acc: 91.000|Top5 Acc: 99.190]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.15it/s]\u001b[0m\n",
      "[Train( 168/ 1024)-Total: 0.890|Labeled: 0.780|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 168/ 1024)-Loss: 0.103|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.17it/s]\u001b[0m\n",
      "[Valid( 168/ 1024)-Loss: 0.333|Top1 Acc: 91.480|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.35it/s]\u001b[0m\n",
      "[Test ( 168/ 1024)-Loss: 0.351|Top1 Acc: 91.120|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.29it/s]\u001b[0m\n",
      "[Train( 169/ 1024)-Total: 0.871|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 169/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.93it/s]\u001b[0m\n",
      "[Valid( 169/ 1024)-Loss: 0.336|Top1 Acc: 91.340|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.85it/s]\u001b[0m\n",
      "[Test ( 169/ 1024)-Loss: 0.357|Top1 Acc: 90.730|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.12it/s]\u001b[0m\n",
      "[Train( 170/ 1024)-Total: 0.857|Labeled: 0.750|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 170/ 1024)-Loss: 0.095|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.55it/s]\u001b[0m\n",
      "[Valid( 170/ 1024)-Loss: 0.328|Top1 Acc: 91.480|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.02it/s]\u001b[0m\n",
      "[Test ( 170/ 1024)-Loss: 0.351|Top1 Acc: 90.930|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.75it/s]\u001b[0m\n",
      "[Train( 171/ 1024)-Total: 0.861|Labeled: 0.752|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 171/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.23it/s]\u001b[0m\n",
      "[Valid( 171/ 1024)-Loss: 0.327|Top1 Acc: 91.360|Top5 Acc: 99.400]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.89it/s]\u001b[0m\n",
      "[Test ( 171/ 1024)-Loss: 0.345|Top1 Acc: 91.340|Top5 Acc: 99.350]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.92it/s]\u001b[0m\n",
      "[Train( 172/ 1024)-Total: 0.869|Labeled: 0.758|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 172/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.64it/s]\u001b[0m\n",
      "[Valid( 172/ 1024)-Loss: 0.328|Top1 Acc: 91.360|Top5 Acc: 99.400]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.14it/s]\u001b[0m\n",
      "[Test ( 172/ 1024)-Loss: 0.349|Top1 Acc: 91.240|Top5 Acc: 99.160]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:45<00:00, 94.44it/s]\u001b[0m\n",
      "[Train( 173/ 1024)-Total: 0.878|Labeled: 0.765|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 173/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.00it/s]\u001b[0m\n",
      "[Valid( 173/ 1024)-Loss: 0.327|Top1 Acc: 91.460|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.34it/s]\u001b[0m\n",
      "[Test ( 173/ 1024)-Loss: 0.345|Top1 Acc: 91.210|Top5 Acc: 99.230]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.61it/s]\u001b[0m\n",
      "[Train( 174/ 1024)-Total: 0.872|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 174/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.80it/s]\u001b[0m\n",
      "[Valid( 174/ 1024)-Loss: 0.324|Top1 Acc: 91.760|Top5 Acc: 99.360]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.53it/s]\u001b[0m\n",
      "[Test ( 174/ 1024)-Loss: 0.339|Top1 Acc: 91.440|Top5 Acc: 99.300]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.78it/s]\u001b[0m\n",
      "[Train( 175/ 1024)-Total: 0.859|Labeled: 0.748|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 175/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.97it/s]\u001b[0m\n",
      "[Valid( 175/ 1024)-Loss: 0.328|Top1 Acc: 91.500|Top5 Acc: 99.340]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.67it/s]\u001b[0m\n",
      "[Test ( 175/ 1024)-Loss: 0.340|Top1 Acc: 91.390|Top5 Acc: 99.280]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.18it/s]\u001b[0m\n",
      "[Train( 176/ 1024)-Total: 0.874|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 176/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.72it/s]\u001b[0m\n",
      "[Valid( 176/ 1024)-Loss: 0.326|Top1 Acc: 91.320|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.64it/s]\u001b[0m\n",
      "[Test ( 176/ 1024)-Loss: 0.341|Top1 Acc: 91.340|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.21it/s]\u001b[0m\n",
      "[Train( 177/ 1024)-Total: 0.873|Labeled: 0.758|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 177/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.04it/s]\u001b[0m\n",
      "[Valid( 177/ 1024)-Loss: 0.324|Top1 Acc: 91.640|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.82it/s]\u001b[0m\n",
      "[Test ( 177/ 1024)-Loss: 0.337|Top1 Acc: 91.360|Top5 Acc: 99.380]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.90it/s]\u001b[0m\n",
      "[Train( 178/ 1024)-Total: 0.884|Labeled: 0.769|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 178/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.07it/s]\u001b[0m\n",
      "[Valid( 178/ 1024)-Loss: 0.330|Top1 Acc: 91.520|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.70it/s]\u001b[0m\n",
      "[Test ( 178/ 1024)-Loss: 0.343|Top1 Acc: 91.260|Top5 Acc: 99.300]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.86it/s]\u001b[0m\n",
      "[Train( 179/ 1024)-Total: 0.893|Labeled: 0.776|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 179/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 44.76it/s]\u001b[0m\n",
      "[Valid( 179/ 1024)-Loss: 0.330|Top1 Acc: 91.620|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.56it/s]\u001b[0m\n",
      "[Test ( 179/ 1024)-Loss: 0.344|Top1 Acc: 91.250|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.31it/s]\u001b[0m\n",
      "[Train( 180/ 1024)-Total: 0.879|Labeled: 0.762|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 180/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.86it/s]\u001b[0m\n",
      "[Valid( 180/ 1024)-Loss: 0.328|Top1 Acc: 91.560|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.36it/s]\u001b[0m\n",
      "[Test ( 180/ 1024)-Loss: 0.342|Top1 Acc: 91.230|Top5 Acc: 99.290]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.77it/s]\u001b[0m\n",
      "[Train( 181/ 1024)-Total: 0.878|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 181/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.71it/s]\u001b[0m\n",
      "[Valid( 181/ 1024)-Loss: 0.326|Top1 Acc: 91.540|Top5 Acc: 99.380]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.13it/s]\u001b[0m\n",
      "[Test ( 181/ 1024)-Loss: 0.340|Top1 Acc: 91.410|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.81it/s]\u001b[0m\n",
      "[Train( 182/ 1024)-Total: 0.870|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 182/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.00it/s]\u001b[0m\n",
      "[Valid( 182/ 1024)-Loss: 0.324|Top1 Acc: 91.540|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.63it/s]\u001b[0m\n",
      "[Test ( 182/ 1024)-Loss: 0.337|Top1 Acc: 91.600|Top5 Acc: 99.290]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.52it/s]\u001b[0m\n",
      "[Train( 183/ 1024)-Total: 0.877|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 183/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.81it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid( 183/ 1024)-Loss: 0.329|Top1 Acc: 91.560|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.45it/s]\u001b[0m\n",
      "[Test ( 183/ 1024)-Loss: 0.343|Top1 Acc: 91.580|Top5 Acc: 99.190]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:45<00:00, 94.57it/s]\u001b[0m\n",
      "[Train( 184/ 1024)-Total: 0.870|Labeled: 0.754|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.05it/s]\u001b[0m\n",
      "[Train( 184/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.86it/s]\u001b[0m\n",
      "[Valid( 184/ 1024)-Loss: 0.324|Top1 Acc: 91.640|Top5 Acc: 99.340]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.91it/s]\u001b[0m\n",
      "[Test ( 184/ 1024)-Loss: 0.338|Top1 Acc: 91.570|Top5 Acc: 99.250]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.20it/s]\u001b[0m\n",
      "[Train( 185/ 1024)-Total: 0.889|Labeled: 0.771|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 185/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.88it/s]\u001b[0m\n",
      "[Valid( 185/ 1024)-Loss: 0.321|Top1 Acc: 91.840|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.26it/s]\u001b[0m\n",
      "[Test ( 185/ 1024)-Loss: 0.335|Top1 Acc: 91.530|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.26it/s]\u001b[0m\n",
      "[Train( 186/ 1024)-Total: 0.887|Labeled: 0.767|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 186/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.04it/s]\u001b[0m\n",
      "[Valid( 186/ 1024)-Loss: 0.324|Top1 Acc: 91.900|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.64it/s]\u001b[0m\n",
      "[Test ( 186/ 1024)-Loss: 0.335|Top1 Acc: 91.590|Top5 Acc: 99.300]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.92it/s]\u001b[0m\n",
      "[Train( 187/ 1024)-Total: 0.882|Labeled: 0.762|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.05it/s]\u001b[0m\n",
      "[Train( 187/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.01it/s]\u001b[0m\n",
      "[Valid( 187/ 1024)-Loss: 0.330|Top1 Acc: 91.740|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.53it/s]\u001b[0m\n",
      "[Test ( 187/ 1024)-Loss: 0.340|Top1 Acc: 91.510|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.73it/s]\u001b[0m\n",
      "[Train( 188/ 1024)-Total: 0.881|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 188/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.13it/s]\u001b[0m\n",
      "[Valid( 188/ 1024)-Loss: 0.323|Top1 Acc: 91.760|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.20it/s]\u001b[0m\n",
      "[Test ( 188/ 1024)-Loss: 0.334|Top1 Acc: 91.570|Top5 Acc: 99.390]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.11it/s]\u001b[0m\n",
      "[Train( 189/ 1024)-Total: 0.909|Labeled: 0.783|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 189/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.01it/s]\u001b[0m\n",
      "[Valid( 189/ 1024)-Loss: 0.323|Top1 Acc: 91.760|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.64it/s]\u001b[0m\n",
      "[Test ( 189/ 1024)-Loss: 0.336|Top1 Acc: 91.760|Top5 Acc: 99.350]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.63it/s]\u001b[0m\n",
      "[Train( 190/ 1024)-Total: 0.880|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 190/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.83it/s]\u001b[0m\n",
      "[Valid( 190/ 1024)-Loss: 0.321|Top1 Acc: 91.860|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.48it/s]\u001b[0m\n",
      "[Test ( 190/ 1024)-Loss: 0.335|Top1 Acc: 91.690|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.62it/s]\u001b[0m\n",
      "[Train( 191/ 1024)-Total: 0.891|Labeled: 0.766|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 191/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.36it/s]\u001b[0m\n",
      "[Valid( 191/ 1024)-Loss: 0.322|Top1 Acc: 91.700|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.81it/s]\u001b[0m\n",
      "[Test ( 191/ 1024)-Loss: 0.335|Top1 Acc: 91.820|Top5 Acc: 99.310]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.85it/s]\u001b[0m\n",
      "[Train( 192/ 1024)-Total: 0.878|Labeled: 0.756|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 192/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.87it/s]\u001b[0m\n",
      "[Valid( 192/ 1024)-Loss: 0.321|Top1 Acc: 91.700|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:43<00:00, 114.07it/s]\u001b[0m\n",
      "[Test ( 192/ 1024)-Loss: 0.336|Top1 Acc: 91.580|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:50<00:00, 90.79it/s]\u001b[0m\n",
      "[Train( 193/ 1024)-Total: 0.862|Labeled: 0.743|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 193/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.78it/s]\u001b[0m\n",
      "[Valid( 193/ 1024)-Loss: 0.316|Top1 Acc: 91.980|Top5 Acc: 99.600]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.60it/s]\u001b[0m\n",
      "[Test ( 193/ 1024)-Loss: 0.336|Top1 Acc: 91.440|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.60it/s]\u001b[0m\n",
      "[Train( 194/ 1024)-Total: 0.882|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 194/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.87it/s]\u001b[0m\n",
      "[Valid( 194/ 1024)-Loss: 0.316|Top1 Acc: 91.920|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.88it/s]\u001b[0m\n",
      "[Test ( 194/ 1024)-Loss: 0.337|Top1 Acc: 91.560|Top5 Acc: 99.290]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.72it/s]\u001b[0m\n",
      "[Train( 195/ 1024)-Total: 0.882|Labeled: 0.758|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 195/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.82it/s]\u001b[0m\n",
      "[Valid( 195/ 1024)-Loss: 0.316|Top1 Acc: 92.040|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.24it/s]\u001b[0m\n",
      "[Test ( 195/ 1024)-Loss: 0.339|Top1 Acc: 91.470|Top5 Acc: 99.410]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.56it/s]\u001b[0m\n",
      "[Train( 196/ 1024)-Total: 0.880|Labeled: 0.756|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 196/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.04it/s]\u001b[0m\n",
      "[Valid( 196/ 1024)-Loss: 0.316|Top1 Acc: 92.100|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.07it/s]\u001b[0m\n",
      "[Test ( 196/ 1024)-Loss: 0.335|Top1 Acc: 91.460|Top5 Acc: 99.370]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.34it/s]\u001b[0m\n",
      "[Train( 197/ 1024)-Total: 0.869|Labeled: 0.746|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 197/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.76it/s]\u001b[0m\n",
      "[Valid( 197/ 1024)-Loss: 0.314|Top1 Acc: 92.200|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.22it/s]\u001b[0m\n",
      "[Test ( 197/ 1024)-Loss: 0.331|Top1 Acc: 91.630|Top5 Acc: 99.420]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.12it/s]\u001b[0m\n",
      "[Train( 198/ 1024)-Total: 0.859|Labeled: 0.737|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 198/ 1024)-Loss: 0.095|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.97it/s]\u001b[0m\n",
      "[Valid( 198/ 1024)-Loss: 0.316|Top1 Acc: 91.980|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.94it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test ( 198/ 1024)-Loss: 0.335|Top1 Acc: 91.430|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.92it/s]\u001b[0m\n",
      "[Train( 199/ 1024)-Total: 0.889|Labeled: 0.763|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.05it/s]\u001b[0m\n",
      "[Train( 199/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.69it/s]\u001b[0m\n",
      "[Valid( 199/ 1024)-Loss: 0.320|Top1 Acc: 92.120|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.85it/s]\u001b[0m\n",
      "[Test ( 199/ 1024)-Loss: 0.338|Top1 Acc: 91.390|Top5 Acc: 99.300]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.62it/s]\u001b[0m\n",
      "[Train( 200/ 1024)-Total: 0.880|Labeled: 0.753|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 200/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.12it/s]\u001b[0m\n",
      "[Valid( 200/ 1024)-Loss: 0.320|Top1 Acc: 91.940|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.24it/s]\u001b[0m\n",
      "[Test ( 200/ 1024)-Loss: 0.334|Top1 Acc: 91.560|Top5 Acc: 99.370]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.12it/s]\u001b[0m\n",
      "[Train( 201/ 1024)-Total: 0.880|Labeled: 0.752|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.05it/s]\u001b[0m\n",
      "[Train( 201/ 1024)-Loss: 0.094|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.22it/s]\u001b[0m\n",
      "[Valid( 201/ 1024)-Loss: 0.322|Top1 Acc: 91.840|Top5 Acc: 99.420]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.68it/s]\u001b[0m\n",
      "[Test ( 201/ 1024)-Loss: 0.333|Top1 Acc: 91.420|Top5 Acc: 99.290]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.20it/s]\u001b[0m\n",
      "[Train( 202/ 1024)-Total: 0.864|Labeled: 0.740|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 202/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.98it/s]\u001b[0m\n",
      "[Valid( 202/ 1024)-Loss: 0.318|Top1 Acc: 91.980|Top5 Acc: 99.440]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.39it/s]\u001b[0m\n",
      "[Test ( 202/ 1024)-Loss: 0.329|Top1 Acc: 91.580|Top5 Acc: 99.410]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.25it/s]\u001b[0m\n",
      "[Train( 203/ 1024)-Total: 0.876|Labeled: 0.750|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 203/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.81it/s]\u001b[0m\n",
      "[Valid( 203/ 1024)-Loss: 0.318|Top1 Acc: 91.780|Top5 Acc: 99.460]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.71it/s]\u001b[0m\n",
      "[Test ( 203/ 1024)-Loss: 0.330|Top1 Acc: 91.660|Top5 Acc: 99.420]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.79it/s]\u001b[0m\n",
      "[Train( 204/ 1024)-Total: 0.911|Labeled: 0.777|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 204/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.86it/s]\u001b[0m\n",
      "[Valid( 204/ 1024)-Loss: 0.323|Top1 Acc: 91.740|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.31it/s]\u001b[0m\n",
      "[Test ( 204/ 1024)-Loss: 0.330|Top1 Acc: 91.710|Top5 Acc: 99.350]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.39it/s]\u001b[0m\n",
      "[Train( 205/ 1024)-Total: 0.887|Labeled: 0.758|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 205/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.15it/s]\u001b[0m\n",
      "[Valid( 205/ 1024)-Loss: 0.319|Top1 Acc: 92.080|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.56it/s]\u001b[0m\n",
      "[Test ( 205/ 1024)-Loss: 0.334|Top1 Acc: 91.550|Top5 Acc: 99.310]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.45it/s]\u001b[0m\n",
      "[Train( 206/ 1024)-Total: 0.896|Labeled: 0.765|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 206/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.00it/s]\u001b[0m\n",
      "[Valid( 206/ 1024)-Loss: 0.313|Top1 Acc: 92.120|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.38it/s]\u001b[0m\n",
      "[Test ( 206/ 1024)-Loss: 0.331|Top1 Acc: 91.510|Top5 Acc: 99.410]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.55it/s]\u001b[0m\n",
      "[Train( 207/ 1024)-Total: 0.869|Labeled: 0.741|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 207/ 1024)-Loss: 0.093|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.62it/s]\u001b[0m\n",
      "[Valid( 207/ 1024)-Loss: 0.312|Top1 Acc: 91.960|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.47it/s]\u001b[0m\n",
      "[Test ( 207/ 1024)-Loss: 0.326|Top1 Acc: 91.530|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.35it/s]\u001b[0m\n",
      "[Train( 208/ 1024)-Total: 0.866|Labeled: 0.738|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 208/ 1024)-Loss: 0.094|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.85it/s]\u001b[0m\n",
      "[Valid( 208/ 1024)-Loss: 0.315|Top1 Acc: 91.740|Top5 Acc: 99.480]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.54it/s]\u001b[0m\n",
      "[Test ( 208/ 1024)-Loss: 0.333|Top1 Acc: 91.350|Top5 Acc: 99.290]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.62it/s]\u001b[0m\n",
      "[Train( 209/ 1024)-Total: 0.893|Labeled: 0.762|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 209/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.68it/s]\u001b[0m\n",
      "[Valid( 209/ 1024)-Loss: 0.316|Top1 Acc: 91.640|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.63it/s]\u001b[0m\n",
      "[Test ( 209/ 1024)-Loss: 0.333|Top1 Acc: 91.480|Top5 Acc: 99.350]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.92it/s]\u001b[0m\n",
      "[Train( 210/ 1024)-Total: 0.875|Labeled: 0.745|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 210/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.56it/s]\u001b[0m\n",
      "[Valid( 210/ 1024)-Loss: 0.314|Top1 Acc: 91.860|Top5 Acc: 99.620]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.63it/s]\u001b[0m\n",
      "[Test ( 210/ 1024)-Loss: 0.330|Top1 Acc: 91.570|Top5 Acc: 99.410]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.53it/s]\u001b[0m\n",
      "[Train( 211/ 1024)-Total: 0.887|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 211/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.58it/s]\u001b[0m\n",
      "[Valid( 211/ 1024)-Loss: 0.312|Top1 Acc: 92.240|Top5 Acc: 99.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.04it/s]\u001b[0m\n",
      "[Test ( 211/ 1024)-Loss: 0.332|Top1 Acc: 91.410|Top5 Acc: 99.380]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.53it/s]\u001b[0m\n",
      "[Train( 212/ 1024)-Total: 0.907|Labeled: 0.770|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 212/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.61it/s]\u001b[0m\n",
      "[Valid( 212/ 1024)-Loss: 0.311|Top1 Acc: 92.180|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.19it/s]\u001b[0m\n",
      "[Test ( 212/ 1024)-Loss: 0.331|Top1 Acc: 91.690|Top5 Acc: 99.440]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.55it/s]\u001b[0m\n",
      "[Train( 213/ 1024)-Total: 0.896|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 213/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.63it/s]\u001b[0m\n",
      "[Valid( 213/ 1024)-Loss: 0.312|Top1 Acc: 92.180|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 116.89it/s]\u001b[0m\n",
      "[Test ( 213/ 1024)-Loss: 0.326|Top1 Acc: 91.940|Top5 Acc: 99.380]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.25it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 214/ 1024)-Total: 0.893|Labeled: 0.760|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 214/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.07it/s]\u001b[0m\n",
      "[Valid( 214/ 1024)-Loss: 0.311|Top1 Acc: 92.360|Top5 Acc: 99.580]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.37it/s]\u001b[0m\n",
      "[Test ( 214/ 1024)-Loss: 0.330|Top1 Acc: 91.730|Top5 Acc: 99.310]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.33it/s]\u001b[0m\n",
      "[Train( 215/ 1024)-Total: 0.896|Labeled: 0.759|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 215/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 46.08it/s]\u001b[0m\n",
      "[Valid( 215/ 1024)-Loss: 0.306|Top1 Acc: 92.300|Top5 Acc: 99.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.90it/s]\u001b[0m\n",
      "[Test ( 215/ 1024)-Loss: 0.326|Top1 Acc: 91.830|Top5 Acc: 99.400]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:45<00:00, 94.68it/s]\u001b[0m\n",
      "[Train( 216/ 1024)-Total: 0.924|Labeled: 0.782|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 216/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.77it/s]\u001b[0m\n",
      "[Valid( 216/ 1024)-Loss: 0.312|Top1 Acc: 92.200|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.72it/s]\u001b[0m\n",
      "[Test ( 216/ 1024)-Loss: 0.331|Top1 Acc: 91.790|Top5 Acc: 99.430]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.71it/s]\u001b[0m\n",
      "[Train( 217/ 1024)-Total: 0.891|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 217/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.79it/s]\u001b[0m\n",
      "[Valid( 217/ 1024)-Loss: 0.312|Top1 Acc: 92.260|Top5 Acc: 99.580]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.43it/s]\u001b[0m\n",
      "[Test ( 217/ 1024)-Loss: 0.330|Top1 Acc: 91.820|Top5 Acc: 99.400]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.34it/s]\u001b[0m\n",
      "[Train( 218/ 1024)-Total: 0.873|Labeled: 0.741|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 218/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.99it/s]\u001b[0m\n",
      "[Valid( 218/ 1024)-Loss: 0.310|Top1 Acc: 92.380|Top5 Acc: 99.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.17it/s]\u001b[0m\n",
      "[Test ( 218/ 1024)-Loss: 0.331|Top1 Acc: 91.810|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.79it/s]\u001b[0m\n",
      "[Train( 219/ 1024)-Total: 0.893|Labeled: 0.755|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.04it/s]\u001b[0m\n",
      "[Train( 219/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.83it/s]\u001b[0m\n",
      "[Valid( 219/ 1024)-Loss: 0.303|Top1 Acc: 92.560|Top5 Acc: 99.580]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.07it/s]\u001b[0m\n",
      "[Test ( 219/ 1024)-Loss: 0.331|Top1 Acc: 91.610|Top5 Acc: 99.380]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.85it/s]\u001b[0m\n",
      "[Train( 220/ 1024)-Total: 0.897|Labeled: 0.760|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 220/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.49it/s]\u001b[0m\n",
      "[Valid( 220/ 1024)-Loss: 0.311|Top1 Acc: 92.280|Top5 Acc: 99.660]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.41it/s]\u001b[0m\n",
      "[Test ( 220/ 1024)-Loss: 0.336|Top1 Acc: 91.420|Top5 Acc: 99.350]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.25it/s]\u001b[0m\n",
      "[Train( 221/ 1024)-Total: 0.907|Labeled: 0.767|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 221/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.82it/s]\u001b[0m\n",
      "[Valid( 221/ 1024)-Loss: 0.314|Top1 Acc: 92.300|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.67it/s]\u001b[0m\n",
      "[Test ( 221/ 1024)-Loss: 0.331|Top1 Acc: 91.710|Top5 Acc: 99.380]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.58it/s]\u001b[0m\n",
      "[Train( 222/ 1024)-Total: 0.901|Labeled: 0.761|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 222/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.74it/s]\u001b[0m\n",
      "[Valid( 222/ 1024)-Loss: 0.308|Top1 Acc: 92.320|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.83it/s]\u001b[0m\n",
      "[Test ( 222/ 1024)-Loss: 0.326|Top1 Acc: 91.780|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.00it/s]\u001b[0m\n",
      "[Train( 223/ 1024)-Total: 0.903|Labeled: 0.762|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 223/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 43.95it/s]\u001b[0m\n",
      "[Valid( 223/ 1024)-Loss: 0.313|Top1 Acc: 92.100|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.91it/s]\u001b[0m\n",
      "[Test ( 223/ 1024)-Loss: 0.332|Top1 Acc: 91.790|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.99it/s]\u001b[0m\n",
      "[Train( 224/ 1024)-Total: 0.911|Labeled: 0.770|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 224/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.74it/s]\u001b[0m\n",
      "[Valid( 224/ 1024)-Loss: 0.309|Top1 Acc: 92.420|Top5 Acc: 99.540]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.64it/s]\u001b[0m\n",
      "[Test ( 224/ 1024)-Loss: 0.329|Top1 Acc: 91.860|Top5 Acc: 99.420]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.72it/s]\u001b[0m\n",
      "[Train( 225/ 1024)-Total: 0.891|Labeled: 0.754|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 225/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.75it/s]\u001b[0m\n",
      "[Valid( 225/ 1024)-Loss: 0.309|Top1 Acc: 92.400|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.29it/s]\u001b[0m\n",
      "[Test ( 225/ 1024)-Loss: 0.331|Top1 Acc: 91.780|Top5 Acc: 99.390]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.52it/s]\u001b[0m\n",
      "[Train( 226/ 1024)-Total: 0.912|Labeled: 0.770|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 226/ 1024)-Loss: 0.102|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.72it/s]\u001b[0m\n",
      "[Valid( 226/ 1024)-Loss: 0.309|Top1 Acc: 92.060|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 117.93it/s]\u001b[0m\n",
      "[Test ( 226/ 1024)-Loss: 0.327|Top1 Acc: 91.930|Top5 Acc: 99.460]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.97it/s]\u001b[0m\n",
      "[Train( 227/ 1024)-Total: 0.884|Labeled: 0.747|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 227/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.70it/s]\u001b[0m\n",
      "[Valid( 227/ 1024)-Loss: 0.303|Top1 Acc: 92.480|Top5 Acc: 99.620]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.05it/s]\u001b[0m\n",
      "[Test ( 227/ 1024)-Loss: 0.323|Top1 Acc: 91.910|Top5 Acc: 99.390]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.54it/s]\u001b[0m\n",
      "[Train( 228/ 1024)-Total: 0.869|Labeled: 0.733|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 228/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.72it/s]\u001b[0m\n",
      "[Valid( 228/ 1024)-Loss: 0.304|Top1 Acc: 92.560|Top5 Acc: 99.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.27it/s]\u001b[0m\n",
      "[Test ( 228/ 1024)-Loss: 0.323|Top1 Acc: 91.950|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:48<00:00, 92.19it/s]\u001b[0m\n",
      "[Train( 229/ 1024)-Total: 0.887|Labeled: 0.746|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train( 229/ 1024)-Loss: 0.093|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.55it/s]\u001b[0m\n",
      "[Valid( 229/ 1024)-Loss: 0.302|Top1 Acc: 92.580|Top5 Acc: 99.660]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.33it/s]\u001b[0m\n",
      "[Test ( 229/ 1024)-Loss: 0.323|Top1 Acc: 91.870|Top5 Acc: 99.460]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.42it/s]\u001b[0m\n",
      "[Train( 230/ 1024)-Total: 0.900|Labeled: 0.756|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 230/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.58it/s]\u001b[0m\n",
      "[Valid( 230/ 1024)-Loss: 0.305|Top1 Acc: 92.640|Top5 Acc: 99.640]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.02it/s]\u001b[0m\n",
      "[Test ( 230/ 1024)-Loss: 0.325|Top1 Acc: 91.880|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 94.03it/s]\u001b[0m\n",
      "[Train( 231/ 1024)-Total: 0.908|Labeled: 0.764|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.03it/s]\u001b[0m\n",
      "[Train( 231/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.84it/s]\u001b[0m\n",
      "[Valid( 231/ 1024)-Loss: 0.309|Top1 Acc: 92.400|Top5 Acc: 99.580]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.85it/s]\u001b[0m\n",
      "[Test ( 231/ 1024)-Loss: 0.329|Top1 Acc: 91.900|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.95it/s]\u001b[0m\n",
      "[Train( 232/ 1024)-Total: 0.892|Labeled: 0.749|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 232/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.62it/s]\u001b[0m\n",
      "[Valid( 232/ 1024)-Loss: 0.305|Top1 Acc: 92.440|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 120.01it/s]\u001b[0m\n",
      "[Test ( 232/ 1024)-Loss: 0.330|Top1 Acc: 91.700|Top5 Acc: 99.370]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.81it/s]\u001b[0m\n",
      "[Train( 233/ 1024)-Total: 0.895|Labeled: 0.751|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 233/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.79it/s]\u001b[0m\n",
      "[Valid( 233/ 1024)-Loss: 0.306|Top1 Acc: 92.140|Top5 Acc: 99.520]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.88it/s]\u001b[0m\n",
      "[Test ( 233/ 1024)-Loss: 0.332|Top1 Acc: 91.750|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.63it/s]\u001b[0m\n",
      "[Train( 234/ 1024)-Total: 0.892|Labeled: 0.751|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:49<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 234/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.75it/s]\u001b[0m\n",
      "[Valid( 234/ 1024)-Loss: 0.303|Top1 Acc: 92.420|Top5 Acc: 99.620]: 100%|\u001b[92m████████████████████\u001b[39m| [00:41<00:00, 119.31it/s]\u001b[0m\n",
      "[Test ( 234/ 1024)-Loss: 0.332|Top1 Acc: 91.700|Top5 Acc: 99.240]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.31it/s]\u001b[0m\n",
      "[Train( 235/ 1024)-Total: 0.898|Labeled: 0.754|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 235/ 1024)-Loss: 0.097|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.76it/s]\u001b[0m\n",
      "[Valid( 235/ 1024)-Loss: 0.308|Top1 Acc: 92.300|Top5 Acc: 99.580]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.10it/s]\u001b[0m\n",
      "[Test ( 235/ 1024)-Loss: 0.332|Top1 Acc: 91.610|Top5 Acc: 99.360]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.67it/s]\u001b[0m\n",
      "[Train( 236/ 1024)-Total: 0.898|Labeled: 0.752|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 236/ 1024)-Loss: 0.096|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.11it/s]\u001b[0m\n",
      "[Valid( 236/ 1024)-Loss: 0.307|Top1 Acc: 92.360|Top5 Acc: 99.640]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.94it/s]\u001b[0m\n",
      "[Test ( 236/ 1024)-Loss: 0.327|Top1 Acc: 91.760|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.15it/s]\u001b[0m\n",
      "[Train( 237/ 1024)-Total: 0.917|Labeled: 0.767|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 237/ 1024)-Loss: 0.098|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.73it/s]\u001b[0m\n",
      "[Valid( 237/ 1024)-Loss: 0.309|Top1 Acc: 92.420|Top5 Acc: 99.680]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.71it/s]\u001b[0m\n",
      "[Test ( 237/ 1024)-Loss: 0.326|Top1 Acc: 92.030|Top5 Acc: 99.260]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:46<00:00, 93.81it/s]\u001b[0m\n",
      "[Train( 238/ 1024)-Total: 0.898|Labeled: 0.752|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 238/ 1024)-Loss: 0.095|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.56it/s]\u001b[0m\n",
      "[Valid( 238/ 1024)-Loss: 0.309|Top1 Acc: 92.240|Top5 Acc: 99.640]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 119.05it/s]\u001b[0m\n",
      "[Test ( 238/ 1024)-Loss: 0.329|Top1 Acc: 91.710|Top5 Acc: 99.230]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.88it/s]\u001b[0m\n",
      "[Train( 239/ 1024)-Total: 0.889|Labeled: 0.744|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 239/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.92it/s]\u001b[0m\n",
      "[Valid( 239/ 1024)-Loss: 0.311|Top1 Acc: 92.520|Top5 Acc: 99.560]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.53it/s]\u001b[0m\n",
      "[Test ( 239/ 1024)-Loss: 0.333|Top1 Acc: 91.680|Top5 Acc: 99.290]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 93.21it/s]\u001b[0m\n",
      "[Train( 240/ 1024)-Total: 0.916|Labeled: 0.767|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.02it/s]\u001b[0m\n",
      "[Train( 240/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.56it/s]\u001b[0m\n",
      "[Valid( 240/ 1024)-Loss: 0.312|Top1 Acc: 92.340|Top5 Acc: 99.500]: 100%|\u001b[92m████████████████████\u001b[39m| [00:42<00:00, 118.54it/s]\u001b[0m\n",
      "[Test ( 240/ 1024)-Loss: 0.327|Top1 Acc: 92.080|Top5 Acc: 99.340]: 100%|\u001b[91m█████████████████████\u001b[39m| [01:47<00:00, 92.75it/s]\u001b[0m\n",
      "[Train( 241/ 1024)-Total: 0.891|Labeled: 0.745|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:50<00:00,  6.01it/s]\u001b[0m\n",
      "[Train( 241/ 1024)-Loss: 0.099|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 45.44it/s]\u001b[0m\n",
      "[Valid( 241/ 1024)-Loss: 0.312|Top1 Acc: 92.340|Top5 Acc: 99.540]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:50<00:00, 99.19it/s]\u001b[0m\n",
      "[Test ( 241/ 1024)-Loss: 0.326|Top1 Acc: 92.010|Top5 Acc: 99.330]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:23<00:00, 69.59it/s]\u001b[0m\n",
      "[Train( 242/ 1024)-Total: 0.920|Labeled: 0.768|Unlabeled: 0.009]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:57<00:00,  5.76it/s]\u001b[0m\n",
      "[Train( 242/ 1024)-Loss: 0.101|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 41.91it/s]\u001b[0m\n",
      "[Valid( 242/ 1024)-Loss: 0.314|Top1 Acc: 92.280|Top5 Acc: 99.600]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:57<00:00, 86.39it/s]\u001b[0m\n",
      "[Test ( 242/ 1024)-Loss: 0.327|Top1 Acc: 91.900|Top5 Acc: 99.320]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:17<00:00, 72.72it/s]\u001b[0m\n",
      "[Train( 243/ 1024)-Total: 0.906|Labeled: 0.755|Unlabeled: 0.008]: 100%|\u001b[94m██████████████████████\u001b[39m| [02:59<00:00,  5.70it/s]\u001b[0m\n",
      "[Train( 243/ 1024)-Loss: 0.100|Top1 Acc: 100.000|Top5 Acc: 100.000]: 100%|\u001b[94m███████████████████\u001b[39m| [00:01<00:00, 40.32it/s]\u001b[0m\n",
      "[Valid( 243/ 1024)-Loss: 0.310|Top1 Acc: 92.540|Top5 Acc: 99.600]: 100%|\u001b[92m█████████████████████\u001b[39m| [00:52<00:00, 95.26it/s]\u001b[0m\n",
      "[Test ( 243/ 1024)-Loss: 0.326|Top1 Acc: 91.890|Top5 Acc: 99.450]: 100%|\u001b[91m█████████████████████\u001b[39m| [02:14<00:00, 74.08it/s]\u001b[0m\n",
      "[Train( 264/ 1024)-Total: 0.904|Labeled: 0.757|Unlabeled: 0.008]:  26%|\u001b[94m█████▋                \u001b[39m| [00:50<02:24,  5.27it/s]\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# accuracy 증가 속도, loss values 감소 속도를 그래프로 그리기\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# list에 각종 값들을 저장\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     loss, loss_x, loss_u \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     21\u001b[0m     losses_x\u001b[38;5;241m.\u001b[39mappend(loss_x)\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mMixMatchTrainer.train\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Unlabeled data에 대한 실제 값 생성\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# 서로 다른 Augmentation 결과의 출력 값의 평균 계산\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Temperature 값으로 실제 값 스케일링\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 123\u001b[0m     outputs_u1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_u1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     outputs_u2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs_u2)\n\u001b[0;32m    126\u001b[0m     pt \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msoftmax(outputs_u1, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39msoftmax(outputs_u2, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mWideResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m     36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock1(out)\n\u001b[1;32m---> 37\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock3(out)\n\u001b[0;32m     39\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out))\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36mNetworkBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(out \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mequalInOut \u001b[38;5;28;01melse\u001b[39;00m x)))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdroprate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\dmqa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:148\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    150\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPxnUlhDyQQW8m0x4Udibre",
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1519005239f2de3440a81beb718df9ab72fdd1ec6a07fd4a7f663a9215b4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
