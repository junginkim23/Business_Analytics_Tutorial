{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit Card Fraud Detection dataset \n",
    "data = pd.read_csv('./data/creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time       24.000000\n",
       "V1          1.492936\n",
       "V2          1.417964\n",
       "V3          2.057323\n",
       "V4          2.712520\n",
       "V5          3.049106\n",
       "V6          3.721818\n",
       "V7          1.120631\n",
       "V8          0.855546\n",
       "V9          1.544071\n",
       "V10         1.638076\n",
       "V11         1.690330\n",
       "V12         1.298329\n",
       "V13         1.757964\n",
       "V14         1.126870\n",
       "V15         2.345865\n",
       "V16         1.660114\n",
       "V17         1.109969\n",
       "V18         1.965775\n",
       "V19         2.221868\n",
       "V20         0.524980\n",
       "V21         1.943465\n",
       "V22         1.353650\n",
       "V23         2.458589\n",
       "V24         1.011592\n",
       "V25         0.820591\n",
       "V26         0.502292\n",
       "V27         0.707519\n",
       "V28         0.949594\n",
       "Amount    378.660000\n",
       "Class       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1:30].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "\n",
    "# target data\n",
    "labels = data.loc[:,'Class']\n",
    "\n",
    "# other data\n",
    "data_1 = data.drop(labels='Class',axis=1)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_1, labels, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "\n",
    "# target data\n",
    "labels = data.loc[:,'Class']\n",
    "\n",
    "# other data\n",
    "data_1 = data.drop(labels='Class',axis=1)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_1, labels, test_size=0.2, random_state=77)\n",
    "\n",
    "min_val = torch.min(torch.tensor(train_y.values))\n",
    "max_val = torch.max(torch.tensor(train_y.values))\n",
    "\n",
    "\n",
    "\n",
    "# train_data = (torch.tensor(train_X.values) - min_val) / (max_val-min_val)\n",
    "# test_data = (torch.tensor(test_X.values) - min_val) / (max_val - min_val)\n",
    "\n",
    "train_labels = train_y.astype(bool)\n",
    "test_labels = test_y.astype(bool)\n",
    "\n",
    "normal_train_data = train_X[~train_labels]\n",
    "# normal_test_data = test_data[~test_labels]\n",
    "\n",
    "# anomalous_train_data = train_data[train_labels]\n",
    "# anomalous_test_data = test_data[test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283928    False\n",
       "194689    False\n",
       "47214     False\n",
       "69333     False\n",
       "120450    False\n",
       "          ...  \n",
       "138904    False\n",
       "107813    False\n",
       "215275    False\n",
       "74335     False\n",
       "178903    False\n",
       "Name: Class, Length: 227844, dtype: bool"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (torch.tensor(train_X.values) - min_val) / (max_val-min_val)\n",
    "test_data = (torch.tensor(test_X.values) - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Linear(32,16),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(16,8),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(8,4),\n",
    "      nn.ReLU())\n",
    "    \n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(16,32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32,70),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(70,140),\n",
    "      nn.Sigmoid())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = AnomalyDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[2,3],[4,5]])\n",
    "\n",
    "a = torch.tensor(a).float()\n",
    "b = torch.tensor(b).float()\n",
    "\n",
    "c = torch.cat([a,b],dim=1)\n",
    "\n",
    "torch.mean(a.view(-1,4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 2]), torch.Size([2, 4]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape , b.shape , c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(c,dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 2., 3.],\n",
       "        [3., 4., 4., 5.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1519005239f2de3440a81beb718df9ab72fdd1ec6a07fd4a7f663a9215b4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
